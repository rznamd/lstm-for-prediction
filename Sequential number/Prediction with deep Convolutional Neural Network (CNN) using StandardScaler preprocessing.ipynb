{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, TimeDistributed, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building synthetic chronological series of numbers dataset\n",
    "\n",
    "data = np.arange(0,200)\n",
    "data = np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling down the raw data with StandardScaler()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = data_scaled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the scaled data into training dataset\n",
    "\n",
    "training_dataset = data_scaled[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the scaled data into test dataset, this dataset won't be used in LSTM model training\n",
    "\n",
    "test_dataset = data_scaled[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.Shape: (185, 5, 1) Y.Shape: (185,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training dataset for LSTM input \n",
    "\n",
    "T = 5\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(len(training_dataset)-T):\n",
    "  x = training_dataset[t:t+T]\n",
    "  X.append(x)\n",
    "  y = training_dataset[t+T]\n",
    "  Y.append(y)\n",
    "X = np.array(X).reshape(-1, T, 1)\n",
    "Y = np.array(Y)\n",
    "N = len(X)\n",
    "print(\"X.Shape:\",X.shape, \"Y.Shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (148, 5, 1) x_test.shape: (37, 5, 1) y_train.shape: (148,) y_test.shape: (37,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting training dataset again into x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "print(\"x_train.shape:\",x_train.shape, \"x_test.shape:\",x_test.shape, \"y_train.shape:\",y_train.shape, \"y_test.shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 14:54:24.661418 20844 deprecation_wrapper.py:119] From C:\\Users\\22458147\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building Model CNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation='relu', input_shape=(5,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 14:54:26.232384 20844 deprecation_wrapper.py:119] From C:\\Users\\22458147\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 37 samples\n",
      "Epoch 1/1000\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 1.0370\n",
      "Epoch 2/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 0.2512 - val_loss: 0.5820\n",
      "Epoch 3/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 0.1132 - val_loss: 0.3141\n",
      "Epoch 4/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 0.0348 - val_loss: 0.1042\n",
      "Epoch 5/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 6/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 7/1000\n",
      "148/148 [==============================] - 0s 157us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 8/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 9/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 0.0032 - val_loss: 5.6714e-04\n",
      "Epoch 10/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 11/1000\n",
      "148/148 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.0131\n",
      "Epoch 12/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0115\n",
      "Epoch 13/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 0.0010 - val_loss: 0.0066\n",
      "Epoch 14/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3427e-04 - val_loss: 0.0032\n",
      "Epoch 15/1000\n",
      "148/148 [==============================] - 0s 166us/step - loss: 5.5033e-04 - val_loss: 0.0023\n",
      "Epoch 16/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.5826e-04 - val_loss: 0.0026\n",
      "Epoch 17/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.8941e-04 - val_loss: 0.0035\n",
      "Epoch 18/1000\n",
      "148/148 [==============================] - 0s 183us/step - loss: 3.2124e-04 - val_loss: 0.0043\n",
      "Epoch 19/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.8151e-04 - val_loss: 0.0044\n",
      "Epoch 20/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.3808e-04 - val_loss: 0.0031\n",
      "Epoch 21/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.0105e-04 - val_loss: 0.0021\n",
      "Epoch 22/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.7295e-04 - val_loss: 0.0016\n",
      "Epoch 23/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 1.4247e-04 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.1863e-04 - val_loss: 0.0012\n",
      "Epoch 25/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 9.7753e-05 - val_loss: 0.0011\n",
      "Epoch 26/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.3328e-05 - val_loss: 9.7245e-04\n",
      "Epoch 27/1000\n",
      "148/148 [==============================] - 0s 171us/step - loss: 7.0125e-05 - val_loss: 7.9845e-04\n",
      "Epoch 28/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 5.8629e-05 - val_loss: 5.3831e-04\n",
      "Epoch 29/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.8406e-05 - val_loss: 3.7887e-04\n",
      "Epoch 30/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.0221e-05 - val_loss: 2.7431e-04\n",
      "Epoch 31/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.3307e-05 - val_loss: 2.4479e-04\n",
      "Epoch 32/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.6395e-05 - val_loss: 1.8620e-04\n",
      "Epoch 33/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.1774e-05 - val_loss: 1.4698e-04\n",
      "Epoch 34/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.7899e-05 - val_loss: 1.0755e-04\n",
      "Epoch 35/1000\n",
      "148/148 [==============================] - 0s 188us/step - loss: 1.4538e-05 - val_loss: 8.6029e-05\n",
      "Epoch 36/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2040e-05 - val_loss: 6.0313e-05\n",
      "Epoch 37/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0100e-05 - val_loss: 4.4083e-05\n",
      "Epoch 38/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 8.0593e-06 - val_loss: 2.9785e-05\n",
      "Epoch 39/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.7345e-06 - val_loss: 1.9439e-05\n",
      "Epoch 40/1000\n",
      "148/148 [==============================] - 0s 183us/step - loss: 5.5939e-06 - val_loss: 1.0931e-05\n",
      "Epoch 41/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.6560e-06 - val_loss: 4.6866e-06\n",
      "Epoch 42/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.9420e-06 - val_loss: 2.8962e-06\n",
      "Epoch 43/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 3.2921e-06 - val_loss: 1.3249e-06\n",
      "Epoch 44/1000\n",
      "148/148 [==============================] - 0s 215us/step - loss: 2.8204e-06 - val_loss: 4.0411e-07\n",
      "Epoch 45/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.4280e-06 - val_loss: 1.3786e-08\n",
      "Epoch 46/1000\n",
      "148/148 [==============================] - 0s 192us/step - loss: 2.1104e-06 - val_loss: 1.8275e-07\n",
      "Epoch 47/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 1.8608e-06 - val_loss: 7.1454e-07\n",
      "Epoch 48/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6826e-06 - val_loss: 9.0782e-07\n",
      "Epoch 49/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.4889e-06 - val_loss: 1.3878e-06\n",
      "Epoch 50/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 1.3843e-06 - val_loss: 1.8321e-06\n",
      "Epoch 51/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.2485e-06 - val_loss: 3.1385e-06\n",
      "Epoch 52/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 1.1445e-06 - val_loss: 3.3922e-06\n",
      "Epoch 53/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0497e-06 - val_loss: 3.7897e-06\n",
      "Epoch 54/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.9592e-07 - val_loss: 4.2591e-06\n",
      "Epoch 55/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 6.9559e-07 - val_loss: 5.5280e-06\n",
      "Epoch 56/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.5943e-07 - val_loss: 4.8359e-06\n",
      "Epoch 57/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 5.8903e-07 - val_loss: 5.0556e-06\n",
      "Epoch 58/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 5.4334e-07 - val_loss: 4.9681e-06\n",
      "Epoch 59/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.6650e-07 - val_loss: 4.0687e-06\n",
      "Epoch 60/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.5102e-07 - val_loss: 2.6691e-06\n",
      "Epoch 61/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.0544e-07 - val_loss: 2.4460e-06\n",
      "Epoch 62/1000\n",
      "148/148 [==============================] - 0s 176us/step - loss: 3.8059e-07 - val_loss: 2.8656e-06\n",
      "Epoch 63/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.6583e-07 - val_loss: 2.9484e-06\n",
      "Epoch 64/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.4254e-07 - val_loss: 2.1989e-06\n",
      "Epoch 65/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.2573e-07 - val_loss: 1.7248e-06\n",
      "Epoch 66/1000\n",
      "148/148 [==============================] - 0s 173us/step - loss: 3.1058e-07 - val_loss: 1.7758e-06\n",
      "Epoch 67/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 3.0401e-07 - val_loss: 1.6608e-06\n",
      "Epoch 68/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.9392e-07 - val_loss: 1.1159e-06\n",
      "Epoch 69/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.7324e-07 - val_loss: 1.1334e-06\n",
      "Epoch 70/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.6660e-07 - val_loss: 1.2424e-06\n",
      "Epoch 71/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.4931e-07 - val_loss: 1.0383e-06\n",
      "Epoch 72/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4287e-07 - val_loss: 6.9170e-07\n",
      "Epoch 73/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.3392e-07 - val_loss: 7.8039e-07\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 158us/step - loss: 2.3248e-07 - val_loss: 9.3092e-07\n",
      "Epoch 75/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.1366e-07 - val_loss: 6.0474e-07\n",
      "Epoch 76/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0020e-07 - val_loss: 5.4260e-07\n",
      "Epoch 77/1000\n",
      "148/148 [==============================] - 0s 151us/step - loss: 1.9265e-07 - val_loss: 5.0994e-07\n",
      "Epoch 78/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8704e-07 - val_loss: 4.9225e-07\n",
      "Epoch 79/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7324e-07 - val_loss: 4.6651e-07\n",
      "Epoch 80/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6444e-07 - val_loss: 5.3412e-07\n",
      "Epoch 81/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.5481e-07 - val_loss: 3.9847e-07\n",
      "Epoch 82/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.5173e-07 - val_loss: 2.4214e-07\n",
      "Epoch 83/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.4428e-07 - val_loss: 2.5750e-07\n",
      "Epoch 84/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.4060e-07 - val_loss: 3.2530e-07\n",
      "Epoch 85/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3278e-07 - val_loss: 3.4050e-07\n",
      "Epoch 86/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2778e-07 - val_loss: 2.1513e-07\n",
      "Epoch 87/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2871e-07 - val_loss: 1.1904e-07\n",
      "Epoch 88/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2032e-07 - val_loss: 1.6763e-07\n",
      "Epoch 89/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2064e-07 - val_loss: 1.6559e-07\n",
      "Epoch 90/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1782e-07 - val_loss: 1.1436e-07\n",
      "Epoch 91/1000\n",
      "148/148 [==============================] - 0s 229us/step - loss: 1.1407e-07 - val_loss: 1.2888e-07\n",
      "Epoch 92/1000\n",
      "148/148 [==============================] - 0s 317us/step - loss: 1.1342e-07 - val_loss: 1.4081e-07\n",
      "Epoch 93/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 1.0944e-07 - val_loss: 1.1767e-07\n",
      "Epoch 94/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 1.0854e-07 - val_loss: 7.8659e-08\n",
      "Epoch 95/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.0446e-07 - val_loss: 6.3674e-08\n",
      "Epoch 96/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0348e-07 - val_loss: 7.1199e-08\n",
      "Epoch 97/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.0121e-07 - val_loss: 8.0640e-08\n",
      "Epoch 98/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 1.0316e-07 - val_loss: 4.6892e-08\n",
      "Epoch 99/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 9.7022e-08 - val_loss: 5.3911e-08\n",
      "Epoch 100/1000\n",
      "148/148 [==============================] - 0s 222us/step - loss: 9.6435e-08 - val_loss: 5.3360e-08\n",
      "Epoch 101/1000\n",
      "148/148 [==============================] - 0s 384us/step - loss: 9.3142e-08 - val_loss: 3.5015e-08\n",
      "Epoch 102/1000\n",
      "148/148 [==============================] - 0s 243us/step - loss: 9.3245e-08 - val_loss: 3.3086e-08\n",
      "Epoch 103/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 9.2763e-08 - val_loss: 5.4600e-08\n",
      "Epoch 104/1000\n",
      "148/148 [==============================] - 0s 603us/step - loss: 9.7722e-08 - val_loss: 5.3699e-08\n",
      "Epoch 105/1000\n",
      "148/148 [==============================] - 0s 398us/step - loss: 9.9362e-08 - val_loss: 1.5469e-08\n",
      "Epoch 106/1000\n",
      "148/148 [==============================] - 0s 283us/step - loss: 8.8008e-08 - val_loss: 2.6453e-08\n",
      "Epoch 107/1000\n",
      "148/148 [==============================] - 0s 371us/step - loss: 8.6087e-08 - val_loss: 3.7444e-08\n",
      "Epoch 108/1000\n",
      "148/148 [==============================] - 0s 499us/step - loss: 9.1893e-08 - val_loss: 2.7162e-08\n",
      "Epoch 109/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 8.8853e-08 - val_loss: 8.4713e-09\n",
      "Epoch 110/1000\n",
      "148/148 [==============================] - 0s 526us/step - loss: 8.7416e-08 - val_loss: 2.4987e-08\n",
      "Epoch 111/1000\n",
      "148/148 [==============================] - 0s 263us/step - loss: 8.6070e-08 - val_loss: 5.3900e-08\n",
      "Epoch 112/1000\n",
      "148/148 [==============================] - 0s 223us/step - loss: 8.4467e-08 - val_loss: 2.1681e-08\n",
      "Epoch 113/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 8.4120e-08 - val_loss: 1.0595e-08\n",
      "Epoch 114/1000\n",
      "148/148 [==============================] - 0s 418us/step - loss: 8.3612e-08 - val_loss: 1.3780e-08\n",
      "Epoch 115/1000\n",
      "148/148 [==============================] - 0s 263us/step - loss: 8.3190e-08 - val_loss: 2.7675e-08\n",
      "Epoch 116/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 8.0757e-08 - val_loss: 3.2293e-08\n",
      "Epoch 117/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.2909e-08 - val_loss: 1.6862e-08\n",
      "Epoch 118/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 8.0522e-08 - val_loss: 9.9694e-09\n",
      "Epoch 119/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.8049e-08 - val_loss: 1.5832e-08\n",
      "Epoch 120/1000\n",
      "148/148 [==============================] - 0s 243us/step - loss: 7.9659e-08 - val_loss: 3.0402e-08\n",
      "Epoch 121/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.8871e-08 - val_loss: 2.3758e-08\n",
      "Epoch 122/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 7.7821e-08 - val_loss: 1.2377e-08\n",
      "Epoch 123/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 8.1153e-08 - val_loss: 8.7647e-09\n",
      "Epoch 124/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.8661e-08 - val_loss: 1.1446e-08\n",
      "Epoch 125/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.9771e-08 - val_loss: 2.5960e-08\n",
      "Epoch 126/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.6591e-08 - val_loss: 1.5923e-08\n",
      "Epoch 127/1000\n",
      "148/148 [==============================] - 0s 136us/step - loss: 7.7214e-08 - val_loss: 1.8800e-08\n",
      "Epoch 128/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.5012e-08 - val_loss: 1.6360e-08\n",
      "Epoch 129/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 7.4857e-08 - val_loss: 1.6538e-08\n",
      "Epoch 130/1000\n",
      "148/148 [==============================] - 0s 445us/step - loss: 7.5025e-08 - val_loss: 1.7015e-08\n",
      "Epoch 131/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.5379e-08 - val_loss: 1.0460e-08\n",
      "Epoch 132/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.3966e-08 - val_loss: 1.3893e-08\n",
      "Epoch 133/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.5115e-08 - val_loss: 1.7531e-08\n",
      "Epoch 134/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 7.5427e-08 - val_loss: 1.5616e-08\n",
      "Epoch 135/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.2854e-08 - val_loss: 1.8022e-08\n",
      "Epoch 136/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.3396e-08 - val_loss: 1.3357e-08\n",
      "Epoch 137/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3987e-08 - val_loss: 1.1026e-08\n",
      "Epoch 138/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.4666e-08 - val_loss: 2.1473e-08\n",
      "Epoch 139/1000\n",
      "148/148 [==============================] - ETA: 0s - loss: 2.4784e-0 - 0s 128us/step - loss: 7.3088e-08 - val_loss: 1.6857e-08\n",
      "Epoch 140/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3471e-08 - val_loss: 8.8666e-09\n",
      "Epoch 141/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.2380e-08 - val_loss: 1.0051e-08\n",
      "Epoch 142/1000\n",
      "148/148 [==============================] - 0s 127us/step - loss: 7.3404e-08 - val_loss: 2.4984e-08\n",
      "Epoch 143/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3146e-08 - val_loss: 1.0210e-08\n",
      "Epoch 144/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.0906e-08 - val_loss: 1.0032e-08\n",
      "Epoch 145/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.1250e-08 - val_loss: 2.1577e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 6.8153e-08 - val_loss: 2.2288e-08\n",
      "Epoch 147/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.2486e-08 - val_loss: 9.4585e-09\n",
      "Epoch 148/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.1893e-08 - val_loss: 9.3903e-09\n",
      "Epoch 149/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.1263e-08 - val_loss: 2.4606e-08\n",
      "Epoch 150/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.3076e-08 - val_loss: 1.7106e-08\n",
      "Epoch 151/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 6.7657e-08 - val_loss: 1.4304e-08\n",
      "Epoch 152/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.0266e-08 - val_loss: 8.9134e-09\n",
      "Epoch 153/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.0440e-08 - val_loss: 1.0456e-08\n",
      "Epoch 154/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.7195e-08 - val_loss: 1.5694e-08\n",
      "Epoch 155/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 6.8245e-08 - val_loss: 1.1943e-08\n",
      "Epoch 156/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.8884e-08 - val_loss: 1.7890e-08\n",
      "Epoch 157/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.6584e-08 - val_loss: 1.0340e-08\n",
      "Epoch 158/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.7132e-08 - val_loss: 1.1704e-08\n",
      "Epoch 159/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.3807e-08 - val_loss: 1.0020e-08\n",
      "Epoch 160/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.4979e-08 - val_loss: 1.2027e-08\n",
      "Epoch 161/1000\n",
      "148/148 [==============================] - 0s 158us/step - loss: 6.8580e-08 - val_loss: 1.6961e-08\n",
      "Epoch 162/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.5122e-08 - val_loss: 1.0203e-08\n",
      "Epoch 163/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.3527e-08 - val_loss: 1.0123e-08\n",
      "Epoch 164/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.3941e-08 - val_loss: 1.4892e-08\n",
      "Epoch 165/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 6.3113e-08 - val_loss: 1.0598e-08\n",
      "Epoch 166/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.3949e-08 - val_loss: 1.1558e-08\n",
      "Epoch 167/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.4970e-08 - val_loss: 9.6817e-09\n",
      "Epoch 168/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.0494e-08 - val_loss: 1.0857e-08\n",
      "Epoch 169/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.9022e-08 - val_loss: 2.8546e-08\n",
      "Epoch 170/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.2730e-08 - val_loss: 8.9830e-09\n",
      "Epoch 171/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 6.0952e-08 - val_loss: 8.9331e-09\n",
      "Epoch 172/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.0724e-08 - val_loss: 3.0914e-08\n",
      "Epoch 173/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.2488e-08 - val_loss: 1.7836e-08\n",
      "Epoch 174/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.9438e-08 - val_loss: 9.8095e-09\n",
      "Epoch 175/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.0574e-08 - val_loss: 9.1455e-09\n",
      "Epoch 176/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.2555e-08 - val_loss: 2.0018e-08\n",
      "Epoch 177/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.9555e-08 - val_loss: 3.1728e-08\n",
      "Epoch 178/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.0342e-08 - val_loss: 1.0418e-08\n",
      "Epoch 179/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.9067e-08 - val_loss: 1.1668e-08\n",
      "Epoch 180/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.8453e-08 - val_loss: 1.7989e-08\n",
      "Epoch 181/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.7955e-08 - val_loss: 1.9064e-08\n",
      "Epoch 182/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.6999e-08 - val_loss: 9.3635e-09\n",
      "Epoch 183/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 5.6833e-08 - val_loss: 1.0070e-08\n",
      "Epoch 184/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.6796e-08 - val_loss: 1.2563e-08\n",
      "Epoch 185/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.7198e-08 - val_loss: 1.2910e-08\n",
      "Epoch 186/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.6786e-08 - val_loss: 1.3495e-08\n",
      "Epoch 187/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.5401e-08 - val_loss: 9.3230e-09\n",
      "Epoch 188/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.6868e-08 - val_loss: 1.2113e-08\n",
      "Epoch 189/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5282e-08 - val_loss: 1.4385e-08\n",
      "Epoch 190/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.5012e-08 - val_loss: 9.2952e-09\n",
      "Epoch 191/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.3844e-08 - val_loss: 1.0700e-08\n",
      "Epoch 192/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.5401e-08 - val_loss: 1.7862e-08\n",
      "Epoch 193/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.3424e-08 - val_loss: 1.1133e-08\n",
      "Epoch 194/1000\n",
      "148/148 [==============================] - 0s 145us/step - loss: 5.3882e-08 - val_loss: 9.1826e-09\n",
      "Epoch 195/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 5.4827e-08 - val_loss: 1.1931e-08\n",
      "Epoch 196/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.3712e-08 - val_loss: 1.1534e-08\n",
      "Epoch 197/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.2617e-08 - val_loss: 1.2567e-08\n",
      "Epoch 198/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.5945e-08 - val_loss: 1.5252e-08\n",
      "Epoch 199/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 5.5243e-08 - val_loss: 9.4993e-09\n",
      "Epoch 200/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5098e-08 - val_loss: 1.5811e-08\n",
      "Epoch 201/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.3022e-08 - val_loss: 9.4720e-09\n",
      "Epoch 202/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.6407e-08 - val_loss: 1.2353e-08\n",
      "Epoch 203/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.9167e-08 - val_loss: 2.2439e-08\n",
      "Epoch 204/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.6816e-08 - val_loss: 2.0791e-08\n",
      "Epoch 205/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.3926e-08 - val_loss: 2.0872e-08\n",
      "Epoch 206/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 5.1446e-08 - val_loss: 4.2179e-08\n",
      "Epoch 207/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.2750e-08 - val_loss: 1.7892e-08\n",
      "Epoch 208/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.1357e-08 - val_loss: 1.2637e-08\n",
      "Epoch 209/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.0298e-08 - val_loss: 4.4335e-08\n",
      "Epoch 210/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.1262e-08 - val_loss: 1.2590e-08\n",
      "Epoch 211/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.1766e-08 - val_loss: 1.0964e-08\n",
      "Epoch 212/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 5.3704e-08 - val_loss: 1.3269e-08\n",
      "Epoch 213/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.2410e-08 - val_loss: 9.5202e-09\n",
      "Epoch 214/1000\n",
      "148/148 [==============================] - 0s 151us/step - loss: 5.1881e-08 - val_loss: 9.5386e-09\n",
      "Epoch 215/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.9035e-08 - val_loss: 3.8096e-08\n",
      "Epoch 216/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 5.2808e-08 - val_loss: 1.1899e-08\n",
      "Epoch 217/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.0887e-08 - val_loss: 2.9919e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.0815e-08 - val_loss: 4.0048e-08\n",
      "Epoch 219/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.9073e-08 - val_loss: 2.8607e-08\n",
      "Epoch 220/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7516e-08 - val_loss: 1.4039e-08\n",
      "Epoch 221/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.9069e-08 - val_loss: 9.9693e-09\n",
      "Epoch 222/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.6659e-08 - val_loss: 1.7886e-08\n",
      "Epoch 223/1000\n",
      "148/148 [==============================] - 0s 125us/step - loss: 4.7774e-08 - val_loss: 1.2756e-08\n",
      "Epoch 224/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7607e-08 - val_loss: 1.1551e-08\n",
      "Epoch 225/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.6081e-08 - val_loss: 9.7848e-09\n",
      "Epoch 226/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7672e-08 - val_loss: 1.4047e-08\n",
      "Epoch 227/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.7448e-08 - val_loss: 2.5203e-08\n",
      "Epoch 228/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.8707e-08 - val_loss: 1.2923e-08\n",
      "Epoch 229/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.5226e-08 - val_loss: 1.0127e-08\n",
      "Epoch 230/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.7216e-08 - val_loss: 2.9999e-08\n",
      "Epoch 231/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7457e-08 - val_loss: 1.3703e-08\n",
      "Epoch 232/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.3537e-08 - val_loss: 1.4223e-08\n",
      "Epoch 233/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.6994e-08 - val_loss: 1.0416e-08\n",
      "Epoch 234/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.4987e-08 - val_loss: 1.7538e-08\n",
      "Epoch 235/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.7347e-08 - val_loss: 1.1597e-08\n",
      "Epoch 236/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.5688e-08 - val_loss: 1.1424e-08\n",
      "Epoch 237/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7381e-08 - val_loss: 1.2540e-08\n",
      "Epoch 238/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.3811e-08 - val_loss: 1.0838e-08\n",
      "Epoch 239/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 5.0194e-08 - val_loss: 1.0036e-08\n",
      "Epoch 240/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.7757e-08 - val_loss: 1.4933e-08\n",
      "Epoch 241/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.8079e-08 - val_loss: 1.2266e-08\n",
      "Epoch 242/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.3389e-08 - val_loss: 1.0456e-08\n",
      "Epoch 243/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.1682e-08 - val_loss: 1.1986e-08\n",
      "Epoch 244/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 4.1731e-08 - val_loss: 1.2572e-08\n",
      "Epoch 245/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.1567e-08 - val_loss: 1.0199e-08\n",
      "Epoch 246/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.7481e-08 - val_loss: 1.0188e-08\n",
      "Epoch 247/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.6628e-08 - val_loss: 9.6135e-09\n",
      "Epoch 248/1000\n",
      "148/148 [==============================] - 0s 153us/step - loss: 4.2309e-08 - val_loss: 3.1928e-08\n",
      "Epoch 249/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.2878e-08 - val_loss: 1.0932e-08\n",
      "Epoch 250/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.6736e-08 - val_loss: 1.4903e-08\n",
      "Epoch 251/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.8628e-08 - val_loss: 1.4472e-08\n",
      "Epoch 252/1000\n",
      "148/148 [==============================] - 0s 131us/step - loss: 4.3664e-08 - val_loss: 2.5743e-08\n",
      "Epoch 253/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8873e-08 - val_loss: 9.9537e-09\n",
      "Epoch 254/1000\n",
      "148/148 [==============================] - 0s 140us/step - loss: 4.3879e-08 - val_loss: 1.2136e-08\n",
      "Epoch 255/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.1780e-08 - val_loss: 1.1975e-08\n",
      "Epoch 256/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.1228e-08 - val_loss: 1.2773e-08\n",
      "Epoch 257/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 3.9961e-08 - val_loss: 1.0581e-08\n",
      "Epoch 258/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.0751e-08 - val_loss: 1.1854e-08\n",
      "Epoch 259/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.4493e-08 - val_loss: 1.1617e-08\n",
      "Epoch 260/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.3128e-08 - val_loss: 9.6912e-09\n",
      "Epoch 261/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.4080e-08 - val_loss: 1.7226e-08\n",
      "Epoch 262/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.7860e-08 - val_loss: 1.0561e-08\n",
      "Epoch 263/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.1301e-08 - val_loss: 1.0060e-08\n",
      "Epoch 264/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8985e-08 - val_loss: 1.3494e-08\n",
      "Epoch 265/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8888e-08 - val_loss: 1.9909e-08\n",
      "Epoch 266/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.7680e-08 - val_loss: 1.3817e-08\n",
      "Epoch 267/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.7775e-08 - val_loss: 1.0280e-08\n",
      "Epoch 268/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.9827e-08 - val_loss: 1.5982e-08\n",
      "Epoch 269/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.9531e-08 - val_loss: 1.3020e-08\n",
      "Epoch 270/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.8781e-08 - val_loss: 1.6276e-08\n",
      "Epoch 271/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.7575e-08 - val_loss: 1.2560e-08\n",
      "Epoch 272/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8380e-08 - val_loss: 1.9561e-08\n",
      "Epoch 273/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.7392e-08 - val_loss: 1.0487e-08\n",
      "Epoch 274/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.8378e-08 - val_loss: 1.0040e-08\n",
      "Epoch 275/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.6284e-08 - val_loss: 1.3633e-08\n",
      "Epoch 276/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.6894e-08 - val_loss: 1.0023e-08\n",
      "Epoch 277/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.7202e-08 - val_loss: 1.1289e-08\n",
      "Epoch 278/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 3.7232e-08 - val_loss: 1.1022e-08\n",
      "Epoch 279/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 3.7530e-08 - val_loss: 1.2841e-08\n",
      "Epoch 280/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 3.9863e-08 - val_loss: 1.2264e-08\n",
      "Epoch 281/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 4.5163e-08 - val_loss: 1.3312e-08\n",
      "Epoch 282/1000\n",
      "148/148 [==============================] - 0s 384us/step - loss: 3.7686e-08 - val_loss: 1.3187e-08\n",
      "Epoch 283/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.6924e-08 - val_loss: 1.2551e-08\n",
      "Epoch 284/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.6791e-08 - val_loss: 9.9098e-09\n",
      "Epoch 285/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 3.8047e-08 - val_loss: 3.0815e-08\n",
      "Epoch 286/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.5031e-08 - val_loss: 1.0532e-08\n",
      "Epoch 287/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.8146e-08 - val_loss: 1.2118e-08\n",
      "Epoch 288/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.5421e-08 - val_loss: 1.9079e-08\n",
      "Epoch 289/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.4738e-08 - val_loss: 1.1148e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.4158e-08 - val_loss: 1.1131e-08\n",
      "Epoch 291/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.4899e-08 - val_loss: 1.0388e-08\n",
      "Epoch 292/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.4577e-08 - val_loss: 1.0111e-08\n",
      "Epoch 293/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.3380e-08 - val_loss: 1.3301e-08\n",
      "Epoch 294/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.3743e-08 - val_loss: 1.0433e-08\n",
      "Epoch 295/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.4119e-08 - val_loss: 1.0197e-08\n",
      "Epoch 296/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.5287e-08 - val_loss: 1.2000e-08\n",
      "Epoch 297/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.5687e-08 - val_loss: 1.0333e-08\n",
      "Epoch 298/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.0939e-08 - val_loss: 1.2928e-08\n",
      "Epoch 299/1000\n",
      "148/148 [==============================] - 0s 129us/step - loss: 3.8115e-08 - val_loss: 1.0439e-08\n",
      "Epoch 300/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.7859e-08 - val_loss: 1.1360e-08\n",
      "Epoch 301/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.8133e-08 - val_loss: 1.1461e-08\n",
      "Epoch 302/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.1263e-08 - val_loss: 1.2011e-08\n",
      "Epoch 303/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.9249e-08 - val_loss: 1.2120e-08\n",
      "Epoch 304/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.5430e-08 - val_loss: 1.0349e-08\n",
      "Epoch 305/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.4034e-08 - val_loss: 1.1959e-08\n",
      "Epoch 306/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.2017e-08 - val_loss: 1.1145e-08\n",
      "Epoch 307/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.3538e-08 - val_loss: 1.4939e-08\n",
      "Epoch 308/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.2635e-08 - val_loss: 1.0682e-08\n",
      "Epoch 309/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.3890e-08 - val_loss: 9.8585e-09\n",
      "Epoch 310/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.3300e-08 - val_loss: 1.6001e-08\n",
      "Epoch 311/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.3372e-08 - val_loss: 1.0495e-08\n",
      "Epoch 312/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.6254e-08 - val_loss: 1.2845e-08\n",
      "Epoch 313/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4638e-08 - val_loss: 1.0060e-08\n",
      "Epoch 314/1000\n",
      "148/148 [==============================] - 0s 147us/step - loss: 3.1483e-08 - val_loss: 2.7744e-08\n",
      "Epoch 315/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1369e-08 - val_loss: 1.0794e-08\n",
      "Epoch 316/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.2839e-08 - val_loss: 2.1190e-08\n",
      "Epoch 317/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 2.9742e-08 - val_loss: 2.6779e-08\n",
      "Epoch 318/1000\n",
      "148/148 [==============================] - 0s 174us/step - loss: 3.0664e-08 - val_loss: 1.0515e-08\n",
      "Epoch 319/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 3.3518e-08 - val_loss: 1.1144e-08\n",
      "Epoch 320/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.0970e-08 - val_loss: 1.3048e-08\n",
      "Epoch 321/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.5104e-08 - val_loss: 1.0698e-08\n",
      "Epoch 322/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.9501e-08 - val_loss: 1.0412e-08\n",
      "Epoch 323/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.0763e-08 - val_loss: 1.6116e-08\n",
      "Epoch 324/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.9509e-08 - val_loss: 1.3639e-08\n",
      "Epoch 325/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.7926e-08 - val_loss: 1.0697e-08\n",
      "Epoch 326/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.0514e-08 - val_loss: 1.0955e-08\n",
      "Epoch 327/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.0339e-08 - val_loss: 1.1636e-08\n",
      "Epoch 328/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 2.9920e-08 - val_loss: 1.1232e-08\n",
      "Epoch 329/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.9045e-08 - val_loss: 1.1629e-08\n",
      "Epoch 330/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7653e-08 - val_loss: 1.8871e-08\n",
      "Epoch 331/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.9551e-08 - val_loss: 1.1167e-08\n",
      "Epoch 332/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.4996e-08 - val_loss: 1.1243e-08\n",
      "Epoch 333/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8815e-08 - val_loss: 1.3404e-08\n",
      "Epoch 334/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 3.1274e-08 - val_loss: 2.0720e-08\n",
      "Epoch 335/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 2.7948e-08 - val_loss: 1.4777e-08\n",
      "Epoch 336/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.7103e-08 - val_loss: 2.5222e-08\n",
      "Epoch 337/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.0140e-08 - val_loss: 3.8584e-08\n",
      "Epoch 338/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.6671e-08 - val_loss: 1.0419e-08\n",
      "Epoch 339/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.5018e-08 - val_loss: 1.2315e-08\n",
      "Epoch 340/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.4683e-08 - val_loss: 2.0812e-08\n",
      "Epoch 341/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.4049e-08 - val_loss: 1.0184e-08\n",
      "Epoch 342/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.3758e-08 - val_loss: 1.0541e-08\n",
      "Epoch 343/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4947e-08 - val_loss: 1.0844e-08\n",
      "Epoch 344/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.4411e-08 - val_loss: 1.5310e-08\n",
      "Epoch 345/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.3994e-08 - val_loss: 1.4872e-08\n",
      "Epoch 346/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.6153e-08 - val_loss: 1.6478e-08\n",
      "Epoch 347/1000\n",
      "148/148 [==============================] - 0s 236us/step - loss: 2.3815e-08 - val_loss: 1.4424e-08\n",
      "Epoch 348/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 2.7082e-08 - val_loss: 2.5356e-08\n",
      "Epoch 349/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.9644e-08 - val_loss: 1.5911e-08\n",
      "Epoch 350/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.5515e-08 - val_loss: 1.5463e-08\n",
      "Epoch 351/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.5396e-08 - val_loss: 2.2764e-08\n",
      "Epoch 352/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.9249e-08 - val_loss: 1.9659e-08\n",
      "Epoch 353/1000\n",
      "148/148 [==============================] - 0s 188us/step - loss: 2.8110e-08 - val_loss: 1.0591e-08\n",
      "Epoch 354/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.5839e-08 - val_loss: 1.0604e-08\n",
      "Epoch 355/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.3443e-08 - val_loss: 1.1164e-08\n",
      "Epoch 356/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.5508e-08 - val_loss: 1.1611e-08\n",
      "Epoch 357/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.4582e-08 - val_loss: 1.0569e-08\n",
      "Epoch 358/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.9343e-08 - val_loss: 1.1299e-08\n",
      "Epoch 359/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.7288e-08 - val_loss: 1.1051e-08\n",
      "Epoch 360/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.1886e-08 - val_loss: 1.0535e-08\n",
      "Epoch 361/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.5329e-08 - val_loss: 1.0736e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.0287e-08 - val_loss: 1.0428e-08\n",
      "Epoch 363/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1553e-08 - val_loss: 1.4710e-08\n",
      "Epoch 364/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.0751e-08 - val_loss: 1.1088e-08\n",
      "Epoch 365/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.0146e-08 - val_loss: 1.0561e-08\n",
      "Epoch 366/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9816e-08 - val_loss: 1.5780e-08\n",
      "Epoch 367/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.9506e-08 - val_loss: 1.2236e-08\n",
      "Epoch 368/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9195e-08 - val_loss: 1.0542e-08\n",
      "Epoch 369/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0884e-08 - val_loss: 1.2013e-08\n",
      "Epoch 370/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2612e-08 - val_loss: 1.0729e-08\n",
      "Epoch 371/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.7221e-08 - val_loss: 1.6643e-08\n",
      "Epoch 372/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.1821e-08 - val_loss: 2.2338e-08\n",
      "Epoch 373/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0143e-08 - val_loss: 1.2575e-08\n",
      "Epoch 374/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.9055e-08 - val_loss: 1.1730e-08\n",
      "Epoch 375/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.9076e-08 - val_loss: 1.1410e-08\n",
      "Epoch 376/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 1.8647e-08 - val_loss: 1.2103e-08\n",
      "Epoch 377/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8365e-08 - val_loss: 1.2341e-08\n",
      "Epoch 378/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8411e-08 - val_loss: 1.1589e-08\n",
      "Epoch 379/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.7294e-08 - val_loss: 1.0630e-08\n",
      "Epoch 380/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8678e-08 - val_loss: 1.3202e-08\n",
      "Epoch 381/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8017e-08 - val_loss: 1.2628e-08\n",
      "Epoch 382/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8293e-08 - val_loss: 1.2033e-08\n",
      "Epoch 383/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7100e-08 - val_loss: 1.2165e-08\n",
      "Epoch 384/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6296e-08 - val_loss: 1.5772e-08\n",
      "Epoch 385/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.6325e-08 - val_loss: 1.2791e-08\n",
      "Epoch 386/1000\n",
      "148/148 [==============================] - 0s 131us/step - loss: 1.9248e-08 - val_loss: 1.0855e-08\n",
      "Epoch 387/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.9518e-08 - val_loss: 1.0795e-08\n",
      "Epoch 388/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5153e-08 - val_loss: 2.1406e-08\n",
      "Epoch 389/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.7492e-08 - val_loss: 2.4827e-08\n",
      "Epoch 390/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7374e-08 - val_loss: 1.7647e-08\n",
      "Epoch 391/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.8736e-08 - val_loss: 1.0691e-08\n",
      "Epoch 392/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.4940e-08 - val_loss: 1.2175e-08\n",
      "Epoch 393/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9595e-08 - val_loss: 1.4452e-08\n",
      "Epoch 394/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.5997e-08 - val_loss: 1.1580e-08\n",
      "Epoch 395/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 1.5421e-08 - val_loss: 1.7518e-08\n",
      "Epoch 396/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5807e-08 - val_loss: 2.4914e-08\n",
      "Epoch 397/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.5335e-08 - val_loss: 1.6426e-08\n",
      "Epoch 398/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.8682e-08 - val_loss: 1.1274e-08\n",
      "Epoch 399/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5494e-08 - val_loss: 1.1621e-08\n",
      "Epoch 400/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5888e-08 - val_loss: 1.1366e-08\n",
      "Epoch 401/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3983e-08 - val_loss: 1.1945e-08\n",
      "Epoch 402/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3870e-08 - val_loss: 1.1769e-08\n",
      "Epoch 403/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 1.3848e-08 - val_loss: 1.1826e-08\n",
      "Epoch 404/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.3141e-08 - val_loss: 1.1131e-08\n",
      "Epoch 405/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4069e-08 - val_loss: 1.1000e-08\n",
      "Epoch 406/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3115e-08 - val_loss: 1.1340e-08\n",
      "Epoch 407/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4720e-08 - val_loss: 1.3988e-08\n",
      "Epoch 408/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3077e-08 - val_loss: 1.5573e-08\n",
      "Epoch 409/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7148e-08 - val_loss: 1.0659e-08\n",
      "Epoch 410/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4670e-08 - val_loss: 1.9752e-08\n",
      "Epoch 411/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6717e-08 - val_loss: 1.2534e-08\n",
      "Epoch 412/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.5079e-08 - val_loss: 1.1686e-08\n",
      "Epoch 413/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.7427e-08 - val_loss: 1.0830e-08\n",
      "Epoch 414/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 2.6414e-08 - val_loss: 1.1091e-08\n",
      "Epoch 415/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.0768e-08 - val_loss: 1.1698e-08\n",
      "Epoch 416/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8514e-08 - val_loss: 1.1330e-08\n",
      "Epoch 417/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.9958e-08 - val_loss: 1.1486e-08\n",
      "Epoch 418/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7413e-08 - val_loss: 1.1038e-08\n",
      "Epoch 419/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4398e-08 - val_loss: 1.1148e-08\n",
      "Epoch 420/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.2749e-08 - val_loss: 1.1271e-08\n",
      "Epoch 421/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.8140e-08 - val_loss: 1.1047e-08\n",
      "Epoch 422/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.8907e-08 - val_loss: 1.1110e-08\n",
      "Epoch 423/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.6307e-08 - val_loss: 1.3745e-08\n",
      "Epoch 424/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.3500e-08 - val_loss: 1.7042e-08\n",
      "Epoch 425/1000\n",
      "148/148 [==============================] - 0s 192us/step - loss: 5.6288e-08 - val_loss: 1.8730e-08\n",
      "Epoch 426/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.3694e-08 - val_loss: 1.1439e-08\n",
      "Epoch 427/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2415e-08 - val_loss: 1.4659e-08\n",
      "Epoch 428/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.2434e-08 - val_loss: 1.7950e-08\n",
      "Epoch 429/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.1048e-08 - val_loss: 2.1584e-08\n",
      "Epoch 430/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6226e-08 - val_loss: 1.4429e-08\n",
      "Epoch 431/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 1.3514e-08 - val_loss: 1.1950e-08\n",
      "Epoch 432/1000\n",
      "148/148 [==============================] - 0s 179us/step - loss: 1.2544e-08 - val_loss: 1.1200e-08\n",
      "Epoch 433/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.6039e-08 - val_loss: 1.6397e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.6458e-08 - val_loss: 1.3913e-08\n",
      "Epoch 435/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5266e-08 - val_loss: 1.2441e-08\n",
      "Epoch 436/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.8773e-08 - val_loss: 1.2896e-08\n",
      "Epoch 437/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 8.4293e-08 - val_loss: 1.1915e-08\n",
      "Epoch 438/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.5685e-08 - val_loss: 1.2886e-08\n",
      "Epoch 439/1000\n",
      "148/148 [==============================] - 0s 431us/step - loss: 2.3572e-08 - val_loss: 1.2019e-08\n",
      "Epoch 440/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.2981e-08 - val_loss: 1.1182e-08\n",
      "Epoch 441/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.2417e-08 - val_loss: 1.1467e-08\n",
      "Epoch 442/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0765e-08 - val_loss: 1.2796e-08\n",
      "Epoch 443/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.0645e-08 - val_loss: 1.7704e-08\n",
      "Epoch 444/1000\n",
      "148/148 [==============================] - 0s 125us/step - loss: 9.8996e-09 - val_loss: 1.2791e-08\n",
      "Epoch 445/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.0933e-08 - val_loss: 1.1315e-08\n",
      "Epoch 446/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.7005e-09 - val_loss: 1.2871e-08\n",
      "Epoch 447/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.9701e-09 - val_loss: 1.1830e-08\n",
      "Epoch 448/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2198e-08 - val_loss: 1.3804e-08\n",
      "Epoch 449/1000\n",
      "148/148 [==============================] - 0s 125us/step - loss: 1.3614e-08 - val_loss: 1.1772e-08\n",
      "Epoch 450/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3579e-08 - val_loss: 1.2265e-08\n",
      "Epoch 451/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3734e-08 - val_loss: 1.5826e-08\n",
      "Epoch 452/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7312e-08 - val_loss: 1.2629e-08\n",
      "Epoch 453/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.7322e-08 - val_loss: 1.2536e-08\n",
      "Epoch 454/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 2.2387e-08 - val_loss: 1.1849e-08\n",
      "Epoch 455/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5108e-08 - val_loss: 1.1932e-08\n",
      "Epoch 456/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.1722e-08 - val_loss: 1.2358e-08\n",
      "Epoch 457/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.4472e-08 - val_loss: 1.2802e-08\n",
      "Epoch 458/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.2184e-08 - val_loss: 1.2030e-08\n",
      "Epoch 459/1000\n",
      "148/148 [==============================] - 0s 140us/step - loss: 1.9366e-08 - val_loss: 1.1999e-08\n",
      "Epoch 460/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.4084e-08 - val_loss: 1.2849e-08\n",
      "Epoch 461/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.6753e-08 - val_loss: 1.1420e-08\n",
      "Epoch 462/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6349e-08 - val_loss: 1.2113e-08\n",
      "Epoch 463/1000\n",
      "148/148 [==============================] - 0s 154us/step - loss: 2.1697e-08 - val_loss: 1.5737e-08\n",
      "Epoch 464/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.0546e-08 - val_loss: 1.2124e-08\n",
      "Epoch 465/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.6319e-08 - val_loss: 1.2943e-08\n",
      "Epoch 466/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.3530e-08 - val_loss: 1.2466e-08\n",
      "Epoch 467/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.3966e-08 - val_loss: 1.2690e-08\n",
      "Epoch 468/1000\n",
      "148/148 [==============================] - 0s 136us/step - loss: 2.0684e-08 - val_loss: 2.8652e-08\n",
      "Epoch 469/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 3.3339e-08 - val_loss: 1.5124e-08\n",
      "Epoch 470/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5310e-08 - val_loss: 1.2676e-08\n",
      "Epoch 471/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.5159e-09 - val_loss: 1.5522e-08\n",
      "Epoch 472/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2288e-08 - val_loss: 1.1834e-08\n",
      "Epoch 473/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3358e-08 - val_loss: 1.2225e-08\n",
      "Epoch 474/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.1743e-08 - val_loss: 1.3944e-08\n",
      "Epoch 475/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.6836e-09 - val_loss: 1.2254e-08\n",
      "Epoch 476/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3503e-08 - val_loss: 1.2008e-08\n",
      "Epoch 477/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.2134e-08 - val_loss: 1.4424e-08\n",
      "Epoch 478/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7235e-08 - val_loss: 1.2100e-08\n",
      "Epoch 479/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.9889e-08 - val_loss: 1.4278e-08\n",
      "Epoch 480/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 6.7141e-08 - val_loss: 1.2058e-08\n",
      "Epoch 481/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.7041e-08 - val_loss: 1.9497e-08\n",
      "Epoch 482/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.6384e-08 - val_loss: 1.4348e-08\n",
      "Epoch 483/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.7531e-07 - val_loss: 1.6156e-08\n",
      "Epoch 484/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.5577e-07 - val_loss: 1.2885e-08\n",
      "Epoch 485/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.1957e-08 - val_loss: 2.7800e-08\n",
      "Epoch 486/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.2786e-08 - val_loss: 1.3253e-08\n",
      "Epoch 487/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 7.2592e-08 - val_loss: 1.1315e-08\n",
      "Epoch 488/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9439e-08 - val_loss: 1.5000e-08\n",
      "Epoch 489/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.6222e-08 - val_loss: 1.2416e-08\n",
      "Epoch 490/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1382e-08 - val_loss: 1.2674e-08\n",
      "Epoch 491/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.3863e-09 - val_loss: 1.2314e-08\n",
      "Epoch 492/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 8.3862e-09 - val_loss: 1.3193e-08\n",
      "Epoch 493/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.3670e-09 - val_loss: 1.2521e-08\n",
      "Epoch 494/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 7.5984e-09 - val_loss: 1.2667e-08\n",
      "Epoch 495/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.2068e-09 - val_loss: 2.0854e-08\n",
      "Epoch 496/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 9.0224e-09 - val_loss: 1.3357e-08\n",
      "Epoch 497/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.2668e-09 - val_loss: 1.5871e-08\n",
      "Epoch 498/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 8.2638e-09 - val_loss: 1.5956e-08\n",
      "Epoch 499/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.8793e-09 - val_loss: 1.3145e-08\n",
      "Epoch 500/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.6199e-09 - val_loss: 1.2776e-08\n",
      "Epoch 501/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.8595e-09 - val_loss: 1.3036e-08\n",
      "Epoch 502/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.6286e-09 - val_loss: 1.2260e-08\n",
      "Epoch 503/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.8277e-09 - val_loss: 1.4339e-08\n",
      "Epoch 504/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.6448e-09 - val_loss: 1.2419e-08\n",
      "Epoch 505/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.9591e-09 - val_loss: 1.6976e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.9321e-09 - val_loss: 1.3453e-08\n",
      "Epoch 507/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0134e-08 - val_loss: 1.7349e-08\n",
      "Epoch 508/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.0760e-09 - val_loss: 1.4265e-08\n",
      "Epoch 509/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.2158e-08 - val_loss: 2.6485e-08\n",
      "Epoch 510/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 1.2402e-08 - val_loss: 2.1901e-08\n",
      "Epoch 511/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1269e-08 - val_loss: 2.3649e-08\n",
      "Epoch 512/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0527e-08 - val_loss: 1.2035e-08\n",
      "Epoch 513/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.5244e-09 - val_loss: 1.2742e-08\n",
      "Epoch 514/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.0369e-09 - val_loss: 1.6089e-08\n",
      "Epoch 515/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 6.7220e-09 - val_loss: 1.3249e-08\n",
      "Epoch 516/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.4307e-09 - val_loss: 2.0141e-08\n",
      "Epoch 517/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.5647e-09 - val_loss: 1.4649e-08\n",
      "Epoch 518/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.8606e-09 - val_loss: 2.3431e-08\n",
      "Epoch 519/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 6.8855e-09 - val_loss: 1.5024e-08\n",
      "Epoch 520/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.8736e-09 - val_loss: 5.4075e-08\n",
      "Epoch 521/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1268e-08 - val_loss: 1.5492e-08\n",
      "Epoch 522/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.0023e-08 - val_loss: 2.7071e-08\n",
      "Epoch 523/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0207e-08 - val_loss: 1.3438e-08\n",
      "Epoch 524/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2866e-08 - val_loss: 1.8568e-08\n",
      "Epoch 525/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4352e-08 - val_loss: 1.2699e-08\n",
      "Epoch 526/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.6972e-09 - val_loss: 1.2833e-08\n",
      "Epoch 527/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9924e-08 - val_loss: 1.6251e-08\n",
      "Epoch 528/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1795e-08 - val_loss: 1.5212e-08\n",
      "Epoch 529/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.5858e-09 - val_loss: 1.2814e-08\n",
      "Epoch 530/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.5433e-09 - val_loss: 1.7883e-08\n",
      "Epoch 531/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3740e-08 - val_loss: 1.2452e-08\n",
      "Epoch 532/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.6692e-08 - val_loss: 1.4667e-08\n",
      "Epoch 533/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 2.9386e-08 - val_loss: 2.2470e-08\n",
      "Epoch 534/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.2033e-08 - val_loss: 1.6621e-08\n",
      "Epoch 535/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.0175e-08 - val_loss: 1.4204e-08\n",
      "Epoch 536/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.3189e-08 - val_loss: 2.0259e-08\n",
      "Epoch 537/1000\n",
      "148/148 [==============================] - 0s 127us/step - loss: 5.2242e-08 - val_loss: 1.3405e-08\n",
      "Epoch 538/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 6.2082e-08 - val_loss: 1.3947e-08\n",
      "Epoch 539/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.0360e-08 - val_loss: 2.7170e-08\n",
      "Epoch 540/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.9554e-08 - val_loss: 1.7069e-08\n",
      "Epoch 541/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2195e-07 - val_loss: 3.8187e-08\n",
      "Epoch 542/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2506e-07 - val_loss: 1.6322e-08\n",
      "Epoch 543/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3359e-07 - val_loss: 1.5781e-08\n",
      "Epoch 544/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.3302e-07 - val_loss: 1.4489e-08\n",
      "Epoch 545/1000\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.8338e-0 - 0s 135us/step - loss: 1.7543e-06 - val_loss: 1.8782e-08\n",
      "Epoch 546/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.3443e-06 - val_loss: 3.7533e-07\n",
      "Epoch 547/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.9512e-05 - val_loss: 1.3712e-08\n",
      "Epoch 548/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.0049e-05 - val_loss: 2.4530e-08\n",
      "Epoch 549/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.1937e-05 - val_loss: 6.3306e-07\n",
      "Epoch 550/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.9449e-05 - val_loss: 8.0627e-08\n",
      "Epoch 551/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.8077e-05 - val_loss: 1.8606e-08\n",
      "Epoch 552/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1357e-05 - val_loss: 8.3163e-08\n",
      "Epoch 553/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7599e-05 - val_loss: 8.8247e-07\n",
      "Epoch 554/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.8632e-05 - val_loss: 8.0124e-08\n",
      "Epoch 555/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.2465e-05 - val_loss: 4.6940e-07\n",
      "Epoch 556/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1273e-05 - val_loss: 2.0137e-07\n",
      "Epoch 557/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 5.3091e-06 - val_loss: 8.3976e-07\n",
      "Epoch 558/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.6677e-06 - val_loss: 2.5678e-08\n",
      "Epoch 559/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.5749e-06 - val_loss: 2.2107e-07\n",
      "Epoch 560/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.5278e-07 - val_loss: 1.1956e-07\n",
      "Epoch 561/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.5200e-07 - val_loss: 2.2731e-07\n",
      "Epoch 562/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.4440e-07 - val_loss: 1.2177e-07\n",
      "Epoch 563/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.5558e-07 - val_loss: 1.0343e-08\n",
      "Epoch 564/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4459e-07 - val_loss: 3.4711e-08\n",
      "Epoch 565/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 1.3977e-07 - val_loss: 2.9744e-08\n",
      "Epoch 566/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.2100e-07 - val_loss: 1.5579e-08\n",
      "Epoch 567/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.4055e-07 - val_loss: 1.3212e-08\n",
      "Epoch 568/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.2454e-07 - val_loss: 1.6098e-08\n",
      "Epoch 569/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.5031e-08 - val_loss: 3.4813e-08\n",
      "Epoch 570/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 8.0968e-08 - val_loss: 4.0255e-08\n",
      "Epoch 571/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 3.8001e-08 - val_loss: 3.4393e-08\n",
      "Epoch 572/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 9.8659e-08 - val_loss: 2.4141e-08\n",
      "Epoch 573/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 1.5913e-07 - val_loss: 3.3896e-08\n",
      "Epoch 574/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5894e-07 - val_loss: 4.5785e-08\n",
      "Epoch 575/1000\n",
      "148/148 [==============================] - 0s 172us/step - loss: 1.8419e-07 - val_loss: 2.2680e-08\n",
      "Epoch 576/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2905e-07 - val_loss: 3.0273e-08\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 135us/step - loss: 6.4520e-08 - val_loss: 1.9779e-08\n",
      "Epoch 578/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.3512e-08 - val_loss: 7.4260e-08\n",
      "Epoch 579/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.3604e-08 - val_loss: 2.8007e-08\n",
      "Epoch 580/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.8927e-08 - val_loss: 1.5641e-08\n",
      "Epoch 581/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 6.4228e-08 - val_loss: 2.5598e-08\n",
      "Epoch 582/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.7216e-08 - val_loss: 4.3021e-08\n",
      "Epoch 583/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.9463e-08 - val_loss: 1.5652e-08\n",
      "Epoch 584/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.4768e-08 - val_loss: 2.8112e-08\n",
      "Epoch 585/1000\n",
      "148/148 [==============================] - 0s 153us/step - loss: 1.1231e-07 - val_loss: 1.6095e-08\n",
      "Epoch 586/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 9.9528e-08 - val_loss: 4.6387e-08\n",
      "Epoch 587/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 8.8159e-08 - val_loss: 1.8221e-08\n",
      "Epoch 588/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.9388e-07 - val_loss: 2.6868e-08\n",
      "Epoch 589/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.9469e-07 - val_loss: 1.9218e-08\n",
      "Epoch 590/1000\n",
      "148/148 [==============================] - 0s 126us/step - loss: 3.3077e-06 - val_loss: 1.5962e-07\n",
      "Epoch 591/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6048e-05 - val_loss: 5.4890e-07\n",
      "Epoch 592/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.5276e-06 - val_loss: 2.2404e-08\n",
      "Epoch 593/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.9733e-06 - val_loss: 3.1674e-08\n",
      "Epoch 594/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.3260e-06 - val_loss: 5.2852e-08\n",
      "Epoch 595/1000\n",
      "148/148 [==============================] - 0s 132us/step - loss: 1.1418e-06 - val_loss: 1.7727e-08\n",
      "Epoch 596/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.2893e-06 - val_loss: 1.4519e-07\n",
      "Epoch 597/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0928e-06 - val_loss: 2.2886e-08\n",
      "Epoch 598/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 5.9140e-07 - val_loss: 1.0511e-08\n",
      "Epoch 599/1000\n",
      "148/148 [==============================] - 0s 132us/step - loss: 3.8613e-07 - val_loss: 1.1148e-08\n",
      "Epoch 600/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6840e-07 - val_loss: 1.3121e-08\n",
      "Epoch 601/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.6328e-08 - val_loss: 2.5560e-08\n",
      "Epoch 602/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.2317e-08 - val_loss: 2.3150e-08\n",
      "Epoch 603/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.1727e-08 - val_loss: 1.2863e-07\n",
      "Epoch 604/1000\n",
      "148/148 [==============================] - 0s 136us/step - loss: 9.0589e-08 - val_loss: 1.8975e-08\n",
      "Epoch 605/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.8594e-08 - val_loss: 8.8291e-08\n",
      "Epoch 606/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.1860e-08 - val_loss: 1.7423e-08\n",
      "Epoch 607/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.6032e-08 - val_loss: 5.1582e-08\n",
      "Epoch 608/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.6995e-08 - val_loss: 2.3672e-08\n",
      "Epoch 609/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3972e-08 - val_loss: 1.6067e-08\n",
      "Epoch 610/1000\n",
      "148/148 [==============================] - 0s 350us/step - loss: 1.4586e-08 - val_loss: 3.3628e-08\n",
      "Epoch 611/1000\n",
      "148/148 [==============================] - 0s 290us/step - loss: 1.1856e-08 - val_loss: 1.5214e-08\n",
      "Epoch 612/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.1393e-08 - val_loss: 2.7260e-08\n",
      "Epoch 613/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1503e-08 - val_loss: 1.6737e-08\n",
      "Epoch 614/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2519e-08 - val_loss: 1.8320e-08\n",
      "Epoch 615/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.1857e-08 - val_loss: 1.8922e-08\n",
      "Epoch 616/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6704e-08 - val_loss: 4.0142e-08\n",
      "Epoch 617/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2350e-08 - val_loss: 1.6336e-08\n",
      "Epoch 618/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2049e-08 - val_loss: 3.3969e-08\n",
      "Epoch 619/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0382e-08 - val_loss: 3.3205e-08\n",
      "Epoch 620/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1707e-08 - val_loss: 1.6498e-08\n",
      "Epoch 621/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8756e-08 - val_loss: 4.9171e-08\n",
      "Epoch 622/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.0886e-09 - val_loss: 2.4049e-08\n",
      "Epoch 623/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1759e-08 - val_loss: 3.1223e-08\n",
      "Epoch 624/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3208e-08 - val_loss: 2.0031e-08\n",
      "Epoch 625/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 1.2340e-08 - val_loss: 2.5678e-08\n",
      "Epoch 626/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.9492e-09 - val_loss: 2.7141e-08\n",
      "Epoch 627/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0959e-08 - val_loss: 1.6982e-08\n",
      "Epoch 628/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.0500e-08 - val_loss: 4.0113e-08\n",
      "Epoch 629/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.1059e-09 - val_loss: 1.8405e-08\n",
      "Epoch 630/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.2591e-09 - val_loss: 4.5880e-08\n",
      "Epoch 631/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2919e-08 - val_loss: 1.6105e-08\n",
      "Epoch 632/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.3987e-09 - val_loss: 4.9485e-08\n",
      "Epoch 633/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2521e-08 - val_loss: 1.7151e-08\n",
      "Epoch 634/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0571e-08 - val_loss: 7.7787e-08\n",
      "Epoch 635/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.1664e-08 - val_loss: 1.7562e-08\n",
      "Epoch 636/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5088e-07 - val_loss: 3.4683e-08\n",
      "Epoch 637/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.2593e-07 - val_loss: 1.8281e-08\n",
      "Epoch 638/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.0389e-07 - val_loss: 2.4255e-08\n",
      "Epoch 639/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.7899e-07 - val_loss: 4.3130e-08\n",
      "Epoch 640/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 8.2269e-08 - val_loss: 3.3514e-08\n",
      "Epoch 641/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.5858e-08 - val_loss: 2.2248e-08\n",
      "Epoch 642/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 4.5451e-08 - val_loss: 6.3822e-08\n",
      "Epoch 643/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.8851e-08 - val_loss: 2.1218e-08\n",
      "Epoch 644/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.2390e-07 - val_loss: 5.9916e-08\n",
      "Epoch 645/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 9.4704e-07 - val_loss: 1.9735e-08\n",
      "Epoch 646/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.6269e-06 - val_loss: 1.1301e-07\n",
      "Epoch 647/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.9483e-06 - val_loss: 1.7781e-07\n",
      "Epoch 648/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 1.0353e-05 - val_loss: 3.5937e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.0030e-06 - val_loss: 2.7260e-08\n",
      "Epoch 650/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 4.4792e-06 - val_loss: 8.9012e-08\n",
      "Epoch 651/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.2483e-06 - val_loss: 1.8301e-08\n",
      "Epoch 652/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.5066e-06 - val_loss: 1.8228e-08\n",
      "Epoch 653/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.1050e-06 - val_loss: 2.6258e-08\n",
      "Epoch 654/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.3343e-06 - val_loss: 4.6646e-08\n",
      "Epoch 655/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.6208e-07 - val_loss: 4.5341e-08\n",
      "Epoch 656/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 1.5718e-06 - val_loss: 6.2215e-08\n",
      "Epoch 657/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4652e-06 - val_loss: 1.8993e-07\n",
      "Epoch 658/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.9931e-06 - val_loss: 2.0019e-08\n",
      "Epoch 659/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.8889e-06 - val_loss: 1.9415e-07\n",
      "Epoch 660/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 4.1211e-06 - val_loss: 2.5391e-08\n",
      "Epoch 661/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.3522e-06 - val_loss: 5.2503e-08\n",
      "Epoch 662/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.4318e-06 - val_loss: 1.2349e-07\n",
      "Epoch 663/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.6227e-06 - val_loss: 1.7132e-08\n",
      "Epoch 664/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2536e-06 - val_loss: 1.8378e-08\n",
      "Epoch 665/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 1.1861e-06 - val_loss: 1.4460e-08\n",
      "Epoch 666/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.3721e-07 - val_loss: 3.9132e-08\n",
      "Epoch 667/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.9275e-07 - val_loss: 2.7395e-08\n",
      "Epoch 668/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.5049e-07 - val_loss: 1.4609e-07\n",
      "Epoch 669/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.9438e-07 - val_loss: 3.9097e-08\n",
      "Epoch 670/1000\n",
      "148/148 [==============================] - 0s 159us/step - loss: 1.7683e-06 - val_loss: 1.1699e-07\n",
      "Epoch 671/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8912e-06 - val_loss: 2.0664e-08\n",
      "Epoch 672/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.5757e-06 - val_loss: 2.2264e-08\n",
      "Epoch 673/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.6414e-07 - val_loss: 3.5913e-08\n",
      "Epoch 674/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.4361e-07 - val_loss: 3.0848e-08\n",
      "Epoch 675/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 7.7150e-07 - val_loss: 1.8585e-07\n",
      "Epoch 676/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.5646e-07 - val_loss: 3.5400e-08\n",
      "Epoch 677/1000\n",
      "148/148 [==============================] - 0s 179us/step - loss: 3.0361e-06 - val_loss: 1.2787e-07\n",
      "Epoch 678/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.9276e-06 - val_loss: 1.6289e-07\n",
      "Epoch 679/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.2428e-06 - val_loss: 2.5965e-07\n",
      "Epoch 680/1000\n",
      "148/148 [==============================] - 0s 161us/step - loss: 2.4546e-06 - val_loss: 2.8461e-08\n",
      "Epoch 681/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.1742e-07 - val_loss: 3.9188e-08\n",
      "Epoch 682/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.6504e-06 - val_loss: 4.5800e-07\n",
      "Epoch 683/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 8.8364e-07 - val_loss: 1.9288e-08\n",
      "Epoch 684/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.0709e-07 - val_loss: 2.4065e-08\n",
      "Epoch 685/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.2160e-07 - val_loss: 1.9113e-07\n",
      "Epoch 686/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.7869e-07 - val_loss: 4.1657e-08\n",
      "Epoch 687/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.2534e-07 - val_loss: 3.1559e-07\n",
      "Epoch 688/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.9772e-08 - val_loss: 4.5818e-08\n",
      "Epoch 689/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.6369e-08 - val_loss: 5.7349e-08\n",
      "Epoch 690/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.4460e-08 - val_loss: 2.8351e-08\n",
      "Epoch 691/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.2674e-07 - val_loss: 1.7137e-08\n",
      "Epoch 692/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.3256e-07 - val_loss: 8.1944e-08\n",
      "Epoch 693/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.0932e-07 - val_loss: 1.3517e-08\n",
      "Epoch 694/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0262e-06 - val_loss: 1.9844e-08\n",
      "Epoch 695/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3001e-06 - val_loss: 3.1852e-08\n",
      "Epoch 696/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.6503e-07 - val_loss: 1.9843e-08\n",
      "Epoch 697/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.3157e-07 - val_loss: 1.0949e-07\n",
      "Epoch 698/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.0712e-07 - val_loss: 4.2838e-08\n",
      "Epoch 699/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.6482e-06 - val_loss: 3.7086e-08\n",
      "Epoch 700/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.1051e-06 - val_loss: 9.8499e-08\n",
      "Epoch 701/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.0509e-06 - val_loss: 1.0729e-07\n",
      "Epoch 702/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 7.7256e-06 - val_loss: 1.7577e-07\n",
      "Epoch 703/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.3999e-05 - val_loss: 5.1734e-06\n",
      "Epoch 704/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.3885e-05 - val_loss: 1.6037e-06\n",
      "Epoch 705/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7698e-05 - val_loss: 2.7119e-06\n",
      "Epoch 706/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7472e-06 - val_loss: 2.8624e-07\n",
      "Epoch 707/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2551e-06 - val_loss: 8.8807e-08\n",
      "Epoch 708/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 5.8309e-07 - val_loss: 4.6858e-07\n",
      "Epoch 709/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4523e-06 - val_loss: 1.1903e-07\n",
      "Epoch 710/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 4.1128e-06 - val_loss: 6.9291e-07\n",
      "Epoch 711/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.7638e-06 - val_loss: 3.3396e-08\n",
      "Epoch 712/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 9.9555e-07 - val_loss: 8.1690e-08\n",
      "Epoch 713/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.6642e-07 - val_loss: 1.1839e-07\n",
      "Epoch 714/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6524e-07 - val_loss: 2.7509e-08\n",
      "Epoch 715/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 5.6800e-08 - val_loss: 4.3243e-08\n",
      "Epoch 716/1000\n",
      "148/148 [==============================] - 0s 167us/step - loss: 2.3804e-08 - val_loss: 2.8173e-08\n",
      "Epoch 717/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1367e-08 - val_loss: 3.1343e-08\n",
      "Epoch 718/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 8.8850e-09 - val_loss: 1.0926e-07\n",
      "Epoch 719/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.6189e-09 - val_loss: 1.6584e-08\n",
      "Epoch 720/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.4285e-09 - val_loss: 1.7807e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 7.0326e-09 - val_loss: 4.9200e-08\n",
      "Epoch 722/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 8.2026e-09 - val_loss: 2.3815e-08\n",
      "Epoch 723/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.6889e-09 - val_loss: 3.1675e-08\n",
      "Epoch 724/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 9.7134e-09 - val_loss: 4.7726e-08\n",
      "Epoch 725/1000\n",
      "148/148 [==============================] - 0s 127us/step - loss: 8.0064e-09 - val_loss: 1.8115e-08\n",
      "Epoch 726/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.2407e-09 - val_loss: 4.7714e-08\n",
      "Epoch 727/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.8970e-09 - val_loss: 3.8529e-08\n",
      "Epoch 728/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.1836e-09 - val_loss: 3.8227e-08\n",
      "Epoch 729/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.9526e-09 - val_loss: 2.5627e-08\n",
      "Epoch 730/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.2575e-09 - val_loss: 4.4551e-08\n",
      "Epoch 731/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.9691e-09 - val_loss: 2.8560e-08\n",
      "Epoch 732/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 6.1799e-09 - val_loss: 3.9598e-08\n",
      "Epoch 733/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.3970e-09 - val_loss: 2.3634e-08\n",
      "Epoch 734/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.5984e-09 - val_loss: 4.3009e-08\n",
      "Epoch 735/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 7.2951e-09 - val_loss: 2.6665e-08\n",
      "Epoch 736/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.7919e-09 - val_loss: 3.2800e-08\n",
      "Epoch 737/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.1223e-09 - val_loss: 4.5048e-08\n",
      "Epoch 738/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.9545e-09 - val_loss: 2.7028e-08\n",
      "Epoch 739/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.7609e-09 - val_loss: 3.4394e-08\n",
      "Epoch 740/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.9433e-09 - val_loss: 2.6990e-08\n",
      "Epoch 741/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.6535e-09 - val_loss: 3.1011e-08\n",
      "Epoch 742/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.8246e-09 - val_loss: 3.0219e-08\n",
      "Epoch 743/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.0456e-09 - val_loss: 4.0490e-08\n",
      "Epoch 744/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2586e-08 - val_loss: 2.8634e-08\n",
      "Epoch 745/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.0468e-08 - val_loss: 2.4819e-08\n",
      "Epoch 746/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.2953e-08 - val_loss: 8.8977e-08\n",
      "Epoch 747/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 9.3137e-08 - val_loss: 1.8065e-08\n",
      "Epoch 748/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4542e-07 - val_loss: 5.0187e-08\n",
      "Epoch 749/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.4186e-06 - val_loss: 8.8806e-08\n",
      "Epoch 750/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.2570e-06 - val_loss: 2.0009e-08\n",
      "Epoch 751/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.3342e-06 - val_loss: 4.1513e-07\n",
      "Epoch 752/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 7.9049e-06 - val_loss: 5.1204e-07\n",
      "Epoch 753/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.0347e-05 - val_loss: 1.3682e-06\n",
      "Epoch 754/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2210e-05 - val_loss: 1.4059e-06\n",
      "Epoch 755/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0276e-05 - val_loss: 8.7709e-08\n",
      "Epoch 756/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 3.3884e-05 - val_loss: 4.1759e-06\n",
      "Epoch 757/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 8.0947e-05 - val_loss: 7.0622e-08\n",
      "Epoch 758/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.7717e-05 - val_loss: 2.4453e-07\n",
      "Epoch 759/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.4633e-05 - val_loss: 8.4714e-06\n",
      "Epoch 760/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.4262e-05 - val_loss: 5.3076e-07\n",
      "Epoch 761/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 8.7340e-06 - val_loss: 6.4140e-06\n",
      "Epoch 762/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.1382e-06 - val_loss: 1.7984e-06\n",
      "Epoch 763/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.1765e-06 - val_loss: 1.0129e-07\n",
      "Epoch 764/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.0586e-06 - val_loss: 4.8828e-07\n",
      "Epoch 765/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1242e-06 - val_loss: 2.2948e-08\n",
      "Epoch 766/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.3853e-06 - val_loss: 1.7707e-07\n",
      "Epoch 767/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.3920e-06 - val_loss: 5.5534e-08\n",
      "Epoch 768/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4246e-06 - val_loss: 1.5211e-07\n",
      "Epoch 769/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1187e-06 - val_loss: 2.6895e-07\n",
      "Epoch 770/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.4204e-07 - val_loss: 3.0912e-08\n",
      "Epoch 771/1000\n",
      "148/148 [==============================] - 0s 125us/step - loss: 4.2600e-07 - val_loss: 6.1733e-08\n",
      "Epoch 772/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 2.0365e-07 - val_loss: 9.1665e-08\n",
      "Epoch 773/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6347e-07 - val_loss: 2.5430e-08\n",
      "Epoch 774/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2955e-07 - val_loss: 1.2219e-07\n",
      "Epoch 775/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2072e-07 - val_loss: 9.1278e-08\n",
      "Epoch 776/1000\n",
      "148/148 [==============================] - 0s 132us/step - loss: 8.3939e-08 - val_loss: 2.5161e-08\n",
      "Epoch 777/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.6637e-07 - val_loss: 2.3971e-08\n",
      "Epoch 778/1000\n",
      "148/148 [==============================] - 0s 445us/step - loss: 2.4368e-07 - val_loss: 2.7884e-07\n",
      "Epoch 779/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.3975e-07 - val_loss: 1.0715e-07\n",
      "Epoch 780/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.5958e-06 - val_loss: 4.1831e-08\n",
      "Epoch 781/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2345e-06 - val_loss: 3.2943e-07\n",
      "Epoch 782/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.7213e-06 - val_loss: 5.5440e-07\n",
      "Epoch 783/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 8.2942e-07 - val_loss: 2.9977e-08\n",
      "Epoch 784/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 4.7514e-07 - val_loss: 1.1051e-07\n",
      "Epoch 785/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.6352e-07 - val_loss: 1.4333e-07\n",
      "Epoch 786/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.9796e-07 - val_loss: 2.5693e-07\n",
      "Epoch 787/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.6287e-07 - val_loss: 1.7382e-08\n",
      "Epoch 788/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.5013e-07 - val_loss: 3.6961e-08\n",
      "Epoch 789/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.3490e-07 - val_loss: 2.2726e-07\n",
      "Epoch 790/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.3591e-07 - val_loss: 7.8569e-08\n",
      "Epoch 791/1000\n",
      "148/148 [==============================] - 0s 154us/step - loss: 3.3799e-07 - val_loss: 3.5792e-08\n",
      "Epoch 792/1000\n",
      "148/148 [==============================] - 0s 398us/step - loss: 3.9799e-07 - val_loss: 1.9218e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 1.4448e-07 - val_loss: 2.3447e-08\n",
      "Epoch 794/1000\n",
      "148/148 [==============================] - 0s 687us/step - loss: 5.9969e-08 - val_loss: 3.3147e-08\n",
      "Epoch 795/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 5.2184e-08 - val_loss: 5.3254e-08\n",
      "Epoch 796/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.7624e-08 - val_loss: 5.1196e-08\n",
      "Epoch 797/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.2408e-08 - val_loss: 3.5769e-08\n",
      "Epoch 798/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.9316e-08 - val_loss: 6.4586e-08\n",
      "Epoch 799/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.9723e-08 - val_loss: 4.3346e-08\n",
      "Epoch 800/1000\n",
      "148/148 [==============================] - 0s 344us/step - loss: 6.9224e-08 - val_loss: 4.5569e-08\n",
      "Epoch 801/1000\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 6.5595e-08 - val_loss: 9.7433e-08\n",
      "Epoch 802/1000\n",
      "148/148 [==============================] - 0s 284us/step - loss: 2.9580e-08 - val_loss: 3.7274e-08\n",
      "Epoch 803/1000\n",
      "148/148 [==============================] - 0s 270us/step - loss: 2.1124e-08 - val_loss: 5.5798e-08\n",
      "Epoch 804/1000\n",
      "148/148 [==============================] - 0s 283us/step - loss: 2.4077e-08 - val_loss: 1.7325e-07\n",
      "Epoch 805/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.4164e-08 - val_loss: 3.1957e-08\n",
      "Epoch 806/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 1.8909e-08 - val_loss: 2.8039e-08\n",
      "Epoch 807/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3734e-08 - val_loss: 1.9561e-07\n",
      "Epoch 808/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.4577e-08 - val_loss: 2.7582e-08\n",
      "Epoch 809/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7675e-08 - val_loss: 3.0030e-08\n",
      "Epoch 810/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.2149e-08 - val_loss: 9.1229e-08\n",
      "Epoch 811/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 4.1414e-08 - val_loss: 8.6048e-08\n",
      "Epoch 812/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.7080e-08 - val_loss: 3.1486e-08\n",
      "Epoch 813/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.6921e-08 - val_loss: 8.2159e-08\n",
      "Epoch 814/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.4883e-08 - val_loss: 6.0705e-08\n",
      "Epoch 815/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.7842e-08 - val_loss: 5.8578e-08\n",
      "Epoch 816/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3811e-08 - val_loss: 8.6479e-08\n",
      "Epoch 817/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2349e-08 - val_loss: 5.3771e-08\n",
      "Epoch 818/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.7581e-08 - val_loss: 6.6711e-08\n",
      "Epoch 819/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.8505e-08 - val_loss: 8.8865e-08\n",
      "Epoch 820/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 8.8496e-08 - val_loss: 6.4377e-08\n",
      "Epoch 821/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.7556e-08 - val_loss: 3.7333e-08\n",
      "Epoch 822/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5407e-08 - val_loss: 2.4896e-07\n",
      "Epoch 823/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.8486e-08 - val_loss: 4.5803e-08\n",
      "Epoch 824/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.7416e-08 - val_loss: 2.5402e-08\n",
      "Epoch 825/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.5342e-08 - val_loss: 1.1946e-07\n",
      "Epoch 826/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.3468e-08 - val_loss: 6.1131e-08\n",
      "Epoch 827/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2062e-07 - val_loss: 3.9250e-08\n",
      "Epoch 828/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.8467e-08 - val_loss: 5.1706e-08\n",
      "Epoch 829/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.0254e-08 - val_loss: 1.4915e-07\n",
      "Epoch 830/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.3408e-08 - val_loss: 4.2913e-08\n",
      "Epoch 831/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.0109e-08 - val_loss: 2.2334e-08\n",
      "Epoch 832/1000\n",
      "148/148 [==============================] - 0s 163us/step - loss: 3.0855e-08 - val_loss: 2.4723e-08\n",
      "Epoch 833/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.4696e-08 - val_loss: 1.8331e-07\n",
      "Epoch 834/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.4257e-08 - val_loss: 2.7975e-08\n",
      "Epoch 835/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.7657e-08 - val_loss: 2.2652e-08\n",
      "Epoch 836/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.6003e-08 - val_loss: 2.0172e-07\n",
      "Epoch 837/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.0240e-07 - val_loss: 7.4231e-08\n",
      "Epoch 838/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.1381e-07 - val_loss: 7.3804e-08\n",
      "Epoch 839/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 1.2279e-06 - val_loss: 3.6684e-07\n",
      "Epoch 840/1000\n",
      "148/148 [==============================] - 0s 125us/step - loss: 6.6470e-07 - val_loss: 4.3512e-08\n",
      "Epoch 841/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.3711e-06 - val_loss: 7.1485e-08\n",
      "Epoch 842/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2465e-06 - val_loss: 9.4407e-07\n",
      "Epoch 843/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.7246e-06 - val_loss: 2.9609e-07\n",
      "Epoch 844/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.8462e-06 - val_loss: 2.3433e-07\n",
      "Epoch 845/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.0388e-06 - val_loss: 6.0473e-08\n",
      "Epoch 846/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.9049e-06 - val_loss: 6.3596e-08\n",
      "Epoch 847/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.2684e-06 - val_loss: 9.4170e-07\n",
      "Epoch 848/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.5159e-05 - val_loss: 1.7290e-07\n",
      "Epoch 849/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.9331e-06 - val_loss: 1.4151e-06\n",
      "Epoch 850/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.1300e-05 - val_loss: 9.4955e-07\n",
      "Epoch 851/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.4631e-06 - val_loss: 5.0808e-07\n",
      "Epoch 852/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7195e-06 - val_loss: 4.1420e-06\n",
      "Epoch 853/1000\n",
      "148/148 [==============================] - 0s 154us/step - loss: 2.2805e-06 - val_loss: 5.3593e-07\n",
      "Epoch 854/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.9181e-06 - val_loss: 6.9471e-08\n",
      "Epoch 855/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.8740e-06 - val_loss: 1.2199e-07\n",
      "Epoch 856/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 1.1779e-05 - val_loss: 6.2689e-08\n",
      "Epoch 857/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.3058e-05 - val_loss: 2.4711e-07\n",
      "Epoch 858/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.2099e-06 - val_loss: 2.0020e-06\n",
      "Epoch 859/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 6.3186e-06 - val_loss: 4.1202e-08\n",
      "Epoch 860/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.9143e-06 - val_loss: 1.9430e-07\n",
      "Epoch 861/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.7534e-07 - val_loss: 1.0628e-07\n",
      "Epoch 862/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.3209e-07 - val_loss: 1.2417e-07\n",
      "Epoch 863/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 8.6532e-07 - val_loss: 3.4187e-07\n",
      "Epoch 864/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.8508e-06 - val_loss: 1.0553e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 865/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.3235e-06 - val_loss: 1.8213e-07\n",
      "Epoch 866/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0521e-06 - val_loss: 7.0993e-07\n",
      "Epoch 867/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.0051e-06 - val_loss: 4.9251e-07\n",
      "Epoch 868/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.9350e-06 - val_loss: 3.5065e-07\n",
      "Epoch 869/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.5097e-06 - val_loss: 6.0090e-08\n",
      "Epoch 870/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4656e-06 - val_loss: 2.5004e-08\n",
      "Epoch 871/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 3.4427e-06 - val_loss: 3.6915e-08\n",
      "Epoch 872/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4220e-06 - val_loss: 1.5625e-06\n",
      "Epoch 873/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.4044e-07 - val_loss: 3.9093e-08\n",
      "Epoch 874/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.9985e-07 - val_loss: 2.5432e-07\n",
      "Epoch 875/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 3.3335e-06 - val_loss: 2.8191e-07\n",
      "Epoch 876/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.8802e-06 - val_loss: 8.3535e-07\n",
      "Epoch 877/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.7443e-06 - val_loss: 9.3240e-08\n",
      "Epoch 878/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7908e-06 - val_loss: 1.2337e-07\n",
      "Epoch 879/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 7.0911e-07 - val_loss: 2.4643e-07\n",
      "Epoch 880/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.9499e-07 - val_loss: 5.7464e-07\n",
      "Epoch 881/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 2.8954e-07 - val_loss: 2.5134e-08\n",
      "Epoch 882/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.9125e-08 - val_loss: 2.5593e-08\n",
      "Epoch 883/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8959e-08 - val_loss: 8.7482e-08\n",
      "Epoch 884/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.5771e-08 - val_loss: 1.8732e-07\n",
      "Epoch 885/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.5960e-08 - val_loss: 3.0725e-08\n",
      "Epoch 886/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8660e-08 - val_loss: 6.1422e-08\n",
      "Epoch 887/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 8.2012e-08 - val_loss: 7.9132e-08\n",
      "Epoch 888/1000\n",
      "148/148 [==============================] - 0s 133us/step - loss: 5.1579e-08 - val_loss: 5.5414e-08\n",
      "Epoch 889/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4705e-08 - val_loss: 2.9287e-08\n",
      "Epoch 890/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.6176e-08 - val_loss: 1.2160e-07\n",
      "Epoch 891/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.2076e-07 - val_loss: 6.8261e-08\n",
      "Epoch 892/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.8368e-08 - val_loss: 2.5666e-08\n",
      "Epoch 893/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 2.7196e-08 - val_loss: 1.1085e-07\n",
      "Epoch 894/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8516e-08 - val_loss: 1.0019e-07\n",
      "Epoch 895/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 2.8512e-08 - val_loss: 7.6414e-08\n",
      "Epoch 896/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9970e-08 - val_loss: 9.1027e-08\n",
      "Epoch 897/1000\n",
      "148/148 [==============================] - 0s 129us/step - loss: 6.0517e-08 - val_loss: 2.6762e-08\n",
      "Epoch 898/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3988e-08 - val_loss: 1.5386e-07\n",
      "Epoch 899/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.0360e-07 - val_loss: 9.5489e-08\n",
      "Epoch 900/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.9775e-07 - val_loss: 1.4816e-07\n",
      "Epoch 901/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.7645e-07 - val_loss: 2.6226e-08\n",
      "Epoch 902/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.2437e-07 - val_loss: 8.8362e-08\n",
      "Epoch 903/1000\n",
      "148/148 [==============================] - 0s 145us/step - loss: 4.9013e-07 - val_loss: 2.7220e-08\n",
      "Epoch 904/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.9469e-07 - val_loss: 4.0104e-08\n",
      "Epoch 905/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.4208e-07 - val_loss: 2.3375e-08\n",
      "Epoch 906/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 5.6231e-07 - val_loss: 2.0070e-07\n",
      "Epoch 907/1000\n",
      "148/148 [==============================] - 0s 166us/step - loss: 4.7537e-07 - val_loss: 1.9304e-07\n",
      "Epoch 908/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 5.5275e-07 - val_loss: 2.9787e-08\n",
      "Epoch 909/1000\n",
      "148/148 [==============================] - 0s 114us/step - loss: 4.7524e-07 - val_loss: 3.3710e-08\n",
      "Epoch 910/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.6402e-07 - val_loss: 1.8697e-07\n",
      "Epoch 911/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3760e-07 - val_loss: 2.7158e-07\n",
      "Epoch 912/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 6.0388e-08 - val_loss: 3.9273e-08\n",
      "Epoch 913/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.4725e-08 - val_loss: 4.6346e-08\n",
      "Epoch 914/1000\n",
      "148/148 [==============================] - 0s 222us/step - loss: 9.7415e-09 - val_loss: 1.2067e-07\n",
      "Epoch 915/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.9076e-09 - val_loss: 7.7405e-08\n",
      "Epoch 916/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 6.8886e-09 - val_loss: 4.9493e-08\n",
      "Epoch 917/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.4056e-09 - val_loss: 6.1844e-08\n",
      "Epoch 918/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2146e-08 - val_loss: 1.0732e-07\n",
      "Epoch 919/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 9.3670e-09 - val_loss: 9.7715e-08\n",
      "Epoch 920/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3005e-08 - val_loss: 3.3199e-08\n",
      "Epoch 921/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 3.7005e-08 - val_loss: 1.0782e-07\n",
      "Epoch 922/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.6895e-08 - val_loss: 1.0665e-07\n",
      "Epoch 923/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3461e-07 - val_loss: 3.0664e-08\n",
      "Epoch 924/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.8061e-07 - val_loss: 4.0588e-07\n",
      "Epoch 925/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.2504e-07 - val_loss: 3.9347e-08\n",
      "Epoch 926/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.3224e-07 - val_loss: 2.9267e-08\n",
      "Epoch 927/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2679e-07 - val_loss: 6.0419e-08\n",
      "Epoch 928/1000\n",
      "148/148 [==============================] - 0s 185us/step - loss: 2.2873e-07 - val_loss: 3.0898e-08\n",
      "Epoch 929/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3385e-07 - val_loss: 9.3106e-07\n",
      "Epoch 930/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.1683e-07 - val_loss: 4.6979e-07\n",
      "Epoch 931/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.5440e-06 - val_loss: 4.2267e-07\n",
      "Epoch 932/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.7716e-06 - val_loss: 8.4585e-08\n",
      "Epoch 933/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.8254e-05 - val_loss: 8.7730e-06\n",
      "Epoch 934/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.7704e-05 - val_loss: 2.5145e-06\n",
      "Epoch 935/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.5657e-05 - val_loss: 9.9792e-07\n",
      "Epoch 936/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.9991e-05 - val_loss: 3.4948e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.3179e-05 - val_loss: 1.6968e-05\n",
      "Epoch 938/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.1127e-04 - val_loss: 1.3291e-06\n",
      "Epoch 939/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3627e-04 - val_loss: 2.1366e-06\n",
      "Epoch 940/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.9862e-05 - val_loss: 4.5410e-07\n",
      "Epoch 941/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.2743e-05 - val_loss: 4.8370e-07\n",
      "Epoch 942/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2487e-05 - val_loss: 9.1296e-08\n",
      "Epoch 943/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0898e-05 - val_loss: 1.5629e-07\n",
      "Epoch 944/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.8334e-06 - val_loss: 5.8759e-07\n",
      "Epoch 945/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7329e-06 - val_loss: 3.2290e-07\n",
      "Epoch 946/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3386e-06 - val_loss: 7.5526e-07\n",
      "Epoch 947/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.7630e-07 - val_loss: 4.0839e-08\n",
      "Epoch 948/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.4288e-07 - val_loss: 3.2768e-07\n",
      "Epoch 949/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9808e-07 - val_loss: 3.5155e-07\n",
      "Epoch 950/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.4909e-07 - val_loss: 1.6167e-07\n",
      "Epoch 951/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0870e-06 - val_loss: 5.5703e-07\n",
      "Epoch 952/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.9203e-07 - val_loss: 2.0449e-07\n",
      "Epoch 953/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 1.3090e-06 - val_loss: 8.0660e-07\n",
      "Epoch 954/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3804e-06 - val_loss: 1.7026e-07\n",
      "Epoch 955/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.3382e-07 - val_loss: 1.0863e-07\n",
      "Epoch 956/1000\n",
      "148/148 [==============================] - 0s 131us/step - loss: 3.5022e-07 - val_loss: 2.0937e-07\n",
      "Epoch 957/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1081e-06 - val_loss: 4.0475e-08\n",
      "Epoch 958/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0846e-06 - val_loss: 2.2950e-06\n",
      "Epoch 959/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.2451e-06 - val_loss: 3.4262e-06\n",
      "Epoch 960/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 9.5708e-06 - val_loss: 1.2828e-08\n",
      "Epoch 961/1000\n",
      "148/148 [==============================] - 0s 158us/step - loss: 7.2335e-06 - val_loss: 1.5507e-06\n",
      "Epoch 962/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.6678e-06 - val_loss: 1.2498e-07\n",
      "Epoch 963/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0219e-05 - val_loss: 2.6888e-06\n",
      "Epoch 964/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.6491e-06 - val_loss: 6.0211e-06\n",
      "Epoch 965/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.9468e-06 - val_loss: 9.2145e-07\n",
      "Epoch 966/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.1738e-06 - val_loss: 1.0521e-06\n",
      "Epoch 967/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.5908e-06 - val_loss: 8.7912e-07\n",
      "Epoch 968/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6350e-05 - val_loss: 6.4480e-06\n",
      "Epoch 969/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.1985e-05 - val_loss: 9.3748e-08\n",
      "Epoch 970/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0662e-05 - val_loss: 1.5720e-07\n",
      "Epoch 971/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.5156e-05 - val_loss: 1.2270e-05\n",
      "Epoch 972/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.9662e-06 - val_loss: 8.1420e-06\n",
      "Epoch 973/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8716e-06 - val_loss: 7.8179e-07\n",
      "Epoch 974/1000\n",
      "148/148 [==============================] - 0s 157us/step - loss: 2.5828e-06 - val_loss: 1.4330e-06\n",
      "Epoch 975/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.8178e-06 - val_loss: 1.4774e-06\n",
      "Epoch 976/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2524e-06 - val_loss: 2.5939e-06\n",
      "Epoch 977/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 7.8946e-07 - val_loss: 7.8072e-07\n",
      "Epoch 978/1000\n",
      "148/148 [==============================] - 0s 249us/step - loss: 1.0085e-06 - val_loss: 1.7705e-07\n",
      "Epoch 979/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.8553e-07 - val_loss: 3.6988e-07\n",
      "Epoch 980/1000\n",
      "148/148 [==============================] - 0s 115us/step - loss: 2.5840e-07 - val_loss: 8.7599e-08\n",
      "Epoch 981/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.8039e-07 - val_loss: 4.2429e-07\n",
      "Epoch 982/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.8881e-06 - val_loss: 2.5483e-08\n",
      "Epoch 983/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.6059e-07 - val_loss: 4.6370e-07\n",
      "Epoch 984/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.9259e-07 - val_loss: 1.4639e-06\n",
      "Epoch 985/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.2847e-07 - val_loss: 4.0667e-07\n",
      "Epoch 986/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.9280e-07 - val_loss: 1.1325e-07\n",
      "Epoch 987/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0140e-07 - val_loss: 3.1356e-08\n",
      "Epoch 988/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.7823e-07 - val_loss: 1.5800e-07\n",
      "Epoch 989/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.5009e-07 - val_loss: 2.3267e-08\n",
      "Epoch 990/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.8933e-07 - val_loss: 1.5346e-07\n",
      "Epoch 991/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.6961e-07 - val_loss: 3.6416e-07\n",
      "Epoch 992/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.0665e-08 - val_loss: 5.8704e-08\n",
      "Epoch 993/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 8.3600e-08 - val_loss: 4.2182e-08\n",
      "Epoch 994/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.4424e-08 - val_loss: 1.1001e-07\n",
      "Epoch 995/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.7746e-08 - val_loss: 8.1738e-08\n",
      "Epoch 996/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.1003e-08 - val_loss: 1.5225e-07\n",
      "Epoch 997/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.4858e-08 - val_loss: 8.5936e-08\n",
      "Epoch 998/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.9067e-08 - val_loss: 1.1402e-07\n",
      "Epoch 999/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.0317e-08 - val_loss: 1.3894e-07\n",
      "Epoch 1000/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.2563e-08 - val_loss: 8.6732e-08\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(x_train.reshape(148, 5, 1), y_train, epochs=1000, validation_data=(x_test.reshape(37, 5, 1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(r.history['loss'], label=\"Loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting y_test when x_test is feeded into the model\n",
    "\n",
    "result = model.predict(x_test.reshape(37,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153.00046, 154.     , 154.9996 , 155.99948, 156.99936, 157.99924,\n",
       "       158.99911, 159.999  , 160.99886, 161.99875, 162.99863, 163.99849,\n",
       "       164.99837, 165.99756, 166.99643, 167.99509, 168.99362, 169.99219,\n",
       "       170.99075, 171.98932, 172.98788, 173.98645, 174.985  , 175.98357,\n",
       "       176.98212, 177.98068, 178.97925, 179.97781, 180.97638, 181.97491,\n",
       "       182.97348, 183.97205, 184.97061, 185.96918, 186.96774, 187.96628,\n",
       "       188.96484], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reversing predicted y_test values \n",
    "\n",
    "scaler.inverse_transform(result).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153., 154., 155., 156., 157., 158., 159., 160., 161., 162., 163.,\n",
       "       164., 165., 166., 167., 168., 169., 170., 171., 172., 173., 174.,\n",
       "       175., 176., 177., 178., 179., 180., 181., 182., 183., 184., 185.,\n",
       "       186., 187., 188., 189.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjusting predicited y_test values by rounding \n",
    "\n",
    "np.round(scaler.inverse_transform(result).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153., 154., 155., 156., 157., 158., 159., 160., 161., 162., 163.,\n",
       "       164., 165., 166., 167., 168., 169., 170., 171., 172., 173., 174.,\n",
       "       175., 176., 177., 178., 179., 180., 181., 182., 183., 184., 185.,\n",
       "       186., 187., 188., 189.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into original y_test values\n",
    "\n",
    "scaler.inverse_transform(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.scatter(range(37), result, c='r', label=\"Predicted\")\n",
    "plt.scatter(range(37),y_test, c='b', label=\"Original\")\n",
    "plt.legend(loc =\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlAVGX/9/H3DKu4oIBpKu4r7oiAOyii+Wu7syhzybTMrW7NJTWX0lRcUKzAfRfTskwttzAztcwFWxRFRVwRkEVA9mHO84dP3JkgCANnZvi+/gLOMh9O+eGaa85co1EURUEIIYRZ0aodQAghhOFJuQshhBmSchdCCDMk5S6EEGZIyl0IIcyQlLsQQpghKXchhDBDUu5CCGGGpNyFEMIMSbkLIYQZslTzwaOjo4t1nJOTE/Hx8QZOUzpMJavkNDxTySo5Dau0c9aqVatI+8nIXQghzJCUuxBCmCEpdyGEMENS7kIIYYak3IUQwgxJuQshhBmSchdCCDMk5S6EEGUkJwdWjI/lz4NJpf5YUu5CCFEGzh1P54V2mcz5sj2hi6+W+uNJuQshRCnKzFBYNDyWfn71iblnx5Zn1/H+nlal/riqLj8ghBDm7PT+VCa9Z8eltPa8Ue1bpq2xp5Jn3zJ5bCl3IYQwsPupsHh4LGuOt6We5gbfDNiAh39PsCy7ypVyF0IIAzq4KZbRY624ldWW0TV38P7GOti28i3zHFLuQghhAEkJCnMH3+WLP9rRXBPBvlGhtJ7mBVp1XtqUchdCiBLatzKBafNqkahrybRG23h7YxOsG/RUNZOUuxBCFFPsrVxmDUpiz+U2dLD4nR1TI/CY9R/iExLUjia3QgohxJNSFNix8C49O1Xhh8tNmNNyE9+esqDR2G6g0agdD5CRuxBCPJFbl3OYOjCNH2+3pavVCRbPu4PzYB+1Yz1Cyl0IIYogNxc2z4xl3samaBQHlrpv4JX1nmiq1lU7Wr6k3IUQohBXwjKY/GYuv8W3p2+Fw8xfksFTz5f97Y1PotByDw4OJiwsDHt7ewICAh7Zfv78eRYuXMhTTz0FgIeHBy+//LLhkwohRBnLyYFV78ew+JuWVCaVVb020G9FNzR2FdSOVqhCy93Ly4u+ffsSFBRU4D4tWrRgypQpBg0mhBBq+uvnNCa9Y8lfKa68UmUvH62woWoP4x6t/1Oh5e7i4kJcXFxZZBFCCNVlpCt8OjKGzw+1owaxbP3PRnos9QIrK7WjPRGDzLlfunSJSZMmUa1aNQYPHoyzs7MhTiuEEGXqtz0pTB5fiSsZHRjmtJMp66tT0bW32rGKRaMoilLYTnFxcSxYsCDfOff09HS0Wi22traEhYWxYcMGPv3003zPExoaSmhoKAD+/v5kZ2cXK7SlpSU6na5Yx5Y1U8kqOQ3PVLJKTki5p2f6S5dYebwNDTRRrBhxGq+lz4KFxROfq7Svp7W1ddFylPSB7Ozs8r52dXVl7dq1pKSkUKVKlUf29fHxwcfnf/eDxsfHF+sxnZycin1sWTOVrJLT8Ewla3nPeXhLAh/MeIro7FaMrf0l47c0wLZpF+KTivdpSaV9PWvVqlWk/Upc7vfu3cPe3h6NRsOVK1fQ6/VUrly5pKcVQohSlRiby5zB8Xx5vj0u2gus++9hWk0ynneYllSh5R4YGEh4eDipqamMHDkSPz+/vKccvr6+nDhxgoMHD2JhYYG1tTXjxo1DYyYXRwhhfhQFvg+6y/SFdUjKbcXUJlt5Z0tLrOp0VzuaQRVa7uPGjXvs9r59+9K3b9l8sogQQpREzLVsZgxKYW9UW9wsz/LNrKs0HOGldqxSIe9QFUKYPUWBL+fG8PHKxmTpazCv3RYGbXTFwqmT2tFKjZS7EMKs3biQxZRBGRyJcaW7za8s8k+gjp+6a62XBSl3IYRZys2FjVOimfdFSyyVHJZ13UT/tZ3RVKqndrQyIeUuhDA7l06mMXm4wqlEN/pVPMy8z3RU72N8y/KWJil3IYTZyM5SWPleNAHftcWeZNY+s5k+n3dFY2ujdrQyJ+UuhDALfx5KYdJoG87d78irVfcxc7UdVTv3UjuWaqTchRAmLSMdAt+6TfARV54mhi9eDaH7wm5gWb7rrXz/9kIIk3bim0QmTarK1cyODHtqF1M21aBia2+1YxkFKXchhMlJSdKzYEgMG8LcaKS5yu4R2+gwoytotWpHMxpS7kIIk3Jo3V2mzq7JnZz2jKv3Fe+GNMK2gXktHWAIUu5CCJNw93Y2456JYUeEK60swlk/+Rgt3+tsNgt9GZo8hxFCGDVFgd1LYmjbJIddEa2Y3mIb359SaPnfTlLsjyEjdyGE0boTmcX0QSnsv+GKu9VZlsy+QYOhMgVTFDJyF0IYHb0evpgVjXcPJ47caIK/21Z+uulMg6Ed1Y5mMmTkLoQwKtf+TGfKG1kcjXPD2/YXFgakUOtFLyyqVQET+MQoYyHlLoQwCjodbJh4i/lftcaabD7zDuE/qzzR2NVXO5pJknIXQqgu4pdUJr2l4UyyO89W/pG5y7U4ecubkUpCyl0IoZqsTIXlo2+x9IAr1Uhi/Qtb6R3YBY21ldrRTJ6UuxBCFb/vS2LiexW5kO7B6w57mb6+KvZuXmrHMhtS7kKIMpV+X2Hpm7dY/ktHamui2T54G13nydIBhiblLoQoM79sj2fSVEeuZXkwotYuJm2ujV1zuW+9NEi5CyFKXXK8Dv/BMWz6050m2it89+5XtP9Alg4oTVLuQohSdWhVDFPm1iZG14H3G+1gbEhTbJy7qB3L7BU6yRUcHMxbb73FhAkTHrvflStXePXVVzlx4oTBwgkhTFf8rWze9brDkI9dcSKeg9O/Y8LPnbFxdlI7WrlQaLl7eXkxbdq0x+6j1+sJCQmhXbt2BgsmhDBNigK7Fkbj3cme7y63Ymab7ew5raHFKFk6oCwVOi3j4uJCXFzcY/fZt28fHh4eREZGGiyYEML03I7IYPrg+xy87Yan9RkC5sVSf0A3tWOVSyW+9ygxMZGTJ0/i6+triDxCCBOk10PI1Jv07FWDY7cbs7DTNr760576A+TZvFpK/ILqhg0bGDhwINoi3KMaGhpKaGgoAP7+/jg5FW/uzdLSstjHljVTySo5Dc9UspY056XfkhjVP4ljdz3wqXic4HVW1HvxJQMmfKC8XE+D5SjpCSIjI1m2bBkAKSkpnD17Fq1Wi7u7+yP7+vj44OPjk/d9fDFXeHNycir2sWXNVLJKTsMzlazFzanLUVg77gYLvm1PBaxZ7vsFzy33RGNrUyq/t7lfz6KqVatWkfYrcbkHBQU99HWHDh3yLXYhhPm4cOQeE9+x4vfUTrxgf4g5q6xx7NpD7VjiHwot98DAQMLDw0lNTWXkyJH4+fmh0+kAZJ5diHImM0MheMQNlv3ohiMJbHxlGz4BXcDCQu1o4l8KLfdx48YV+WRjxowpURghhPEK2x3PxPerEJHRiUHV9/LhJieqtJGlA4yVvENVCPFYacm5BAy9xaqTHjhrbrHjrR10+kg+nNrYSbkLIQp0bHMsk2fU4EaOB+8472HClrrYNe6sdixRBFLuQohH3IvLYd7AWELC3Wmmvcx3E3bTbnxHGa2bEFlAWQjxkAOf3aaXWwW2hbsysdk37DuZTbv33aXYTYyM3IUQANy9nsWs1xPZda0jbS3PsXXOKZoN81Q7ligmGbkLUc4pCnwz5wbeXaux/1pLPnL9it1nrWg2rL3a0UQJyMhdiHLsdngab76RwMFoTzrbnGbxoiTq9Ze11s2BlLsQ5ZBeDyEfXGPOF21BUVjU/SteW+OKtmLR3toujJ+UuxDlzNWTyUwepufXpM74VjpG0OaK2LnLaN3cyJy7EOVETrbCihFR+PynAReTnmbF/33Jur+cqduvpdrRRCmQkbsQ5UB4aAITx9jyx/0uvFTtEB+vs8PBvavasUQpknIXwoxlpOkJGn6dT496UF0Tz+bXd9BzgScU4fMXhGmTchfCTJ35OpYJkxy4nNWFN57ey9RNNajsIksHlBdS7kKYmftJOhYPvsXqs52pr73ON6N34jFN3mFa3ki5C2FGjq6LZvLHtbip82RMg92MD2lAhXoeascSKpByF8IMJEZnMW9QLF9EeNLC4hL7pn5P67FuascSKpJyF8KEKQocWHqDqUsbk6ivw+SWOxkV0gLr6h3UjiZUJuUuhImKi0xn5sB77Lnpiav1n2yfc4amg2QKRjwg90MJYWIUBb6eGYV3Dyd+uNmS2e5f8+0fdjQd1FrtaMKIyMhdCBNy648UpryRxeG7Xeha4RSLlt6n7nOd1I4ljJCUuxAmIFensGVCFJ/saI8WPQG9vsZvVQe0trXVjiaMlJS7EEbu8rFEPhih4bfkrvSpcox5KzTU7CGjdfF4Uu5CGKmcLD2rR0ax6KA7lUll5X++4f8CO6KxtFA7mjABhZZ7cHAwYWFh2NvbExAQ8Mj2U6dOsX37djQaDRYWFgwdOpTmzZuXSlghyotz++KY+F5F/krvxitOoczcYI9De/nIO1F0hZa7l5cXffv2JSgoKN/trVu3xs3NDY1Gw/Xr11m6dCmBgYEGDypEeZBxP5fPhl7js187U0MTR8gbO/GaK0sHiCdXaLm7uLgQFxdX4HZbW9u8r7OystDI/4RCFMvJL6KZOO0pIrO7MbT2PqZseZrKTeW+dVE8BplzP3nyJFu3biU5OZmpU6ca4pRClBup8dksGnSbtX91oaE2im/+uwePSa4yWhclolEURSlsp7i4OBYsWJDvnPs/hYeH8/XXXzNjxox8t4eGhhIaGgqAv78/2dnZxYgMlpaW6HS6Yh1b1kwlq+Q0vKJk3R8YwZgPnYjWPcV7zQ8w8ztXKjo7lFHCB0zlmkrOB6ytrYuWw5AP6uLiQlBQECkpKVSpUuWR7T4+Pvj4+OR9Hx8fX6zHcXJyKvaxZc1UskpOw3tc1sSbGXwy8C7bIz1paXmRtbN+p9WIdmSgJ6OMfz9TuaaS84FatYr2IeYlXn4gJiaGvwf/V69eRafTUbly5ZKeVgizpCjwvf81vDtX5ZtIV6a2/Zbvz2ppNaKt2tGEmSl05B4YGEh4eDipqamMHDkSPz+/vKccvr6+nDhxgp9//hkLCwusra0ZP368vKgqRD5iLqYyc3AK30d3xs3mDwL842ns5652LGGmCi33cePGPXb7iy++yIsvvmiwQEKYG0WBr6ZeYdaWduQozsztspPB69tiUbG62tGEGZN3qApRim6cuceUN3M4ktCdHhVPsuCzLJz7yO2NovRJuQtRCnJ1CssGhTHrqzZYkUPgM9/SP6g9WhsrtaOJckLKXQgDu/RTPJNHWnIq1ZN+VY/yyWoranSWuXVRtqTchTCQ7IxcVr59lYDDnbAnhc1D9uP9SSs0FvKZOKLsyf91QhjAX7vv8GyrLPwP9+ClGj/z04Gb+K3uKcUuVCMjdyFKICNFR+DgKIJPd+VpTSxb395Dj1mydIBQn5S7EMX026abTJz5NFdzejC8/n4mb6lDpQYd1I4lBCDlLsQTS43LYsHAW6wP70Yjiyh2Tt6P+3/bqB1LiIfIhKAQT+Dwp1H0dKvAxvDO/LfF9xw4mSXFLoySjNyFKILEa2nMHniXr651oaXVRdbPPkeroe3VjiVEgaTchXgMRYHv5lzhw1WtSFHq8aHbbt7e1BIrexe1ownxWFLuQhTgzvkUpg++z/7Y7rjb/sHigHs0etFN7VhCFImUuxD/os9V+GryZWZt64AOC+Z57WbQmjZYVJCFvoTpkHIX4h+u/RrPlLcUjt7zwqvSSRasyKWOt4zWhemRchcC0GXr2TD6EvP3dcKabD59bjcvfd4ejaWF2tGEKBYpd1HuRRyMYdJYW86k9eRZh6PMWW/HU24yWhemTcpdlFtZaTpWDItkybGuVNPcY92gPfjOd0WjlaUDhOmTchfl0u87bjFxsgMXsrwZUOsQ0zc7UbW5LB0gzIeUuyhX0pOyWTroGst/704dbTTbxu6j25Q2stCXMDtS7qLc+HVNFJPm1CVK58WIRgeYsMWZSnXbqh1LiFIh5S7MXsqdDOa/Hs2mS91oYnGV3dN/oMOo1mrHEqJUycJhwqwdWnyFnu6VCLnUifGt97I/LJcOo1qqHUuIUicjd2GW4i+n8PGgJL651Z021uFsnneBFgPaqR1LiDJTaLkHBwcTFhaGvb09AQEBj2w/evQou3btAsDW1pa33nqL+vXrGzyoEEWhKLB7RgTTN7TlvtKAmZ2+Y9h6F6wqN1U7mhBlqtBpGS8vL6ZNm1bg9qeeeoqPPvqIxYsX079/f1atWmXQgEIUVfTviQxrf5vR671pWuEGh1af5p0drlhVtlU7mhBlrtCRu4uLC3FxcQVub9asWd7XTZo0ISEhwTDJhCgifa7CtvEX+fhrd/RoWdD7OwasbIOFzVNqRxNCNQadc//xxx9p377gDzAIDQ0lNDQUAH9/f5ycnIr1OJaWlsU+tqyZSlZTzXnpx1uMfu0+R5N74VP1JEHb7Knv7atiwv8x1WtqrCTnE+Yw1InOnTvH4cOHmT17doH7+Pj44OPjk/d9fHx8sR7Lycmp2MeWNVPJamo5dVm5bHgngvk/dMGWTIL6f8cLS9uhsdAaze9hatfU2EnOB2rVqlWk/QxS7tevX2flypVMnTqVypUrG+KUQhQoYu9tJrxXibMZPjxf/SizN1ameltXtWMJYVRKXO7x8fEsXryYsWPHFvkvihDFkZmaw0evnWDR0U44ahLZMHwfvT+WpQOEyE+h5R4YGEh4eDipqamMHDkSPz8/dDodAL6+vuzYsYP79++zZs0aACwsLPD39y/d1KLcObv1GhM+rEFEdncGOv/Ih1trYt9Qlg4QoiCFlvu4ceMeu33kyJGMHDnSYIGE+Kf0+EyWDLzGinNeOGuj+W76MdqPaq52LCGMniw/IIzW8eWR+Lhas/xcT0Y0CyX0ZDq9Z7irHUsIkyDLDwijk3zzPvNej2HL1e40s4xkz+zDuA5vpXYsIUyKlLswKj/Mu8iU5S25q2/IhPb7GbOlKTZVmxV+oBDiIVLuwijERyQza1AS30b3pK3NBUIWXaZ5/zZqxxLCZMmcu1CVolfYOTkcr1412Rftyqxue9n1VwWa92+odjQhTJqM3IVqbp+6y7Rh2YQm+tCl4lkWBmVRv7csyyuEIUi5izKn1+nZOiac2d91RoPCon57eS24NVorC7WjCWE2pNxFmbr6YzSTR1vxa6ovvav9xry1VtTykNG6EIYm5S7KRE6GjrVvRbDgp+5U1KQTPGA/zy9sjUYrSwcIURqk3EWpC//2BhMn2PNHZm9eqnmUjzZXxdFF7oQRojRJuYtSk3Evi+AhV1h2xpvqmgQ2jjyIzwx5M5IQZUHKXZSKMxsjmTCrNpdzejOk/o9MCXka+/pS7EKUFSl3YVBpseksHnidVRd6Ud/iBl9PPYTn2BZqxxKi3JE3MQmDObrsEr06VmD1BW9Gu/zAD6eypNiFUImM3EWJJUWlMHdgHF9c96K51RW+n3uMtoNbqh1LiHJNyl0Um6LAwdnhTFndlkSlERPd9jN6U1Ns7BurHU2Ick/KXRRL3LlEZg5JYU+sD66259m25DLNXpDbG4UwFlLu4okoeoWvJ5xn5pceZGHN7J77eGOVC5YVqqkdTQjxD1LuoshunYhjynAdh+/50rVyGAuW51LfWz7HVAhjJOUuCpWbncuWUeF8sr8rFuQS8Pw+/D5rjdZSbrYSwlhJuYvHivzhNpPG2PBbWh/6Opxg7gZbanaQ0boQxk7KXeQrOy2HNcMiWHSsB5U191kxaD/PzpeFvoQwFYWWe3BwMGFhYdjb2xMQEPDI9tu3bxMcHExUVBSvvfYazz//fKkEFWXn/NfXmTDJgb+yfHml1s/M3OKIQzO5E0YIU1LopKmXlxfTpk0rcHulSpV48803ee655wwaTJS9jMRMFj57nr7vuZOQU4Ut7/5A4KnGODSTO2GEMDWFlruLiwuVKlUqcLu9vT2NGzfGwkI+RceUHQ06R9/2Wpad7c2QRkc4dDwZ7ynyLlMhTJXMuZdz92PSWTjgBmsv9aShxXW++fBHPEY3VzuWEKKEyrTcQ0NDCQ0NBcDf3x8nJ6dincfS0rLYx5Y1Y86675Mwxs6rS3RuD8a3P8yM3e2o+FRXtWM9ljFfz38zlayS07CMJWeZlruPjw8+Pj5538fHxxfrPE5OTsU+tqwZY9bEyGQ+GXiX7Te742J9idX+kfR8rwvx8fFkxGeoHe+xjPF6FsRUskpOwyrtnLVq1SrSfjItU44oeoV9s8KZtr4d95RGTPHYzzsbm2FduZHa0YQQBlZouQcGBhIeHk5qaiojR47Ez88PnU4HgK+vL/fu3WPKlClkZGSg0WjYu3cvS5Yswc7OrtTDi6KL/TOB6UPS2Hu3N24VzvHlsis0/T+5vVEIc1VouY8bN+6x26tWrcqKFSsMFkgYlqJX2DH+PDN3eJCDFXN89vPGKhcsbBzUjiaEKEUyLWPGbh6P4YO3FY4k+9K9yhkWrIK63WS0LkR5IOVuhnKzc9n0TjhzD3bDihwC/7OP/oGy0JcQ5YmUu5m5vP8Wk96twKn0Pvyf0y/M2ViRGu1koS8hyhspdzORfT+blUMvEfCrF/aaFFYPPcAzc1rJQl9ClFNS7mbgr+1RvD/1KcKzfPGrc4SZIdWp1ri12rGEECqScjdhGYmZBA68SvCf3jytjSXkv6F4TXZRO5YQwghIuZuok6suM2Fufa7qfBjW+BCTtzpTubYUuxDiASl3E5N6+z7+r99mwxVvGltG8e3Mw3R8p4XasYQQRkbujTMhhxdeoKdnZTZd6c5/2x5k/1mFju80UzuWEMIIycjdBCRevsfHAxPYcbsXrWwi2OAfSUu/VmrHEkIYMRm5GzFFr/D9h+fx8q7BrtsefNjlAHv+tKGlX0O1owkhjJyM3I3UnbC7zHgzg33xvXG3+4tFn6XTuK/c3iiEKBopdyOj1+n5atx5Zu3sRC4WzOuzn0ErWmJh7ah2NCGECZFyNyLXf77DB+9oOJrSB2/70/iv0VKnsyz0JYR4clLuRkCXqWPTOxeYG9odG7L47JX9/GdJa1k6QAhRbFLuKov4/iaT/luJMxl9eLb6L8zZVImn2shoXQhRMlLuKslKyWLF0Mss+c0bB00S6946gO8sWehLCGEYUu4q+GPrVSZ8WIML2b4MqPsT00NqULWh3AkjhDAcKfcylBGfwdKBUQSf60kd7R22TThEt/dl6QAhhOHJm5jKyIngCHq7WhF0zofhTQ8TejJdil0IUWpk5F7K7l1PZtozEWyM9KaJZRS7Zh/BbbiUuhCidMnIvRQdmn+Bds1z2RLZjfGuB9n3u4Lb8CZqxxJClAMyci8FCReT+GhQEt/c6UVb24tsWngVl/6y0JcoHxRFITMzE71ej0ZjuLu/YmNjycrKMtj5SoshciqKglarxdbWttjXsNByDw4OJiwsDHt7ewICAvINsX79es6ePYuNjQ2jR4+mYcPyubCVolfYM/U8H4a4cV9pzIxu+/lgdzeS06uoHU2IMpOZmYmVlRWWloYdO1paWmJhYWHQc5YGQ+XU6XRkZmZSoUKFYh1f6LSMl5cX06ZNK3D72bNniYmJ4dNPP2XEiBGsWbOmWEFM3Z0zdxne7hajtvjSzO4mhzb+ychtbbCys1I7mhBlSq/XG7zYyyNLS0v0en2xjy+03F1cXKhUqVKB20+fPk337t3RaDQ0bdqUtLQ0kpKSih3I1Oh1eraO+guv5xtyLKEl/v0OsP2cAw19aqsdTQhVGHIqprwrybUs8QuqiYmJODk55X3v6OhIYmJiSU9rEqIOR/Naq7tM2t0Hj6oXOfzNZQavbo2FtfE/dRTCnDk7O9O7d2969uzJiBEjyMjIKPa5fvnlF4YMGQLAwYMH+fzzzwvcNzk5mfXr1z/xYwQEBLBixYpiZ8xPiZ87KYryyM8K+msTGhpKaGgoAP7+/g/9UXgSlpaWxT7WEHSZOpb5neDjA52poMlkzdAjDFrume/SAWpnLSrJaXimktXQOWNjY0ttWqao57W1teXw4cMAjBo1ipCQEEaOHJm3XVGUvBctC2NhYYFGo8HS0pJ+/frRr1+/AvdNS0tj/fr1vPnmm0XK+TetVotWq33k97OxsSl+TxbrqH9wdHQkPj4+7/uEhASqVauW774+Pj74+Pjkff/P456Ek5NTsY8tqYu7rzNxvD1nM3vyQo3jzN5cBaeWTUhITMh3fzWzPgnJaXimktXQObOyskrlhU9LS0t0Ol2R9/97344dO3LhwgWioqIYNGgQnTt35syZM6xbt47IyEgWL15MdnY29erVY+nSpVSsWJHDhw8za9YsHBwcaN26NYqioNPp2L59O3/++Sdz587l7t27TJkyhevXrwMwf/581q1bx/Xr1/H29qZ79+7MmDGD5cuXs2fPHrKzs+nbty8TJ04EYNmyZezYsYNatWrh6OhImzZtHvn9srKyHvlvU6tWraJdryJfqQK4ubmxf/9+unTpwuXLl7Gzsyuw3E1ZZnIWy4dcZunpnjhpEln/zg/4zmypdiwhjFqVmTOxCg83yLk0Gg2KopDj4kLK7NlFOkan03H48GG8vLwAiIyMZMmSJcyfP5/ExESWLVvG9u3bsbOzIygoiFWrVjFq1CgmTZrEl19+SYMGDR4a8f/TjBkz8PT0ZO3ateTm5pKWlsa0adOIiIjghx9+AODIkSNERUXx/fffoygKQ4cO5cSJE9jZ2bF7924OHjyITqejb9++tDHwarCFlntgYCDh4eGkpqYycuRI/Pz88v66+Pr60r59e8LCwnjvvfewtrZm9OjRBg1oDM5uvsKEGbWJyPFlYL2fmLa1JlXrS7ELYawyMzPp3bs3AB4eHgwYMIDY2Fjq1KlDhw4dADhz5gyXLl3ihRdeACAnJ4cOHTpw5coV6tatm3dLd//+/dmyZcsjj3H8+HGWLVsGPJi6qVKlCsnJyQ/tc+TIEY4cOYKvry8A6enpREVFcf/+ffr27Zt3m+PfWQ2p0HIfN27cY7drNBreeusKGmr6AAANkUlEQVQtgwUyJulx6QQMvMbK8J44W0Tz5QeH6fJeM7VjCWEyijrCLoonmZaxtbXNGz3/k52dXd7XiqLQvXt3goODH9rn3LlzBrvjR1EUxo4dy+DBgx/6+erVq0v9riJZfqAAv34egY+bDSvDezKixY+EnsyQYhfCjHTo0IFTp04RFRUFQEZGBpGRkTRu3JgbN25w7do1AL799tt8j+/atSubNm0CIDc3l9TUVCpWrEhaWlrePl5eXmzfvj3vZ3fu3CE+Ph5PT0/2799PRkYG9+/fz/cPUUnJOw3+JflaMvMGxrLlmjfNrCLZPfsYrkNd1I4lhDAwR0dHli5dypgxY8jOzgZg8uTJNGrUiIULFzJkyBAcHBxwd3fn4sWLjxw/e/ZsJk+ezLZt29BqtcyfPx83Nzc6duxIz5498fb2ZsaMGVy+fJnnn38eePDM4bPPPqN169Y899xz+Pr6UqdOHTw8PAz++2mU/O5lLCPR0dHFOq607kL4Yc55pqxqw129I+M7HGLU5qbY2tuU6Jzl9Y6J0mIqOcF0sho6Z3p6+kPTH4bypHfLqMWQOfO7lmV2t4w5iA9PZNbge3wb05t2tuGELLlK8xfkk5GEEKarXJe7olf4dtI5pm/3IENpzKwe+3lzTQus7KqqHU0IIUqk3Jb77d9imTY8h9CkPnSu9DuLludQv6dh7zMVQgi1lLty1+v0bB19ntnfd0GDwqLn9vPa563QWsqNQ0II81Guyv1q6G0mjbHmxP0++Dr8xrz1NjztJqN1IYT5KRflnpOew5phF1l41ItKmjSWDzzAc/6t8l3oSwghzIHZz0Vc+OYaz7fO4JOjfXju6ZP8FHqH5xe2lmIXwoxFR0fz5ptv0qVLFzp37szMmTPz7mX/p5iYGN5+++1Czzd48OBHlhYoqtJYzrcozLbcM5IyWfzcefq8605cdjU2jQnl09ONcGxufouaCSH+R1EU3n77bfr27cvx48c5evQoaWlpLFiw4KH9dDodNWvWZPXq1YWec/Pmzdjb25dW5FJhltMyZ9ZfYeLHdbiU05s3Gh7mgy1PY19P3mUqRHlw7NgxbGxsePXVV4EHi3p99NFHeHp64uzszC+//EJWVhbp6eksWbKEN954gx9//JGMjAzGjRuXtwTBrVu3mDt3Lm3btsXDw4N9+/aRlpbGoEGDcHd35/Tp09SsWZN169ZRoUIFQkJCCAkJIScnh/r16/Ppp58W+/NPDcGsyj0tJo1Fr99gdUQv6lvcYMe0w3QaI+vBCKGWmTOrEB5umM8R/nvJXxeXHGbPTilwv0uXLtG69cNvQqxcuTK1a9cmNzeXM2fOEBoaSrVq1bh582bePhs3bsTe3p7Q0FAuXryYt5Ljv0VFRREUFMSiRYt455132Lt3L/379+eZZ55h4MCBWFpaMnfuXL744guGDRtmkN+9OMym3I8uvcikpc24levNmFY/MD6kIRWcpNiFKG8URcl3xcW/f969e/d8P3Pi5MmTDB8+HIDmzZvTokWLfM/v7OxMq1atAGjTpk3eH4iIiAgWLlxISkoKaWlp9OjRw1C/UrGYfLknXU1m7sA4vrjRk+bWV/hu3nHaDZK11oUwBo8bYT+poq7Z0rRpU/bu3fvQz1JTU4mOjkar1Ra47k1Rl9mysfnfelMWFhZkZmYCMH78eNauXUvbtm0JCQnh119/LdL5SovJvqCq6BX2zzqPd3cnvrrRmUnuB9n7hwXtBjVSO5oQQkXdunUjIyODr776CniwHO/s2bPx8/N77By4u7s7e/bsAR5M7eS3EuTj3L9/nxo1apCTk8POnTuL/wsYiEmWe/TZWEZ1uMbwNb1xto3j4IozjNvZCpsqJVvBUQhh+jQaDWvWrOG7776jS5cudOvWDRsbG6ZMmfLY49544w0SEhLw8fEhKCiIFi1aULly5SI/7qRJk3j22Wfx8/OjcePGJf01Sszklvz9eckFRga4kYU103od4Y1VLljaGu/sUnld9rW0mEpOMJ2ssuTvA7m5ueTk5GBra8u1a9d49dVXOXr0KNbW1k90Hlnyt5jqu1fD0/ESsz7TUK+HLB0ghDCMjIwMXnnlFXJycgCYP3/+Exe7MTG5cq/btSa7o01jRCSEMB2VKlVi3759ascwGJOccxdCCPF4Uu5CCINS8WU8s1OSaynlLoQwKK1WaxKfdWrsdDodWm3xK7pIc+6///4769evR6/X06tXL1588cWHtt+9e5fly5eTkpJCpUqVePfdd3F0dCx2KCGE6bK1tSUzM5OsrKx83ylaXDY2NmRlZRnsfKXFEDkVRUGr1WJra1vscxRa7nq9nrVr1zJ9+nQcHR2ZOnUqbm5u1KlTJ2+fzZs30717d7y8vDh37hxbt27l3XffLXYoIYTp0mg0pbJgVnm9tbS4Ch3zX7lyhZo1a1KjRg0sLS3p3Lkzp06demifW7du5S3U07JlS06fPl06aYUQQhRJoSP3xMTEh6ZYHB0duXz58kP71KtXj99++41+/fpx8uRJMjIySE1NfeTdXaGhoYSGhgLg7++Pk5NT8UJbWhb72LJmKlklp+GZSlbJaVjGkrPQcs/v1dp/z6MNHjyYdevW8dNPP9GiRQscHBywsLB45DgfHx98fHzyvi/uUxdjedpTFKaSVXIanqlklZyGVdo5DfYOVUdHRxISEvK+T0hIeGS5TAcHByZOnAhAZmYmv/32W5HeflzUkIY+tqyZSlbJaXimklVyGpYx5Cx0zr1Ro0bcuXOHuLg4dDodv/zyC25ubg/tk5KSgl6vB2Dnzp14e3uXTtr/r7AFgIyJqWSVnIZnKlklp2EZS85CR+4WFhYMGzaMuXPnotfr8fb2xtnZme3bt9OoUSPc3NwIDw9n69ataDQaWrRokbfgvRBCCHUU6T53V1dXXF1dH/rZ359PCODp6Ymnp6dhkwkhhCg2i48++ugjtUMUR8OGDdWOUGSmklVyGp6pZJWchmUMOVVdz10IIUTpkLVlhBDCDJnceu6FrXNjLMaMGYOtrS1arRYLCwv8/f3VjpQnODiYsLAw7O3tCQgIAB58/uPSpUu5e/cu1atXZ/z48VSqVMnocn755ZccOnSIKlWqADBgwIBHXg8qa/Hx8QQFBXHv3j00Gg0+Pj7069fP6K5pQTmN8ZpmZ2cza9YsdDodubm5eHp64ufnR1xcHIGBgdy/f58GDRrw7rvvYmmpXo0VlDMoKIjw8PC8W8LHjBlD/fr1yzacYkJyc3OVsWPHKjExMUpOTo4yceJE5ebNm2rHytfo0aOV5ORktWPk6/z580pkZKTy/vvv5/1s8+bNys6dOxVFUZSdO3cqmzdvVitenvxybt++Xdm1a5eKqR6VmJioREZGKoqiKOnp6cp7772n3Lx50+iuaUE5jfGa6vV6JSMjQ1EURcnJyVGmTp2qREREKAEBAcqxY8cURVGUlStXKgcOHFAzZoE5P//8c+XXX39VNZtJTcsUZZ0bUTgXF5dHRpCnTp2iR48eAPTo0cMormt+OY1RtWrV8l5Aq1ChArVr1yYxMdHormlBOY2RRqPJWxExNzeX3NxcNBoN58+fz7szz8vLS/VrWlBOY2BS0zJFWefGmMydOxeA3r17P7TsgjFKTk7Oe+dxtWrVSElJUTlRwQ4cOMDPP/9Mw4YNGTJkiFH9AYiLiyMqKorGjRsb9TX9Z86LFy8a5TXV6/V88MEHxMTE0KdPH2rUqIGdnV3e0iYODg5G8cfp3zmbNGnCwYMH+eKLL9ixYwetWrVi4MCBWFlZlWkukyp3pQjr3BiLOXPm4ODgQHJyMp988gm1atXCxcVF7Vgmz9fXl5dffhmA7du3s2nTJkaPHq1yqgcyMzMJCAhg6NChRVp+Qy3/zmms11Sr1bJo0SLS0tJYvHgxt2/fVjtSvv6d88aNG7z++utUrVoVnU7HypUr2bVrV941LrNcZfpoJVSUdW6MhYODAwD29vZ07NiRK1euqJzo8ezt7UlKSgIgKSkp78U1Y1O1alW0Wi1arZZevXoRGRmpdiTgwafmBAQE0K1bNzw8PADjvKb55TTWa/q3ihUr4uLiwuXLl0lPTyc3Nxd48Ez+739nxuDvnL///jvVqlVDo9FgZWWFt7e3Kv/+Tarci7LOjTHIzMwkIyMj7+s///yTunXrqpzq8dzc3Dhy5AgAR44coWPHjionyt/fZQlw8uRJnJ2dVUzzgKIorFixgtq1a/Pss8/m/dzYrmlBOY3xmqakpJCWlgY8uCPlr7/+onbt2rRs2ZITJ04A8NNPP6n+77+gnH9fU0VROHXqlCrX1OTexBQWFsbGjRvz1rl56aWX1I70iNjYWBYvXgw8eJGla9euRpUzMDCQ8PBwUlNTsbe3x8/Pj44dO7J06VLi4+NxcnLi/fffV33eNb+c58+f59q1a2g0GqpXr86IESNUf/Z28eJFZs6cSd26dfOmCQcMGECTJk2M6poWlPP48eNGd02vX79OUFAQer0eRVHo1KkTL7/8MrGxsY/cClnWc9lFyfnxxx/nvcZSr149RowYUaKPzCsOkyt3IYQQhTOpaRkhhBBFI+UuhBBmSMpdCCHMkJS7EEKYISl3IYQwQ1LuQghhhqTchRDCDEm5CyGEGfp/KA8KrI8DnOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(result, c='r', label=\"Predicted\")\n",
    "plt.plot(y_test, c='b', label=\"Original\")\n",
    "plt.legend(loc =\"lower right\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.Shape: (10, 5, 1) Y_test.Shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the test dataset for series of numbers prediction with LSTM trained model \n",
    "\n",
    "T = 5\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for t in range(len(test_dataset)-T):\n",
    "  x = test_dataset[t:t+T]\n",
    "  X_test.append(x)\n",
    "  y = test_dataset[t+T]\n",
    "  Y_test.append(y)\n",
    "X_test = np.array(X_test).reshape(-1, T, 1)\n",
    "Y_test = np.array(Y_test)\n",
    "NN = len(X_test)\n",
    "\n",
    "print(\"X_test.Shape:\",X_test.shape, \"Y_test.Shape:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with untrain dataset X_test \n",
    "\n",
    "result_01 = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190., 191., 192., 193., 194., 195., 196., 197., 198., 199.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjusting predicited Y_test values by rounding  \n",
    "\n",
    "np.round(scaler.inverse_transform(result_01).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190., 191., 192., 193., 194., 195., 196., 197., 198., 199.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into original y_test values\n",
    "\n",
    "scaler.inverse_transform(Y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_xx values are not correctly feed  \n",
    "future_predictions = []\n",
    "\n",
    "\n",
    "last_x = x_test[-1] \n",
    "\n",
    "while len(future_predictions) < 30:\n",
    "  p = model.predict([last_x.reshape(1, 5, 1)])[0,0] \n",
    "  future_predictions.append(p) \n",
    "  last_x = np.roll(last_x, -1)\n",
    "  last_x[-1] = p\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([189., 190., 191., 192., 193., 194., 195., 196., 197., 198., 199.,\n",
       "       200., 201., 202., 203., 204., 205., 206., 207., 208., 209., 209.,\n",
       "       210., 211., 212., 213., 214., 215., 216., 217.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(scaler.inverse_transform(future_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
