{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, TimeDistributed, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building synthetic chronological series of numbers dataset\n",
    "\n",
    "data = np.arange(0,200)\n",
    "data = np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling down the raw data with StandardScaler()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = data_scaled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the scaled data into training dataset\n",
    "\n",
    "training_dataset = data_scaled[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the scaled data into test dataset, this dataset won't be used in LSTM model training\n",
    "\n",
    "test_dataset = data_scaled[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.Shape: (185, 5, 1) Y.Shape: (185,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training dataset for LSTM input \n",
    "\n",
    "T = 5\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(len(training_dataset)-T):\n",
    "  x = training_dataset[t:t+T]\n",
    "  X.append(x)\n",
    "  y = training_dataset[t+T]\n",
    "  Y.append(y)\n",
    "X = np.array(X).reshape(-1, T, 1)\n",
    "Y = np.array(Y)\n",
    "N = len(X)\n",
    "print(\"X.Shape:\",X.shape, \"Y.Shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (148, 5, 1) x_test.shape: (37, 5, 1) y_train.shape: (148,) y_test.shape: (37,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting training dataset again into x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "print(\"x_train.shape:\",x_train.shape, \"x_test.shape:\",x_test.shape, \"y_train.shape:\",y_train.shape, \"y_test.shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model CNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation='relu', input_shape=(5,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 37 samples\n",
      "Epoch 1/1000\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.5115 - val_loss: 0.6938\n",
      "Epoch 2/1000\n",
      "148/148 [==============================] - 0s 238us/step - loss: 0.2062 - val_loss: 0.2655\n",
      "Epoch 3/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 0.0625 - val_loss: 0.0474\n",
      "Epoch 4/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 0.0067 - val_loss: 2.1502e-04\n",
      "Epoch 5/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 0.0054 - val_loss: 0.0135\n",
      "Epoch 6/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 7/1000\n",
      "148/148 [==============================] - 0s 137us/step - loss: 0.0042 - val_loss: 1.1078e-04\n",
      "Epoch 8/1000\n",
      "148/148 [==============================] - 0s 191us/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 9/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 0.0021 - val_loss: 0.0155\n",
      "Epoch 10/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 0.0017 - val_loss: 0.0150\n",
      "Epoch 11/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 0.0012 - val_loss: 0.0087\n",
      "Epoch 12/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.0780e-04 - val_loss: 0.0042\n",
      "Epoch 13/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 5.7172e-04 - val_loss: 0.0031\n",
      "Epoch 14/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.4297e-04 - val_loss: 0.0065\n",
      "Epoch 15/1000\n",
      "148/148 [==============================] - 0s 158us/step - loss: 3.7185e-04 - val_loss: 0.0076\n",
      "Epoch 16/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.8097e-04 - val_loss: 0.0033\n",
      "Epoch 17/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.3192e-04 - val_loss: 0.0018\n",
      "Epoch 18/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.8265e-04 - val_loss: 0.0023\n",
      "Epoch 19/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3546e-04 - val_loss: 0.0025\n",
      "Epoch 20/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 9.8986e-05 - val_loss: 0.0016\n",
      "Epoch 21/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.7019e-05 - val_loss: 0.0013\n",
      "Epoch 22/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.4748e-05 - val_loss: 9.8318e-04\n",
      "Epoch 23/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 3.9672e-05 - val_loss: 7.5494e-04\n",
      "Epoch 24/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.8589e-05 - val_loss: 4.8717e-04\n",
      "Epoch 25/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.8450e-05 - val_loss: 4.4569e-04\n",
      "Epoch 26/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3236e-05 - val_loss: 3.2338e-04\n",
      "Epoch 27/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.7741e-06 - val_loss: 2.3445e-04\n",
      "Epoch 28/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 5.8908e-06 - val_loss: 1.8329e-04\n",
      "Epoch 29/1000\n",
      "148/148 [==============================] - 0s 229us/step - loss: 3.8725e-06 - val_loss: 1.5773e-04\n",
      "Epoch 30/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.7865e-06 - val_loss: 1.3474e-04\n",
      "Epoch 31/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.9485e-06 - val_loss: 1.1346e-04\n",
      "Epoch 32/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.5761e-06 - val_loss: 1.1028e-04\n",
      "Epoch 33/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 1.3411e-06 - val_loss: 9.9089e-05\n",
      "Epoch 34/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 1.1664e-06 - val_loss: 9.9111e-05\n",
      "Epoch 35/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0328e-06 - val_loss: 9.7611e-05\n",
      "Epoch 36/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 9.2462e-07 - val_loss: 9.4753e-05\n",
      "Epoch 37/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 8.4340e-07 - val_loss: 9.8307e-05\n",
      "Epoch 38/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 7.8923e-07 - val_loss: 9.4307e-05\n",
      "Epoch 39/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 7.5584e-07 - val_loss: 9.3722e-05\n",
      "Epoch 40/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.8749e-07 - val_loss: 9.5819e-05\n",
      "Epoch 41/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.5730e-07 - val_loss: 9.2310e-05\n",
      "Epoch 42/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 6.0159e-07 - val_loss: 9.2163e-05\n",
      "Epoch 43/1000\n",
      "148/148 [==============================] - 0s 180us/step - loss: 5.4362e-07 - val_loss: 9.1657e-05\n",
      "Epoch 44/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 5.1070e-07 - val_loss: 9.0881e-05\n",
      "Epoch 45/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.8964e-07 - val_loss: 8.8432e-05\n",
      "Epoch 46/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.4748e-07 - val_loss: 9.1131e-05\n",
      "Epoch 47/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.3290e-07 - val_loss: 8.8542e-05\n",
      "Epoch 48/1000\n",
      "148/148 [==============================] - 0s 188us/step - loss: 4.0625e-07 - val_loss: 8.6691e-05\n",
      "Epoch 49/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.8274e-07 - val_loss: 8.8675e-05\n",
      "Epoch 50/1000\n",
      "148/148 [==============================] - 0s 229us/step - loss: 3.6215e-07 - val_loss: 8.7283e-05\n",
      "Epoch 51/1000\n",
      "148/148 [==============================] - 0s 310us/step - loss: 3.5126e-07 - val_loss: 8.6341e-05\n",
      "Epoch 52/1000\n",
      "148/148 [==============================] - 0s 317us/step - loss: 3.3606e-07 - val_loss: 8.7063e-05\n",
      "Epoch 53/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 3.2212e-07 - val_loss: 8.5466e-05\n",
      "Epoch 54/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.0462e-07 - val_loss: 8.6402e-05\n",
      "Epoch 55/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.8896e-07 - val_loss: 8.5733e-05\n",
      "Epoch 56/1000\n",
      "148/148 [==============================] - 0s 164us/step - loss: 2.8437e-07 - val_loss: 8.4573e-05\n",
      "Epoch 57/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.7705e-07 - val_loss: 8.4644e-05\n",
      "Epoch 58/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.6465e-07 - val_loss: 8.5267e-05\n",
      "Epoch 59/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.5414e-07 - val_loss: 8.4309e-05\n",
      "Epoch 60/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.5127e-07 - val_loss: 8.4256e-05\n",
      "Epoch 61/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.3767e-07 - val_loss: 8.4133e-05\n",
      "Epoch 62/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 2.2650e-07 - val_loss: 8.4686e-05\n",
      "Epoch 63/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.2168e-07 - val_loss: 8.3155e-05\n",
      "Epoch 64/1000\n",
      "148/148 [==============================] - 0s 270us/step - loss: 2.1946e-07 - val_loss: 8.2892e-05\n",
      "Epoch 65/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1290e-07 - val_loss: 8.4187e-05\n",
      "Epoch 66/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.1312e-07 - val_loss: 8.2104e-05\n",
      "Epoch 67/1000\n",
      "148/148 [==============================] - 0s 153us/step - loss: 2.0197e-07 - val_loss: 8.2599e-05\n",
      "Epoch 68/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.9595e-07 - val_loss: 8.3614e-05\n",
      "Epoch 69/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8632e-07 - val_loss: 8.1316e-05\n",
      "Epoch 70/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.8771e-07 - val_loss: 8.1961e-05\n",
      "Epoch 71/1000\n",
      "148/148 [==============================] - 0s 172us/step - loss: 1.8232e-07 - val_loss: 8.2678e-05\n",
      "Epoch 72/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.7629e-07 - val_loss: 8.0666e-05\n",
      "Epoch 73/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.7070e-07 - val_loss: 8.2359e-05\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 169us/step - loss: 1.6845e-07 - val_loss: 8.1372e-05\n",
      "Epoch 75/1000\n",
      "148/148 [==============================] - 0s 226us/step - loss: 1.6211e-07 - val_loss: 8.1216e-05\n",
      "Epoch 76/1000\n",
      "148/148 [==============================] - 0s 163us/step - loss: 1.6086e-07 - val_loss: 8.1259e-05\n",
      "Epoch 77/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5740e-07 - val_loss: 8.0418e-05\n",
      "Epoch 78/1000\n",
      "148/148 [==============================] - 0s 243us/step - loss: 1.5332e-07 - val_loss: 8.1204e-05\n",
      "Epoch 79/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5104e-07 - val_loss: 8.0028e-05\n",
      "Epoch 80/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.4990e-07 - val_loss: 7.9757e-05\n",
      "Epoch 81/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5319e-07 - val_loss: 8.0084e-05\n",
      "Epoch 82/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.4583e-07 - val_loss: 7.9191e-05\n",
      "Epoch 83/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.4151e-07 - val_loss: 8.0251e-05\n",
      "Epoch 84/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3762e-07 - val_loss: 7.8483e-05\n",
      "Epoch 85/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3585e-07 - val_loss: 7.8878e-05\n",
      "Epoch 86/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3317e-07 - val_loss: 7.8414e-05\n",
      "Epoch 87/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2895e-07 - val_loss: 7.7766e-05\n",
      "Epoch 88/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2520e-07 - val_loss: 7.8796e-05\n",
      "Epoch 89/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2419e-07 - val_loss: 7.8544e-05\n",
      "Epoch 90/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2087e-07 - val_loss: 7.7752e-05\n",
      "Epoch 91/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2126e-07 - val_loss: 7.7872e-05\n",
      "Epoch 92/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1979e-07 - val_loss: 7.7878e-05\n",
      "Epoch 93/1000\n",
      "148/148 [==============================] - 0s 121us/step - loss: 1.2100e-07 - val_loss: 7.7945e-05\n",
      "Epoch 94/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.2016e-07 - val_loss: 7.6711e-05\n",
      "Epoch 95/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1201e-07 - val_loss: 7.9240e-05\n",
      "Epoch 96/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 1.1187e-07 - val_loss: 7.6270e-05\n",
      "Epoch 97/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.1037e-07 - val_loss: 7.8025e-05\n",
      "Epoch 98/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0985e-07 - val_loss: 7.6944e-05\n",
      "Epoch 99/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.0577e-07 - val_loss: 7.5978e-05\n",
      "Epoch 100/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.0349e-07 - val_loss: 7.6765e-05\n",
      "Epoch 101/1000\n",
      "148/148 [==============================] - 0s 438us/step - loss: 1.0072e-07 - val_loss: 7.6555e-05\n",
      "Epoch 102/1000\n",
      "148/148 [==============================] - 0s 512us/step - loss: 9.8375e-08 - val_loss: 7.5263e-05\n",
      "Epoch 103/1000\n",
      "148/148 [==============================] - 0s 761us/step - loss: 9.5428e-08 - val_loss: 7.6653e-05\n",
      "Epoch 104/1000\n",
      "148/148 [==============================] - 0s 256us/step - loss: 9.4895e-08 - val_loss: 7.4947e-05\n",
      "Epoch 105/1000\n",
      "148/148 [==============================] - 0s 222us/step - loss: 9.3348e-08 - val_loss: 7.5722e-05\n",
      "Epoch 106/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 9.0523e-08 - val_loss: 7.6636e-05\n",
      "Epoch 107/1000\n",
      "148/148 [==============================] - 0s 330us/step - loss: 8.9287e-08 - val_loss: 7.5329e-05\n",
      "Epoch 108/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.8653e-08 - val_loss: 7.5571e-05\n",
      "Epoch 109/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.5005e-08 - val_loss: 7.4488e-05\n",
      "Epoch 110/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.6038e-08 - val_loss: 7.5548e-05\n",
      "Epoch 111/1000\n",
      "148/148 [==============================] - ETA: 0s - loss: 7.3347e-0 - 0s 148us/step - loss: 8.2910e-08 - val_loss: 7.5207e-05\n",
      "Epoch 112/1000\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.0370e-0 - 0s 627us/step - loss: 8.2341e-08 - val_loss: 7.5217e-05\n",
      "Epoch 113/1000\n",
      "148/148 [==============================] - 0s 815us/step - loss: 8.0032e-08 - val_loss: 7.4420e-05\n",
      "Epoch 114/1000\n",
      "148/148 [==============================] - 0s 290us/step - loss: 8.0385e-08 - val_loss: 7.5200e-05\n",
      "Epoch 115/1000\n",
      "148/148 [==============================] - 0s 263us/step - loss: 7.8946e-08 - val_loss: 7.3899e-05\n",
      "Epoch 116/1000\n",
      "148/148 [==============================] - 0s 270us/step - loss: 7.6735e-08 - val_loss: 7.5371e-05\n",
      "Epoch 117/1000\n",
      "148/148 [==============================] - 0s 229us/step - loss: 7.5986e-08 - val_loss: 7.3953e-05\n",
      "Epoch 118/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 7.5368e-08 - val_loss: 7.4456e-05\n",
      "Epoch 119/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.2814e-08 - val_loss: 7.4157e-05\n",
      "Epoch 120/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.1034e-08 - val_loss: 7.4235e-05\n",
      "Epoch 121/1000\n",
      "148/148 [==============================] - 0s 176us/step - loss: 7.1223e-08 - val_loss: 7.4022e-05\n",
      "Epoch 122/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.9854e-08 - val_loss: 7.4079e-05\n",
      "Epoch 123/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.8106e-08 - val_loss: 7.3717e-05\n",
      "Epoch 124/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.7731e-08 - val_loss: 7.3763e-05\n",
      "Epoch 125/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.7067e-08 - val_loss: 7.3305e-05\n",
      "Epoch 126/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.7158e-08 - val_loss: 7.3251e-05\n",
      "Epoch 127/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.4291e-08 - val_loss: 7.4233e-05\n",
      "Epoch 128/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.5553e-08 - val_loss: 7.2704e-05\n",
      "Epoch 129/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.6899e-08 - val_loss: 7.2736e-05\n",
      "Epoch 130/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.3703e-08 - val_loss: 7.4024e-05\n",
      "Epoch 131/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.1500e-08 - val_loss: 7.1769e-05\n",
      "Epoch 132/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.1333e-08 - val_loss: 7.4349e-05\n",
      "Epoch 133/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.1276e-08 - val_loss: 7.1914e-05\n",
      "Epoch 134/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.8598e-08 - val_loss: 7.4002e-05\n",
      "Epoch 135/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 5.9067e-08 - val_loss: 7.1542e-05\n",
      "Epoch 136/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.9030e-08 - val_loss: 7.3140e-05\n",
      "Epoch 137/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.6284e-08 - val_loss: 7.2227e-05\n",
      "Epoch 138/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.5200e-08 - val_loss: 7.2625e-05\n",
      "Epoch 139/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.4537e-08 - val_loss: 7.2374e-05\n",
      "Epoch 140/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.3776e-08 - val_loss: 7.2194e-05\n",
      "Epoch 141/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.3267e-08 - val_loss: 7.2237e-05\n",
      "Epoch 142/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 5.2274e-08 - val_loss: 7.1558e-05\n",
      "Epoch 143/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.1837e-08 - val_loss: 7.2242e-05\n",
      "Epoch 144/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 5.1391e-08 - val_loss: 7.1657e-05\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 141us/step - loss: 5.1857e-08 - val_loss: 7.2645e-05\n",
      "Epoch 146/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 5.2626e-08 - val_loss: 7.0498e-05\n",
      "Epoch 147/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.2144e-08 - val_loss: 7.2004e-05\n",
      "Epoch 148/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.1797e-08 - val_loss: 7.1629e-05\n",
      "Epoch 149/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.9614e-08 - val_loss: 7.1700e-05\n",
      "Epoch 150/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.9173e-08 - val_loss: 7.2043e-05\n",
      "Epoch 151/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.7098e-08 - val_loss: 7.1137e-05\n",
      "Epoch 152/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.6636e-08 - val_loss: 7.1821e-05\n",
      "Epoch 153/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.6868e-08 - val_loss: 7.1469e-05\n",
      "Epoch 154/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.5749e-08 - val_loss: 7.1636e-05\n",
      "Epoch 155/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.5200e-08 - val_loss: 7.1304e-05\n",
      "Epoch 156/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.5460e-08 - val_loss: 7.1370e-05\n",
      "Epoch 157/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.4172e-08 - val_loss: 7.1326e-05\n",
      "Epoch 158/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.3667e-08 - val_loss: 7.0464e-05\n",
      "Epoch 159/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.5549e-08 - val_loss: 7.1049e-05\n",
      "Epoch 160/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.4112e-08 - val_loss: 7.0893e-05\n",
      "Epoch 161/1000\n",
      "148/148 [==============================] - 0s 161us/step - loss: 4.3172e-08 - val_loss: 7.1286e-05\n",
      "Epoch 162/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.2219e-08 - val_loss: 7.0812e-05\n",
      "Epoch 163/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.1487e-08 - val_loss: 7.0160e-05\n",
      "Epoch 164/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1384e-08 - val_loss: 7.0906e-05\n",
      "Epoch 165/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.9441e-08 - val_loss: 7.0772e-05\n",
      "Epoch 166/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.0452e-08 - val_loss: 7.1236e-05\n",
      "Epoch 167/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8295e-08 - val_loss: 7.0791e-05\n",
      "Epoch 168/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.8692e-08 - val_loss: 7.0070e-05\n",
      "Epoch 169/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 3.8121e-08 - val_loss: 7.0449e-05\n",
      "Epoch 170/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.9328e-08 - val_loss: 7.1388e-05\n",
      "Epoch 171/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.8652e-08 - val_loss: 7.0498e-05\n",
      "Epoch 172/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.6932e-08 - val_loss: 7.0400e-05\n",
      "Epoch 173/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.7389e-08 - val_loss: 7.0466e-05\n",
      "Epoch 174/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.7595e-08 - val_loss: 7.0574e-05\n",
      "Epoch 175/1000\n",
      "148/148 [==============================] - 0s 145us/step - loss: 3.6225e-08 - val_loss: 7.0679e-05\n",
      "Epoch 176/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.6003e-08 - val_loss: 7.0689e-05\n",
      "Epoch 177/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.5224e-08 - val_loss: 7.0058e-05\n",
      "Epoch 178/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.5592e-08 - val_loss: 7.0288e-05\n",
      "Epoch 179/1000\n",
      "148/148 [==============================] - 0s 150us/step - loss: 3.4771e-08 - val_loss: 7.0142e-05\n",
      "Epoch 180/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.4295e-08 - val_loss: 7.0836e-05\n",
      "Epoch 181/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4517e-08 - val_loss: 7.0463e-05\n",
      "Epoch 182/1000\n",
      "148/148 [==============================] - 0s 192us/step - loss: 3.2373e-08 - val_loss: 7.0373e-05\n",
      "Epoch 183/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.2850e-08 - val_loss: 7.0141e-05\n",
      "Epoch 184/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2936e-08 - val_loss: 7.0552e-05\n",
      "Epoch 185/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.3148e-08 - val_loss: 6.9524e-05\n",
      "Epoch 186/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.3384e-08 - val_loss: 7.1716e-05\n",
      "Epoch 187/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.3442e-08 - val_loss: 7.0039e-05\n",
      "Epoch 188/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.1171e-08 - val_loss: 7.0373e-05\n",
      "Epoch 189/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.0346e-08 - val_loss: 7.0356e-05\n",
      "Epoch 190/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.9679e-08 - val_loss: 7.0538e-05\n",
      "Epoch 191/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.0363e-08 - val_loss: 7.0274e-05\n",
      "Epoch 192/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.1604e-08 - val_loss: 6.9912e-05\n",
      "Epoch 193/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.0531e-08 - val_loss: 7.0670e-05\n",
      "Epoch 194/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.9919e-08 - val_loss: 7.0734e-05\n",
      "Epoch 195/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.9303e-08 - val_loss: 6.9988e-05\n",
      "Epoch 196/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.8369e-08 - val_loss: 7.0540e-05\n",
      "Epoch 197/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8330e-08 - val_loss: 6.9851e-05\n",
      "Epoch 198/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.8056e-08 - val_loss: 7.0431e-05\n",
      "Epoch 199/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.8989e-08 - val_loss: 7.0414e-05\n",
      "Epoch 200/1000\n",
      "148/148 [==============================] - 0s 176us/step - loss: 2.8405e-08 - val_loss: 7.0449e-05\n",
      "Epoch 201/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.8574e-08 - val_loss: 6.9956e-05\n",
      "Epoch 202/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.8556e-08 - val_loss: 7.0197e-05\n",
      "Epoch 203/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.7184e-08 - val_loss: 6.9620e-05\n",
      "Epoch 204/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.7895e-08 - val_loss: 7.0767e-05\n",
      "Epoch 205/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 2.9527e-08 - val_loss: 6.8941e-05\n",
      "Epoch 206/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2564e-08 - val_loss: 7.1680e-05\n",
      "Epoch 207/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.2263e-08 - val_loss: 6.9048e-05\n",
      "Epoch 208/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.0880e-08 - val_loss: 7.1701e-05\n",
      "Epoch 209/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.0623e-08 - val_loss: 6.9227e-05\n",
      "Epoch 210/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.8392e-08 - val_loss: 7.1664e-05\n",
      "Epoch 211/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.6484e-08 - val_loss: 6.9725e-05\n",
      "Epoch 212/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.6401e-08 - val_loss: 7.1063e-05\n",
      "Epoch 213/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.5359e-08 - val_loss: 7.1181e-05\n",
      "Epoch 214/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.6636e-08 - val_loss: 7.0270e-05\n",
      "Epoch 215/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.6346e-08 - val_loss: 7.1792e-05\n",
      "Epoch 216/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.5343e-08 - val_loss: 7.0251e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.4997e-08 - val_loss: 7.1006e-05\n",
      "Epoch 218/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.3075e-08 - val_loss: 7.0150e-05\n",
      "Epoch 219/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.3498e-08 - val_loss: 7.1259e-05\n",
      "Epoch 220/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.3149e-08 - val_loss: 6.9988e-05\n",
      "Epoch 221/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.2976e-08 - val_loss: 7.1253e-05\n",
      "Epoch 222/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.4146e-08 - val_loss: 6.9490e-05\n",
      "Epoch 223/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4018e-08 - val_loss: 7.0899e-05\n",
      "Epoch 224/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4477e-08 - val_loss: 7.0341e-05\n",
      "Epoch 225/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.3291e-08 - val_loss: 7.0539e-05\n",
      "Epoch 226/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2183e-08 - val_loss: 7.0494e-05\n",
      "Epoch 227/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2004e-08 - val_loss: 7.0228e-05\n",
      "Epoch 228/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.1979e-08 - val_loss: 7.1376e-05\n",
      "Epoch 229/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.1689e-08 - val_loss: 6.9994e-05\n",
      "Epoch 230/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.0752e-08 - val_loss: 7.1080e-05\n",
      "Epoch 231/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1153e-08 - val_loss: 7.0503e-05\n",
      "Epoch 232/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.0536e-08 - val_loss: 7.0620e-05\n",
      "Epoch 233/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0948e-08 - val_loss: 7.1268e-05\n",
      "Epoch 234/1000\n",
      "148/148 [==============================] - 0s 146us/step - loss: 2.1052e-08 - val_loss: 7.0127e-05\n",
      "Epoch 235/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0468e-08 - val_loss: 7.0310e-05\n",
      "Epoch 236/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0548e-08 - val_loss: 7.0894e-05\n",
      "Epoch 237/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1218e-08 - val_loss: 7.0284e-05\n",
      "Epoch 238/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0551e-08 - val_loss: 7.0964e-05\n",
      "Epoch 239/1000\n",
      "148/148 [==============================] - 0s 176us/step - loss: 1.9560e-08 - val_loss: 6.9995e-05\n",
      "Epoch 240/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.0385e-08 - val_loss: 7.1569e-05\n",
      "Epoch 241/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.9904e-08 - val_loss: 7.0202e-05\n",
      "Epoch 242/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0010e-08 - val_loss: 7.0804e-05\n",
      "Epoch 243/1000\n",
      "148/148 [==============================] - 0s 431us/step - loss: 1.9524e-08 - val_loss: 7.0774e-05\n",
      "Epoch 244/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.0359e-08 - val_loss: 7.0213e-05\n",
      "Epoch 245/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.8975e-08 - val_loss: 7.1167e-05\n",
      "Epoch 246/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.8825e-08 - val_loss: 7.0247e-05\n",
      "Epoch 247/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.9364e-08 - val_loss: 7.0685e-05\n",
      "Epoch 248/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9217e-08 - val_loss: 7.1214e-05\n",
      "Epoch 249/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.9186e-08 - val_loss: 6.9921e-05\n",
      "Epoch 250/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.9894e-08 - val_loss: 7.2395e-05\n",
      "Epoch 251/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.2552e-08 - val_loss: 6.9239e-05\n",
      "Epoch 252/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.9674e-08 - val_loss: 7.1308e-05\n",
      "Epoch 253/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0234e-08 - val_loss: 7.1522e-05\n",
      "Epoch 254/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9816e-08 - val_loss: 7.0183e-05\n",
      "Epoch 255/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.1423e-08 - val_loss: 7.2163e-05\n",
      "Epoch 256/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.1947e-08 - val_loss: 6.9588e-05\n",
      "Epoch 257/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.1311e-08 - val_loss: 7.1253e-05\n",
      "Epoch 258/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7693e-08 - val_loss: 7.0974e-05\n",
      "Epoch 259/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7527e-08 - val_loss: 7.0351e-05\n",
      "Epoch 260/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.7027e-08 - val_loss: 7.1104e-05\n",
      "Epoch 261/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6445e-08 - val_loss: 7.0150e-05\n",
      "Epoch 262/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6482e-08 - val_loss: 7.1111e-05\n",
      "Epoch 263/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.6493e-08 - val_loss: 6.9950e-05\n",
      "Epoch 264/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6564e-08 - val_loss: 7.1330e-05\n",
      "Epoch 265/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.6466e-08 - val_loss: 7.0053e-05\n",
      "Epoch 266/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.6624e-08 - val_loss: 7.0660e-05\n",
      "Epoch 267/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.6324e-08 - val_loss: 7.0186e-05\n",
      "Epoch 268/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5873e-08 - val_loss: 7.0500e-05\n",
      "Epoch 269/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5866e-08 - val_loss: 6.9975e-05\n",
      "Epoch 270/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6039e-08 - val_loss: 7.0138e-05\n",
      "Epoch 271/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 1.5856e-08 - val_loss: 6.9860e-05\n",
      "Epoch 272/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6522e-08 - val_loss: 7.0694e-05\n",
      "Epoch 273/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6005e-08 - val_loss: 6.9517e-05\n",
      "Epoch 274/1000\n",
      "148/148 [==============================] - 0s 191us/step - loss: 1.5401e-08 - val_loss: 7.0677e-05\n",
      "Epoch 275/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 1.6438e-08 - val_loss: 6.9162e-05\n",
      "Epoch 276/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.5993e-08 - val_loss: 7.0682e-05\n",
      "Epoch 277/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.5334e-08 - val_loss: 6.9936e-05\n",
      "Epoch 278/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 1.5606e-08 - val_loss: 6.9785e-05\n",
      "Epoch 279/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6026e-08 - val_loss: 7.0712e-05\n",
      "Epoch 280/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.6997e-08 - val_loss: 6.8694e-05\n",
      "Epoch 281/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.5621e-08 - val_loss: 7.1891e-05\n",
      "Epoch 282/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 4.2119e-08 - val_loss: 7.0191e-05\n",
      "Epoch 283/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 3.7583e-08 - val_loss: 6.9749e-05\n",
      "Epoch 284/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.3618e-08 - val_loss: 7.0800e-05\n",
      "Epoch 285/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 7.6137e-08 - val_loss: 6.9853e-05\n",
      "Epoch 286/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.5611e-08 - val_loss: 7.1213e-05\n",
      "Epoch 287/1000\n",
      "148/148 [==============================] - 0s 183us/step - loss: 2.7051e-08 - val_loss: 6.9267e-05\n",
      "Epoch 288/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.2881e-08 - val_loss: 7.1429e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 4.1414e-08 - val_loss: 7.0110e-05\n",
      "Epoch 290/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4731e-08 - val_loss: 7.0185e-05\n",
      "Epoch 291/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.2781e-08 - val_loss: 7.0752e-05\n",
      "Epoch 292/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.0514e-08 - val_loss: 6.9511e-05\n",
      "Epoch 293/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.5108e-08 - val_loss: 7.0625e-05\n",
      "Epoch 294/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5464e-08 - val_loss: 7.0311e-05\n",
      "Epoch 295/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3953e-08 - val_loss: 7.0369e-05\n",
      "Epoch 296/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.4195e-08 - val_loss: 6.9336e-05\n",
      "Epoch 297/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3777e-08 - val_loss: 7.1179e-05\n",
      "Epoch 298/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3749e-08 - val_loss: 6.9682e-05\n",
      "Epoch 299/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3372e-08 - val_loss: 7.2020e-05\n",
      "Epoch 300/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5455e-08 - val_loss: 6.9149e-05\n",
      "Epoch 301/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7006e-08 - val_loss: 7.0624e-05\n",
      "Epoch 302/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3554e-08 - val_loss: 7.1285e-05\n",
      "Epoch 303/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4762e-08 - val_loss: 6.9859e-05\n",
      "Epoch 304/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4916e-08 - val_loss: 7.1968e-05\n",
      "Epoch 305/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2786e-08 - val_loss: 7.0178e-05\n",
      "Epoch 306/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2930e-08 - val_loss: 7.0580e-05\n",
      "Epoch 307/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2922e-08 - val_loss: 7.0362e-05\n",
      "Epoch 308/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3060e-08 - val_loss: 6.9887e-05\n",
      "Epoch 309/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4619e-08 - val_loss: 7.0762e-05\n",
      "Epoch 310/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.3292e-08 - val_loss: 6.9610e-05\n",
      "Epoch 311/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3617e-08 - val_loss: 7.0908e-05\n",
      "Epoch 312/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3584e-08 - val_loss: 6.9766e-05\n",
      "Epoch 313/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3958e-08 - val_loss: 7.0246e-05\n",
      "Epoch 314/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.4014e-08 - val_loss: 7.1056e-05\n",
      "Epoch 315/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2382e-08 - val_loss: 7.0473e-05\n",
      "Epoch 316/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1950e-08 - val_loss: 6.9921e-05\n",
      "Epoch 317/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2096e-08 - val_loss: 7.0719e-05\n",
      "Epoch 318/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1779e-08 - val_loss: 7.0400e-05\n",
      "Epoch 319/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1564e-08 - val_loss: 6.9872e-05\n",
      "Epoch 320/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1589e-08 - val_loss: 7.0882e-05\n",
      "Epoch 321/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.1922e-08 - val_loss: 7.0259e-05\n",
      "Epoch 322/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1101e-08 - val_loss: 7.0214e-05\n",
      "Epoch 323/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1546e-08 - val_loss: 7.0388e-05\n",
      "Epoch 324/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1878e-08 - val_loss: 6.9937e-05\n",
      "Epoch 325/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1466e-08 - val_loss: 6.9699e-05\n",
      "Epoch 326/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2901e-08 - val_loss: 7.0827e-05\n",
      "Epoch 327/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2654e-08 - val_loss: 6.9158e-05\n",
      "Epoch 328/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2537e-08 - val_loss: 7.0947e-05\n",
      "Epoch 329/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1679e-08 - val_loss: 7.0471e-05\n",
      "Epoch 330/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1408e-08 - val_loss: 7.0011e-05\n",
      "Epoch 331/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0895e-08 - val_loss: 7.0941e-05\n",
      "Epoch 332/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1553e-08 - val_loss: 7.0321e-05\n",
      "Epoch 333/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2722e-08 - val_loss: 7.0252e-05\n",
      "Epoch 334/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1543e-08 - val_loss: 7.0572e-05\n",
      "Epoch 335/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0927e-08 - val_loss: 6.9642e-05\n",
      "Epoch 336/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1128e-08 - val_loss: 7.0327e-05\n",
      "Epoch 337/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0887e-08 - val_loss: 7.1505e-05\n",
      "Epoch 338/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.1238e-08 - val_loss: 6.9001e-05\n",
      "Epoch 339/1000\n",
      "148/148 [==============================] - 0s 179us/step - loss: 1.1866e-08 - val_loss: 7.0840e-05\n",
      "Epoch 340/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2128e-08 - val_loss: 7.1676e-05\n",
      "Epoch 341/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2286e-08 - val_loss: 6.9283e-05\n",
      "Epoch 342/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3291e-08 - val_loss: 7.1991e-05\n",
      "Epoch 343/1000\n",
      "148/148 [==============================] - 0s 145us/step - loss: 1.3686e-08 - val_loss: 7.0154e-05\n",
      "Epoch 344/1000\n",
      "148/148 [==============================] - 0s 151us/step - loss: 1.3182e-08 - val_loss: 6.9062e-05\n",
      "Epoch 345/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5626e-08 - val_loss: 7.3208e-05\n",
      "Epoch 346/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2424e-08 - val_loss: 7.0028e-05\n",
      "Epoch 347/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2890e-08 - val_loss: 7.2061e-05\n",
      "Epoch 348/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1737e-08 - val_loss: 7.2045e-05\n",
      "Epoch 349/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2629e-08 - val_loss: 6.9488e-05\n",
      "Epoch 350/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2527e-08 - val_loss: 7.2067e-05\n",
      "Epoch 351/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2809e-08 - val_loss: 7.0745e-05\n",
      "Epoch 352/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2920e-08 - val_loss: 6.9117e-05\n",
      "Epoch 353/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.1037e-08 - val_loss: 7.1252e-05\n",
      "Epoch 354/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 9.6868e-09 - val_loss: 6.9616e-05\n",
      "Epoch 355/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0508e-08 - val_loss: 7.1172e-05\n",
      "Epoch 356/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.0668e-08 - val_loss: 6.9744e-05\n",
      "Epoch 357/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.3127e-08 - val_loss: 6.8308e-05\n",
      "Epoch 358/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.5110e-08 - val_loss: 7.2798e-05\n",
      "Epoch 359/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3941e-08 - val_loss: 6.9670e-05\n",
      "Epoch 360/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2734e-08 - val_loss: 6.9119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3621e-08 - val_loss: 7.1701e-05\n",
      "Epoch 362/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1226e-08 - val_loss: 7.0765e-05\n",
      "Epoch 363/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3419e-08 - val_loss: 6.9320e-05\n",
      "Epoch 364/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6061e-08 - val_loss: 7.2502e-05\n",
      "Epoch 365/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1636e-08 - val_loss: 7.0513e-05\n",
      "Epoch 366/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.8239e-08 - val_loss: 7.0172e-05\n",
      "Epoch 367/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2876e-08 - val_loss: 7.1238e-05\n",
      "Epoch 368/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2014e-08 - val_loss: 6.9897e-05\n",
      "Epoch 369/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1413e-08 - val_loss: 7.0169e-05\n",
      "Epoch 370/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.1069e-08 - val_loss: 7.0900e-05\n",
      "Epoch 371/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0297e-08 - val_loss: 7.0474e-05\n",
      "Epoch 372/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0953e-08 - val_loss: 7.0457e-05\n",
      "Epoch 373/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1155e-08 - val_loss: 7.0089e-05\n",
      "Epoch 374/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.0650e-08 - val_loss: 6.9743e-05\n",
      "Epoch 375/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 9.1883e-09 - val_loss: 7.0619e-05\n",
      "Epoch 376/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.6548e-09 - val_loss: 6.8989e-05\n",
      "Epoch 377/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.6978e-09 - val_loss: 7.0729e-05\n",
      "Epoch 378/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0121e-08 - val_loss: 7.1814e-05\n",
      "Epoch 379/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0381e-08 - val_loss: 6.9512e-05\n",
      "Epoch 380/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 9.9673e-09 - val_loss: 6.9946e-05\n",
      "Epoch 381/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.7562e-09 - val_loss: 7.1192e-05\n",
      "Epoch 382/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.9459e-09 - val_loss: 7.0852e-05\n",
      "Epoch 383/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0145e-08 - val_loss: 6.9596e-05\n",
      "Epoch 384/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3555e-08 - val_loss: 7.0570e-05\n",
      "Epoch 385/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3755e-08 - val_loss: 7.1006e-05\n",
      "Epoch 386/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3159e-08 - val_loss: 6.9150e-05\n",
      "Epoch 387/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.3656e-08 - val_loss: 7.0586e-05\n",
      "Epoch 388/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3439e-08 - val_loss: 6.9697e-05\n",
      "Epoch 389/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1543e-08 - val_loss: 7.0424e-05\n",
      "Epoch 390/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7469e-08 - val_loss: 7.0206e-05\n",
      "Epoch 391/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.5074e-08 - val_loss: 7.0371e-05\n",
      "Epoch 392/1000\n",
      "148/148 [==============================] - 0s 143us/step - loss: 1.4162e-07 - val_loss: 7.0831e-05\n",
      "Epoch 393/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3994e-07 - val_loss: 7.0386e-05\n",
      "Epoch 394/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.4779e-07 - val_loss: 6.9343e-05\n",
      "Epoch 395/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.7151e-07 - val_loss: 7.0077e-05\n",
      "Epoch 396/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6950e-06 - val_loss: 6.9543e-05\n",
      "Epoch 397/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.4437e-07 - val_loss: 7.0950e-05\n",
      "Epoch 398/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.5558e-06 - val_loss: 6.6180e-05\n",
      "Epoch 399/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2959e-06 - val_loss: 6.7440e-05\n",
      "Epoch 400/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.2286e-07 - val_loss: 7.3572e-05\n",
      "Epoch 401/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.6598e-07 - val_loss: 6.8901e-05\n",
      "Epoch 402/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.4877e-07 - val_loss: 6.6931e-05\n",
      "Epoch 403/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.9002e-07 - val_loss: 7.3084e-05\n",
      "Epoch 404/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3664e-07 - val_loss: 7.3516e-05\n",
      "Epoch 405/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 3.3145e-07 - val_loss: 7.0786e-05\n",
      "Epoch 406/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.4411e-07 - val_loss: 7.1274e-05\n",
      "Epoch 407/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.5070e-06 - val_loss: 7.4264e-05\n",
      "Epoch 408/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5367e-06 - val_loss: 6.6788e-05\n",
      "Epoch 409/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1379e-06 - val_loss: 7.2511e-05\n",
      "Epoch 410/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.1605e-06 - val_loss: 7.1128e-05\n",
      "Epoch 411/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.0907e-06 - val_loss: 6.9271e-05\n",
      "Epoch 412/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.4526e-06 - val_loss: 6.9953e-05\n",
      "Epoch 413/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.9493e-06 - val_loss: 6.9959e-05\n",
      "Epoch 414/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4852e-06 - val_loss: 7.3279e-05\n",
      "Epoch 415/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.0361e-06 - val_loss: 6.8121e-05\n",
      "Epoch 416/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.9608e-07 - val_loss: 7.0845e-05\n",
      "Epoch 417/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.0057e-06 - val_loss: 8.4258e-05\n",
      "Epoch 418/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.8752e-06 - val_loss: 6.3760e-05\n",
      "Epoch 419/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.5605e-06 - val_loss: 6.7905e-05\n",
      "Epoch 420/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.4124e-06 - val_loss: 7.6003e-05\n",
      "Epoch 421/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2698e-06 - val_loss: 7.5864e-05\n",
      "Epoch 422/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.7129e-06 - val_loss: 7.4485e-05\n",
      "Epoch 423/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.4845e-06 - val_loss: 6.7519e-05\n",
      "Epoch 424/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.8650e-06 - val_loss: 7.2461e-05\n",
      "Epoch 425/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.4736e-07 - val_loss: 7.3563e-05\n",
      "Epoch 426/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.0136e-06 - val_loss: 7.0621e-05\n",
      "Epoch 427/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.1533e-07 - val_loss: 7.0691e-05\n",
      "Epoch 428/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 7.8273e-08 - val_loss: 7.3833e-05\n",
      "Epoch 429/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.6353e-07 - val_loss: 7.1915e-05\n",
      "Epoch 430/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.0125e-08 - val_loss: 6.8883e-05\n",
      "Epoch 431/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.5005e-07 - val_loss: 7.1682e-05\n",
      "Epoch 432/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.1028e-08 - val_loss: 7.2038e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.3206e-08 - val_loss: 7.1668e-05\n",
      "Epoch 434/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.8819e-08 - val_loss: 7.0981e-05\n",
      "Epoch 435/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1712e-07 - val_loss: 7.0406e-05\n",
      "Epoch 436/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.7134e-08 - val_loss: 7.0340e-05\n",
      "Epoch 437/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.6574e-08 - val_loss: 7.0554e-05\n",
      "Epoch 438/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.2197e-08 - val_loss: 6.9988e-05\n",
      "Epoch 439/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.7314e-08 - val_loss: 7.0044e-05\n",
      "Epoch 440/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8383e-08 - val_loss: 7.0722e-05\n",
      "Epoch 441/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.5111e-08 - val_loss: 7.0398e-05\n",
      "Epoch 442/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.7859e-08 - val_loss: 7.0133e-05\n",
      "Epoch 443/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.5295e-08 - val_loss: 7.0546e-05\n",
      "Epoch 444/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.8068e-08 - val_loss: 7.0099e-05\n",
      "Epoch 445/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.5761e-08 - val_loss: 6.8431e-05\n",
      "Epoch 446/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.5748e-08 - val_loss: 7.2658e-05\n",
      "Epoch 447/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.9196e-07 - val_loss: 7.0153e-05\n",
      "Epoch 448/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.7348e-07 - val_loss: 7.0256e-05\n",
      "Epoch 449/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.8893e-07 - val_loss: 7.2872e-05\n",
      "Epoch 450/1000\n",
      "148/148 [==============================] - 0s 378us/step - loss: 9.2114e-07 - val_loss: 7.1293e-05\n",
      "Epoch 451/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.5901e-06 - val_loss: 6.8912e-05\n",
      "Epoch 452/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.7714e-06 - val_loss: 7.3470e-05\n",
      "Epoch 453/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9850e-05 - val_loss: 6.3491e-05\n",
      "Epoch 454/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 1.9995e-05 - val_loss: 6.9504e-05\n",
      "Epoch 455/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.9698e-05 - val_loss: 7.8790e-05\n",
      "Epoch 456/1000\n",
      "148/148 [==============================] - 0s 166us/step - loss: 1.2010e-05 - val_loss: 7.6074e-05\n",
      "Epoch 457/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3543e-05 - val_loss: 7.7019e-05\n",
      "Epoch 458/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0875e-05 - val_loss: 7.7526e-05\n",
      "Epoch 459/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.9112e-05 - val_loss: 8.0253e-05\n",
      "Epoch 460/1000\n",
      "148/148 [==============================] - 0s 222us/step - loss: 1.8493e-05 - val_loss: 7.9174e-05\n",
      "Epoch 461/1000\n",
      "148/148 [==============================] - 0s 147us/step - loss: 1.0558e-05 - val_loss: 9.4920e-05\n",
      "Epoch 462/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2691e-06 - val_loss: 8.6482e-05\n",
      "Epoch 463/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.3250e-07 - val_loss: 7.6731e-05\n",
      "Epoch 464/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.5452e-07 - val_loss: 7.6853e-05\n",
      "Epoch 465/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.3303e-08 - val_loss: 8.3366e-05\n",
      "Epoch 466/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.4714e-07 - val_loss: 7.7840e-05\n",
      "Epoch 467/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 8.9618e-08 - val_loss: 6.9990e-05\n",
      "Epoch 468/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.2017e-07 - val_loss: 7.3586e-05\n",
      "Epoch 469/1000\n",
      "148/148 [==============================] - 0s 160us/step - loss: 1.0024e-07 - val_loss: 7.6767e-05\n",
      "Epoch 470/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.4918e-08 - val_loss: 7.6751e-05\n",
      "Epoch 471/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.9947e-08 - val_loss: 7.3813e-05\n",
      "Epoch 472/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4146e-07 - val_loss: 7.0852e-05\n",
      "Epoch 473/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.6510e-08 - val_loss: 7.3555e-05\n",
      "Epoch 474/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.8863e-08 - val_loss: 7.2507e-05\n",
      "Epoch 475/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.3334e-08 - val_loss: 7.1475e-05\n",
      "Epoch 476/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.7797e-08 - val_loss: 7.1052e-05\n",
      "Epoch 477/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.5185e-08 - val_loss: 7.1788e-05\n",
      "Epoch 478/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.5890e-08 - val_loss: 7.4106e-05\n",
      "Epoch 479/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.3987e-08 - val_loss: 7.1874e-05\n",
      "Epoch 480/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0068e-07 - val_loss: 7.3647e-05\n",
      "Epoch 481/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.0950e-07 - val_loss: 7.0569e-05\n",
      "Epoch 482/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.1972e-06 - val_loss: 7.5306e-05\n",
      "Epoch 483/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.6859e-06 - val_loss: 7.1440e-05\n",
      "Epoch 484/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9612e-06 - val_loss: 7.3009e-05\n",
      "Epoch 485/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0211e-05 - val_loss: 7.1823e-05\n",
      "Epoch 486/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 9.9528e-06 - val_loss: 6.7746e-05\n",
      "Epoch 487/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9165e-05 - val_loss: 9.2302e-05\n",
      "Epoch 488/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3838e-04 - val_loss: 8.3937e-05\n",
      "Epoch 489/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 5.3170e-05 - val_loss: 9.3508e-05\n",
      "Epoch 490/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 3.7742e-05 - val_loss: 8.4049e-05\n",
      "Epoch 491/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.5257e-05 - val_loss: 6.6292e-05\n",
      "Epoch 492/1000\n",
      "148/148 [==============================] - 0s 188us/step - loss: 8.0564e-05 - val_loss: 1.1929e-04\n",
      "Epoch 493/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.8011e-05 - val_loss: 1.2194e-04\n",
      "Epoch 494/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4490e-05 - val_loss: 8.1909e-05\n",
      "Epoch 495/1000\n",
      "148/148 [==============================] - 0s 174us/step - loss: 1.7383e-05 - val_loss: 7.0896e-05\n",
      "Epoch 496/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1186e-05 - val_loss: 8.4448e-05\n",
      "Epoch 497/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.1088e-06 - val_loss: 6.9634e-05\n",
      "Epoch 498/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.7881e-06 - val_loss: 4.2731e-05\n",
      "Epoch 499/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.5568e-06 - val_loss: 6.3498e-05\n",
      "Epoch 500/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0967e-05 - val_loss: 6.0912e-05\n",
      "Epoch 501/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.4702e-05 - val_loss: 3.8697e-05\n",
      "Epoch 502/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.9171e-06 - val_loss: 4.1290e-05\n",
      "Epoch 503/1000\n",
      "148/148 [==============================] - 0s 197us/step - loss: 6.1460e-06 - val_loss: 4.9202e-05\n",
      "Epoch 504/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.0926e-06 - val_loss: 4.5480e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.4357e-06 - val_loss: 4.4143e-05\n",
      "Epoch 506/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1386e-06 - val_loss: 5.6851e-05\n",
      "Epoch 507/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.7034e-06 - val_loss: 5.2676e-05\n",
      "Epoch 508/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.8919e-06 - val_loss: 4.2761e-05\n",
      "Epoch 509/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4403e-06 - val_loss: 3.6915e-05\n",
      "Epoch 510/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.2950e-06 - val_loss: 4.3262e-05\n",
      "Epoch 511/1000\n",
      "148/148 [==============================] - 0s 138us/step - loss: 3.0243e-06 - val_loss: 4.8585e-05\n",
      "Epoch 512/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.9474e-07 - val_loss: 5.1866e-05\n",
      "Epoch 513/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.9181e-07 - val_loss: 4.5306e-05\n",
      "Epoch 514/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0113e-06 - val_loss: 4.4047e-05\n",
      "Epoch 515/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.2119e-07 - val_loss: 5.4542e-05\n",
      "Epoch 516/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 7.9236e-07 - val_loss: 5.5747e-05\n",
      "Epoch 517/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2943e-06 - val_loss: 4.1532e-05\n",
      "Epoch 518/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0048e-06 - val_loss: 4.3175e-05\n",
      "Epoch 519/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.6258e-07 - val_loss: 5.0474e-05\n",
      "Epoch 520/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.6389e-06 - val_loss: 4.5670e-05\n",
      "Epoch 521/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.9207e-06 - val_loss: 3.8982e-05\n",
      "Epoch 522/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.5866e-07 - val_loss: 4.0017e-05\n",
      "Epoch 523/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.5938e-07 - val_loss: 4.2092e-05\n",
      "Epoch 524/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.2938e-07 - val_loss: 4.7134e-05\n",
      "Epoch 525/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 1.7211e-07 - val_loss: 4.5224e-05\n",
      "Epoch 526/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.0154e-07 - val_loss: 4.2311e-05\n",
      "Epoch 527/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1255e-07 - val_loss: 4.4716e-05\n",
      "Epoch 528/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.6863e-07 - val_loss: 5.1522e-05\n",
      "Epoch 529/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.2840e-07 - val_loss: 4.9069e-05\n",
      "Epoch 530/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.6201e-07 - val_loss: 4.4073e-05\n",
      "Epoch 531/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.4776e-07 - val_loss: 4.3788e-05\n",
      "Epoch 532/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.0355e-07 - val_loss: 4.7410e-05\n",
      "Epoch 533/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.0793e-07 - val_loss: 5.0555e-05\n",
      "Epoch 534/1000\n",
      "148/148 [==============================] - 0s 145us/step - loss: 3.3499e-07 - val_loss: 4.7215e-05\n",
      "Epoch 535/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5480e-07 - val_loss: 4.1736e-05\n",
      "Epoch 536/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.6411e-07 - val_loss: 4.5195e-05\n",
      "Epoch 537/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.1955e-07 - val_loss: 5.0712e-05\n",
      "Epoch 538/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1541e-07 - val_loss: 5.0564e-05\n",
      "Epoch 539/1000\n",
      "148/148 [==============================] - 0s 158us/step - loss: 1.4794e-07 - val_loss: 4.7587e-05\n",
      "Epoch 540/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7302e-07 - val_loss: 4.6319e-05\n",
      "Epoch 541/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.0894e-07 - val_loss: 4.2580e-05\n",
      "Epoch 542/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.9253e-08 - val_loss: 4.1049e-05\n",
      "Epoch 543/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.1279e-08 - val_loss: 4.1202e-05\n",
      "Epoch 544/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.3446e-08 - val_loss: 4.2471e-05\n",
      "Epoch 545/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.9735e-08 - val_loss: 4.4968e-05\n",
      "Epoch 546/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.3181e-08 - val_loss: 4.3363e-05\n",
      "Epoch 547/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.6504e-08 - val_loss: 4.2339e-05\n",
      "Epoch 548/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.7745e-08 - val_loss: 4.3189e-05\n",
      "Epoch 549/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.7725e-08 - val_loss: 4.0278e-05\n",
      "Epoch 550/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.6415e-08 - val_loss: 3.8270e-05\n",
      "Epoch 551/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.1347e-08 - val_loss: 3.9173e-05\n",
      "Epoch 552/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.5077e-08 - val_loss: 4.7441e-05\n",
      "Epoch 553/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.2634e-08 - val_loss: 4.4645e-05\n",
      "Epoch 554/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.0485e-08 - val_loss: 4.2854e-05\n",
      "Epoch 555/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 7.0159e-08 - val_loss: 4.0716e-05\n",
      "Epoch 556/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 4.6097e-08 - val_loss: 3.7386e-05\n",
      "Epoch 557/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.1094e-08 - val_loss: 4.2936e-05\n",
      "Epoch 558/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.2433e-08 - val_loss: 4.6126e-05\n",
      "Epoch 559/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.5495e-08 - val_loss: 4.6165e-05\n",
      "Epoch 560/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.6505e-08 - val_loss: 4.6325e-05\n",
      "Epoch 561/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.3533e-08 - val_loss: 4.5860e-05\n",
      "Epoch 562/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.2970e-08 - val_loss: 4.1952e-05\n",
      "Epoch 563/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1180e-08 - val_loss: 4.2647e-05\n",
      "Epoch 564/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.3613e-08 - val_loss: 4.3210e-05\n",
      "Epoch 565/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.0662e-08 - val_loss: 4.2812e-05\n",
      "Epoch 566/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3557e-07 - val_loss: 4.2572e-05\n",
      "Epoch 567/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.9532e-07 - val_loss: 4.1801e-05\n",
      "Epoch 568/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.5734e-07 - val_loss: 4.1104e-05\n",
      "Epoch 569/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 4.5083e-07 - val_loss: 3.9558e-05\n",
      "Epoch 570/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 4.7123e-07 - val_loss: 4.0294e-05\n",
      "Epoch 571/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.6391e-06 - val_loss: 3.9745e-05\n",
      "Epoch 572/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.2469e-06 - val_loss: 3.5209e-05\n",
      "Epoch 573/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7602e-05 - val_loss: 6.4246e-05\n",
      "Epoch 574/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.9499e-05 - val_loss: 5.1527e-05\n",
      "Epoch 575/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 3.8537e-05 - val_loss: 4.3881e-05\n",
      "Epoch 576/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.0940e-05 - val_loss: 6.4793e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.9217e-05 - val_loss: 4.8700e-05\n",
      "Epoch 578/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.3651e-05 - val_loss: 6.8698e-05\n",
      "Epoch 579/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2932e-05 - val_loss: 6.9035e-05\n",
      "Epoch 580/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.1548e-05 - val_loss: 4.7844e-05\n",
      "Epoch 581/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3606e-05 - val_loss: 4.5474e-05\n",
      "Epoch 582/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 9.8012e-06 - val_loss: 5.8898e-05\n",
      "Epoch 583/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.0887e-06 - val_loss: 6.0918e-05\n",
      "Epoch 584/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.6884e-06 - val_loss: 5.8961e-05\n",
      "Epoch 585/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 6.6469e-07 - val_loss: 5.6493e-05\n",
      "Epoch 586/1000\n",
      "148/148 [==============================] - 0s 153us/step - loss: 2.7894e-07 - val_loss: 5.1245e-05\n",
      "Epoch 587/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.4417e-07 - val_loss: 5.2211e-05\n",
      "Epoch 588/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6622e-07 - val_loss: 5.4542e-05\n",
      "Epoch 589/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1672e-07 - val_loss: 5.3294e-05\n",
      "Epoch 590/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.0643e-07 - val_loss: 5.6428e-05\n",
      "Epoch 591/1000\n",
      "148/148 [==============================] - 0s 147us/step - loss: 8.2390e-08 - val_loss: 5.6104e-05\n",
      "Epoch 592/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 9.3059e-08 - val_loss: 5.3168e-05\n",
      "Epoch 593/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.3768e-08 - val_loss: 5.0151e-05\n",
      "Epoch 594/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 8.8811e-08 - val_loss: 5.2678e-05\n",
      "Epoch 595/1000\n",
      "148/148 [==============================] - 0s 144us/step - loss: 9.2995e-08 - val_loss: 5.2027e-05\n",
      "Epoch 596/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.5282e-08 - val_loss: 5.3065e-05\n",
      "Epoch 597/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1817e-07 - val_loss: 5.3922e-05\n",
      "Epoch 598/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.1176e-07 - val_loss: 5.4581e-05\n",
      "Epoch 599/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.5375e-08 - val_loss: 5.5600e-05\n",
      "Epoch 600/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.9314e-08 - val_loss: 5.4329e-05\n",
      "Epoch 601/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.1041e-08 - val_loss: 5.3215e-05\n",
      "Epoch 602/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.9741e-08 - val_loss: 5.0846e-05\n",
      "Epoch 603/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0197e-08 - val_loss: 5.2534e-05\n",
      "Epoch 604/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 2.0917e-08 - val_loss: 5.4176e-05\n",
      "Epoch 605/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5744e-08 - val_loss: 5.4849e-05\n",
      "Epoch 606/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.4076e-08 - val_loss: 5.6631e-05\n",
      "Epoch 607/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.2536e-08 - val_loss: 5.2982e-05\n",
      "Epoch 608/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 4.2958e-08 - val_loss: 4.9970e-05\n",
      "Epoch 609/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.2914e-08 - val_loss: 5.0215e-05\n",
      "Epoch 610/1000\n",
      "148/148 [==============================] - 0s 152us/step - loss: 6.3103e-08 - val_loss: 5.1543e-05\n",
      "Epoch 611/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.5143e-08 - val_loss: 5.2109e-05\n",
      "Epoch 612/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.8863e-08 - val_loss: 5.1924e-05\n",
      "Epoch 613/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2866e-08 - val_loss: 5.3362e-05\n",
      "Epoch 614/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3168e-08 - val_loss: 5.3461e-05\n",
      "Epoch 615/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3885e-08 - val_loss: 5.2568e-05\n",
      "Epoch 616/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.6981e-08 - val_loss: 5.3130e-05\n",
      "Epoch 617/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 1.3977e-08 - val_loss: 5.3114e-05\n",
      "Epoch 618/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.4189e-08 - val_loss: 5.2695e-05\n",
      "Epoch 619/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2353e-08 - val_loss: 5.2190e-05\n",
      "Epoch 620/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5465e-08 - val_loss: 5.1839e-05\n",
      "Epoch 621/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2456e-08 - val_loss: 5.0553e-05\n",
      "Epoch 622/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.8076e-08 - val_loss: 5.0771e-05\n",
      "Epoch 623/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8903e-08 - val_loss: 5.1334e-05\n",
      "Epoch 624/1000\n",
      "148/148 [==============================] - 0s 186us/step - loss: 1.9026e-08 - val_loss: 5.1153e-05\n",
      "Epoch 625/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 1.4309e-08 - val_loss: 5.2149e-05\n",
      "Epoch 626/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2365e-08 - val_loss: 5.3536e-05\n",
      "Epoch 627/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.2079e-08 - val_loss: 5.3249e-05\n",
      "Epoch 628/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4066e-08 - val_loss: 5.2627e-05\n",
      "Epoch 629/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.3698e-08 - val_loss: 5.2249e-05\n",
      "Epoch 630/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0963e-08 - val_loss: 5.2065e-05\n",
      "Epoch 631/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.9417e-08 - val_loss: 5.0988e-05\n",
      "Epoch 632/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.2358e-08 - val_loss: 5.1775e-05\n",
      "Epoch 633/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 9.2741e-09 - val_loss: 5.1771e-05\n",
      "Epoch 634/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.7374e-09 - val_loss: 5.1502e-05\n",
      "Epoch 635/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.0407e-08 - val_loss: 5.1148e-05\n",
      "Epoch 636/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.2328e-08 - val_loss: 5.1241e-05\n",
      "Epoch 637/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.5545e-08 - val_loss: 5.1980e-05\n",
      "Epoch 638/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2838e-08 - val_loss: 5.3470e-05\n",
      "Epoch 639/1000\n",
      "148/148 [==============================] - 0s 188us/step - loss: 2.0120e-08 - val_loss: 5.4495e-05\n",
      "Epoch 640/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.8393e-08 - val_loss: 5.3302e-05\n",
      "Epoch 641/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.5402e-08 - val_loss: 5.4538e-05\n",
      "Epoch 642/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.0685e-08 - val_loss: 5.3472e-05\n",
      "Epoch 643/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7537e-08 - val_loss: 5.0792e-05\n",
      "Epoch 644/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.4556e-08 - val_loss: 4.8847e-05\n",
      "Epoch 645/1000\n",
      "148/148 [==============================] - 0s 176us/step - loss: 2.1336e-08 - val_loss: 4.9634e-05\n",
      "Epoch 646/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.4186e-08 - val_loss: 4.8687e-05\n",
      "Epoch 647/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.3904e-08 - val_loss: 4.9338e-05\n",
      "Epoch 648/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.7237e-08 - val_loss: 4.9947e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.4862e-08 - val_loss: 4.8729e-05\n",
      "Epoch 650/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5857e-08 - val_loss: 5.0280e-05\n",
      "Epoch 651/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2283e-08 - val_loss: 5.0371e-05\n",
      "Epoch 652/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2355e-08 - val_loss: 5.0784e-05\n",
      "Epoch 653/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0298e-08 - val_loss: 5.0792e-05\n",
      "Epoch 654/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0999e-08 - val_loss: 5.0007e-05\n",
      "Epoch 655/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.1899e-08 - val_loss: 5.0135e-05\n",
      "Epoch 656/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.8904e-08 - val_loss: 4.7518e-05\n",
      "Epoch 657/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.2842e-08 - val_loss: 4.6530e-05\n",
      "Epoch 658/1000\n",
      "148/148 [==============================] - 0s 144us/step - loss: 4.2786e-08 - val_loss: 4.8603e-05\n",
      "Epoch 659/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.3910e-08 - val_loss: 4.9742e-05\n",
      "Epoch 660/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.7132e-08 - val_loss: 5.0859e-05\n",
      "Epoch 661/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4368e-08 - val_loss: 5.0482e-05\n",
      "Epoch 662/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0225e-08 - val_loss: 5.0563e-05\n",
      "Epoch 663/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.1990e-08 - val_loss: 5.0235e-05\n",
      "Epoch 664/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1099e-08 - val_loss: 4.8770e-05\n",
      "Epoch 665/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.7589e-08 - val_loss: 5.0889e-05\n",
      "Epoch 666/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0223e-08 - val_loss: 5.1048e-05\n",
      "Epoch 667/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 9.3244e-09 - val_loss: 5.2051e-05\n",
      "Epoch 668/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.8414e-09 - val_loss: 5.2989e-05\n",
      "Epoch 669/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2842e-08 - val_loss: 5.2635e-05\n",
      "Epoch 670/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0333e-08 - val_loss: 5.3081e-05\n",
      "Epoch 671/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.3553e-08 - val_loss: 5.3553e-05\n",
      "Epoch 672/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.8582e-08 - val_loss: 5.2987e-05\n",
      "Epoch 673/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.5380e-08 - val_loss: 5.3328e-05\n",
      "Epoch 674/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.9300e-08 - val_loss: 5.3642e-05\n",
      "Epoch 675/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.1596e-08 - val_loss: 5.3460e-05\n",
      "Epoch 676/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5929e-07 - val_loss: 5.5452e-05\n",
      "Epoch 677/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.4493e-07 - val_loss: 5.4642e-05\n",
      "Epoch 678/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 7.3590e-08 - val_loss: 5.2891e-05\n",
      "Epoch 679/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.8945e-08 - val_loss: 5.3949e-05\n",
      "Epoch 680/1000\n",
      "148/148 [==============================] - 0s 129us/step - loss: 8.7064e-08 - val_loss: 5.1761e-05\n",
      "Epoch 681/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.3183e-07 - val_loss: 5.2962e-05\n",
      "Epoch 682/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.4303e-08 - val_loss: 5.4299e-05\n",
      "Epoch 683/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4487e-07 - val_loss: 5.2946e-05\n",
      "Epoch 684/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3223e-07 - val_loss: 5.4678e-05\n",
      "Epoch 685/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1745e-07 - val_loss: 5.3064e-05\n",
      "Epoch 686/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.9201e-08 - val_loss: 5.1666e-05\n",
      "Epoch 687/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8329e-08 - val_loss: 5.2902e-05\n",
      "Epoch 688/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.3117e-08 - val_loss: 5.0941e-05\n",
      "Epoch 689/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.5952e-08 - val_loss: 4.8991e-05\n",
      "Epoch 690/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.9839e-08 - val_loss: 5.0881e-05\n",
      "Epoch 691/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8953e-08 - val_loss: 5.1424e-05\n",
      "Epoch 692/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6969e-08 - val_loss: 5.1065e-05\n",
      "Epoch 693/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 6.7586e-08 - val_loss: 5.2177e-05\n",
      "Epoch 694/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.7289e-08 - val_loss: 5.2096e-05\n",
      "Epoch 695/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.2326e-07 - val_loss: 5.0726e-05\n",
      "Epoch 696/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7527e-07 - val_loss: 5.2129e-05\n",
      "Epoch 697/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.5264e-07 - val_loss: 5.3624e-05\n",
      "Epoch 698/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.7231e-07 - val_loss: 5.1493e-05\n",
      "Epoch 699/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 6.3505e-07 - val_loss: 5.0894e-05\n",
      "Epoch 700/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.3024e-07 - val_loss: 5.3131e-05\n",
      "Epoch 701/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 6.6058e-07 - val_loss: 5.4600e-05\n",
      "Epoch 702/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.3399e-06 - val_loss: 5.4373e-05\n",
      "Epoch 703/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.8716e-07 - val_loss: 5.3580e-05\n",
      "Epoch 704/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 4.5254e-07 - val_loss: 5.5426e-05\n",
      "Epoch 705/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.5543e-07 - val_loss: 5.5752e-05\n",
      "Epoch 706/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.2302e-07 - val_loss: 5.4070e-05\n",
      "Epoch 707/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.9504e-06 - val_loss: 6.6471e-05\n",
      "Epoch 708/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.5703e-06 - val_loss: 6.3583e-05\n",
      "Epoch 709/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 5.9388e-07 - val_loss: 7.2908e-05\n",
      "Epoch 710/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 4.2635e-07 - val_loss: 7.3396e-05\n",
      "Epoch 711/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.4725e-06 - val_loss: 6.2688e-05\n",
      "Epoch 712/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.2403e-07 - val_loss: 6.7226e-05\n",
      "Epoch 713/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8707e-06 - val_loss: 8.5372e-05\n",
      "Epoch 714/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.8015e-05 - val_loss: 9.1496e-05\n",
      "Epoch 715/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.0910e-05 - val_loss: 5.6891e-05\n",
      "Epoch 716/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.5108e-05 - val_loss: 6.8699e-05\n",
      "Epoch 717/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.8606e-05 - val_loss: 7.1274e-05\n",
      "Epoch 718/1000\n",
      "148/148 [==============================] - 0s 170us/step - loss: 1.7001e-05 - val_loss: 8.2636e-05\n",
      "Epoch 719/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.9661e-05 - val_loss: 9.5904e-05\n",
      "Epoch 720/1000\n",
      "148/148 [==============================] - 0s 209us/step - loss: 5.1712e-05 - val_loss: 6.1639e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 8.0731e-05 - val_loss: 1.1836e-04\n",
      "Epoch 722/1000\n",
      "148/148 [==============================] - 0s 144us/step - loss: 8.7681e-05 - val_loss: 1.0143e-04\n",
      "Epoch 723/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 4.4743e-04 - val_loss: 1.6427e-04\n",
      "Epoch 724/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.3768e-04 - val_loss: 4.6450e-05\n",
      "Epoch 725/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.7850e-05 - val_loss: 1.0404e-05\n",
      "Epoch 726/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1034e-04 - val_loss: 1.1714e-04\n",
      "Epoch 727/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.0763e-05 - val_loss: 3.9024e-04\n",
      "Epoch 728/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5923e-05 - val_loss: 3.4856e-05\n",
      "Epoch 729/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3238e-04 - val_loss: 3.9781e-06\n",
      "Epoch 730/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0072e-04 - val_loss: 9.6258e-05\n",
      "Epoch 731/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.1318e-04 - val_loss: 8.0881e-06\n",
      "Epoch 732/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.7694e-05 - val_loss: 3.9157e-06\n",
      "Epoch 733/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.4106e-05 - val_loss: 2.8546e-05\n",
      "Epoch 734/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 3.2276e-05 - val_loss: 6.5008e-05\n",
      "Epoch 735/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.7958e-05 - val_loss: 9.4191e-07\n",
      "Epoch 736/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7034e-05 - val_loss: 6.3407e-07\n",
      "Epoch 737/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.1081e-06 - val_loss: 3.5819e-05\n",
      "Epoch 738/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.0137e-06 - val_loss: 4.0138e-06\n",
      "Epoch 739/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1859e-06 - val_loss: 9.9468e-07\n",
      "Epoch 740/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.1922e-06 - val_loss: 1.0960e-05\n",
      "Epoch 741/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.2159e-06 - val_loss: 1.7971e-05\n",
      "Epoch 742/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.9918e-07 - val_loss: 1.5053e-06\n",
      "Epoch 743/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 5.5713e-07 - val_loss: 2.6503e-06\n",
      "Epoch 744/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.5740e-07 - val_loss: 4.9803e-06\n",
      "Epoch 745/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.5731e-07 - val_loss: 3.1621e-06\n",
      "Epoch 746/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 7.5088e-07 - val_loss: 2.3127e-06\n",
      "Epoch 747/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.4399e-06 - val_loss: 5.9282e-06\n",
      "Epoch 748/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 9.5946e-07 - val_loss: 3.1518e-06\n",
      "Epoch 749/1000\n",
      "148/148 [==============================] - 0s 172us/step - loss: 9.1591e-07 - val_loss: 1.5428e-06\n",
      "Epoch 750/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.1712e-07 - val_loss: 1.6715e-06\n",
      "Epoch 751/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 7.7969e-07 - val_loss: 7.6287e-06\n",
      "Epoch 752/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.8084e-07 - val_loss: 1.1220e-06\n",
      "Epoch 753/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.6038e-07 - val_loss: 1.1068e-06\n",
      "Epoch 754/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.4096e-07 - val_loss: 4.4376e-06\n",
      "Epoch 755/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.6233e-07 - val_loss: 2.4722e-06\n",
      "Epoch 756/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.1359e-07 - val_loss: 1.0959e-06\n",
      "Epoch 757/1000\n",
      "148/148 [==============================] - 0s 149us/step - loss: 2.5359e-07 - val_loss: 2.2942e-06\n",
      "Epoch 758/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.6733e-07 - val_loss: 2.4101e-06\n",
      "Epoch 759/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.5426e-07 - val_loss: 1.4342e-06\n",
      "Epoch 760/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.3214e-07 - val_loss: 3.2224e-06\n",
      "Epoch 761/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 1.8099e-07 - val_loss: 2.6155e-06\n",
      "Epoch 762/1000\n",
      "148/148 [==============================] - 0s 485us/step - loss: 2.0926e-07 - val_loss: 1.4277e-06\n",
      "Epoch 763/1000\n",
      "148/148 [==============================] - 0s 199us/step - loss: 1.9062e-07 - val_loss: 5.7287e-07\n",
      "Epoch 764/1000\n",
      "148/148 [==============================] - 0s 910us/step - loss: 1.0216e-07 - val_loss: 2.8258e-06\n",
      "Epoch 765/1000\n",
      "148/148 [==============================] - 0s 647us/step - loss: 1.4042e-07 - val_loss: 2.6730e-06\n",
      "Epoch 766/1000\n",
      "148/148 [==============================] - 0s 458us/step - loss: 3.9177e-07 - val_loss: 6.5943e-07\n",
      "Epoch 767/1000\n",
      "148/148 [==============================] - 0s 344us/step - loss: 3.3191e-07 - val_loss: 1.1273e-06\n",
      "Epoch 768/1000\n",
      "148/148 [==============================] - 0s 539us/step - loss: 4.4269e-07 - val_loss: 2.2216e-06\n",
      "Epoch 769/1000\n",
      "148/148 [==============================] - 0s 795us/step - loss: 2.3299e-07 - val_loss: 2.1373e-06\n",
      "Epoch 770/1000\n",
      "148/148 [==============================] - 0s 236us/step - loss: 9.6713e-08 - val_loss: 1.6104e-06\n",
      "Epoch 771/1000\n",
      "148/148 [==============================] - 0s 398us/step - loss: 5.5738e-08 - val_loss: 1.3158e-06\n",
      "Epoch 772/1000\n",
      "148/148 [==============================] - 0s 222us/step - loss: 4.4305e-08 - val_loss: 1.9081e-06\n",
      "Epoch 773/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.8442e-08 - val_loss: 1.9634e-06\n",
      "Epoch 774/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.7696e-08 - val_loss: 2.2360e-06\n",
      "Epoch 775/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.7765e-08 - val_loss: 2.0750e-06\n",
      "Epoch 776/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.2921e-08 - val_loss: 1.7895e-06\n",
      "Epoch 777/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.1631e-08 - val_loss: 1.7298e-06\n",
      "Epoch 778/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.4238e-08 - val_loss: 8.2190e-07\n",
      "Epoch 779/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.3622e-08 - val_loss: 2.4319e-06\n",
      "Epoch 780/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.4253e-08 - val_loss: 2.9639e-06\n",
      "Epoch 781/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.2583e-08 - val_loss: 1.5093e-06\n",
      "Epoch 782/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.1819e-08 - val_loss: 9.6162e-07\n",
      "Epoch 783/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.1826e-08 - val_loss: 1.6812e-06\n",
      "Epoch 784/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.5329e-08 - val_loss: 2.1378e-06\n",
      "Epoch 785/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 3.5501e-08 - val_loss: 1.3743e-06\n",
      "Epoch 786/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.3039e-08 - val_loss: 1.4013e-06\n",
      "Epoch 787/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.7522e-08 - val_loss: 1.9557e-06\n",
      "Epoch 788/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.6442e-08 - val_loss: 1.5398e-06\n",
      "Epoch 789/1000\n",
      "148/148 [==============================] - 0s 202us/step - loss: 2.5890e-08 - val_loss: 1.9771e-06\n",
      "Epoch 790/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.6175e-08 - val_loss: 1.8229e-06\n",
      "Epoch 791/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7318e-08 - val_loss: 1.7017e-06\n",
      "Epoch 792/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 2.4369e-08 - val_loss: 2.0666e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 2.4120e-08 - val_loss: 1.6432e-06\n",
      "Epoch 794/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.2609e-08 - val_loss: 2.3707e-06\n",
      "Epoch 795/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.5092e-08 - val_loss: 1.5564e-06\n",
      "Epoch 796/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 2.7335e-08 - val_loss: 1.1551e-06\n",
      "Epoch 797/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.5673e-08 - val_loss: 1.8773e-06\n",
      "Epoch 798/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.9416e-08 - val_loss: 3.0175e-06\n",
      "Epoch 799/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 2.6612e-08 - val_loss: 3.2062e-06\n",
      "Epoch 800/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 3.5001e-08 - val_loss: 1.2655e-06\n",
      "Epoch 801/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.4516e-08 - val_loss: 7.3683e-07\n",
      "Epoch 802/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 4.5166e-08 - val_loss: 2.9395e-06\n",
      "Epoch 803/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.9946e-08 - val_loss: 2.5276e-06\n",
      "Epoch 804/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.9438e-08 - val_loss: 1.0925e-06\n",
      "Epoch 805/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1950e-08 - val_loss: 1.8886e-06\n",
      "Epoch 806/1000\n",
      "148/148 [==============================] - 0s 408us/step - loss: 2.9468e-08 - val_loss: 2.5117e-06\n",
      "Epoch 807/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.1291e-08 - val_loss: 1.7639e-06\n",
      "Epoch 808/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.5068e-08 - val_loss: 1.8255e-06\n",
      "Epoch 809/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.8035e-08 - val_loss: 1.7600e-06\n",
      "Epoch 810/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.2018e-08 - val_loss: 1.9055e-06\n",
      "Epoch 811/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.6229e-08 - val_loss: 2.7731e-06\n",
      "Epoch 812/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 3.7765e-08 - val_loss: 1.5153e-06\n",
      "Epoch 813/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1723e-08 - val_loss: 1.6120e-06\n",
      "Epoch 814/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.3321e-08 - val_loss: 2.2452e-06\n",
      "Epoch 815/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.2559e-08 - val_loss: 2.2300e-06\n",
      "Epoch 816/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.4244e-08 - val_loss: 2.0261e-06\n",
      "Epoch 817/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.9945e-08 - val_loss: 1.4816e-06\n",
      "Epoch 818/1000\n",
      "148/148 [==============================] - 0s 164us/step - loss: 2.2415e-08 - val_loss: 2.1981e-06\n",
      "Epoch 819/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.6008e-08 - val_loss: 2.1151e-06\n",
      "Epoch 820/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 3.5786e-08 - val_loss: 1.6219e-06\n",
      "Epoch 821/1000\n",
      "148/148 [==============================] - 0s 300us/step - loss: 7.8670e-08 - val_loss: 1.9476e-06\n",
      "Epoch 822/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 6.5702e-08 - val_loss: 3.6402e-06\n",
      "Epoch 823/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.6612e-08 - val_loss: 2.4046e-06\n",
      "Epoch 824/1000\n",
      "148/148 [==============================] - 0s 122us/step - loss: 4.1553e-08 - val_loss: 1.4418e-06\n",
      "Epoch 825/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.5835e-08 - val_loss: 1.4955e-06\n",
      "Epoch 826/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.9061e-07 - val_loss: 9.4592e-07\n",
      "Epoch 827/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.4313e-07 - val_loss: 1.6263e-06\n",
      "Epoch 828/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4547e-07 - val_loss: 2.3638e-06\n",
      "Epoch 829/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.9190e-07 - val_loss: 3.3052e-06\n",
      "Epoch 830/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2038e-07 - val_loss: 1.3444e-06\n",
      "Epoch 831/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 6.5075e-08 - val_loss: 1.2670e-06\n",
      "Epoch 832/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 5.9956e-08 - val_loss: 2.0407e-06\n",
      "Epoch 833/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.2708e-08 - val_loss: 2.2066e-06\n",
      "Epoch 834/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.7512e-08 - val_loss: 1.5197e-06\n",
      "Epoch 835/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.7646e-08 - val_loss: 1.6272e-06\n",
      "Epoch 836/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 2.1133e-08 - val_loss: 1.4570e-06\n",
      "Epoch 837/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7192e-08 - val_loss: 1.6501e-06\n",
      "Epoch 838/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8499e-08 - val_loss: 2.1050e-06\n",
      "Epoch 839/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.7351e-08 - val_loss: 1.7574e-06\n",
      "Epoch 840/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.3211e-08 - val_loss: 1.6194e-06\n",
      "Epoch 841/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.8754e-08 - val_loss: 1.4793e-06\n",
      "Epoch 842/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5982e-08 - val_loss: 1.4369e-06\n",
      "Epoch 843/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.4915e-08 - val_loss: 2.3634e-06\n",
      "Epoch 844/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.6877e-08 - val_loss: 2.2050e-06\n",
      "Epoch 845/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.6670e-08 - val_loss: 1.5376e-06\n",
      "Epoch 846/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.1561e-08 - val_loss: 1.3203e-06\n",
      "Epoch 847/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 2.1674e-08 - val_loss: 1.4690e-06\n",
      "Epoch 848/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.9379e-08 - val_loss: 1.9790e-06\n",
      "Epoch 849/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 6.6723e-08 - val_loss: 2.1937e-06\n",
      "Epoch 850/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 6.2469e-08 - val_loss: 2.0434e-06\n",
      "Epoch 851/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 7.4305e-08 - val_loss: 1.6526e-06\n",
      "Epoch 852/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 1.1680e-07 - val_loss: 1.3514e-06\n",
      "Epoch 853/1000\n",
      "148/148 [==============================] - 0s 196us/step - loss: 1.2835e-07 - val_loss: 1.2550e-06\n",
      "Epoch 854/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.5140e-07 - val_loss: 1.7706e-06\n",
      "Epoch 855/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.0179e-07 - val_loss: 2.8798e-06\n",
      "Epoch 856/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.8167e-08 - val_loss: 2.8465e-06\n",
      "Epoch 857/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 4.3411e-08 - val_loss: 1.7424e-06\n",
      "Epoch 858/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 3.0389e-08 - val_loss: 1.3341e-06\n",
      "Epoch 859/1000\n",
      "148/148 [==============================] - 0s 263us/step - loss: 2.8035e-08 - val_loss: 1.0799e-06\n",
      "Epoch 860/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 1.9194e-08 - val_loss: 1.4007e-06\n",
      "Epoch 861/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.7534e-08 - val_loss: 1.7706e-06\n",
      "Epoch 862/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.5021e-08 - val_loss: 1.7881e-06\n",
      "Epoch 863/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.3009e-08 - val_loss: 2.3078e-06\n",
      "Epoch 864/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5867e-08 - val_loss: 2.4325e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 865/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.3432e-08 - val_loss: 1.1331e-06\n",
      "Epoch 866/1000\n",
      "148/148 [==============================] - 0s 137us/step - loss: 1.2045e-08 - val_loss: 1.5116e-06\n",
      "Epoch 867/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0579e-08 - val_loss: 2.0403e-06\n",
      "Epoch 868/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.3149e-08 - val_loss: 1.3737e-06\n",
      "Epoch 869/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1395e-08 - val_loss: 2.0904e-06\n",
      "Epoch 870/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0323e-08 - val_loss: 1.6857e-06\n",
      "Epoch 871/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 9.6221e-09 - val_loss: 1.6885e-06\n",
      "Epoch 872/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.2644e-08 - val_loss: 1.4868e-06\n",
      "Epoch 873/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.5058e-08 - val_loss: 1.9453e-06\n",
      "Epoch 874/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.4949e-08 - val_loss: 9.5929e-07\n",
      "Epoch 875/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.8875e-08 - val_loss: 1.1781e-06\n",
      "Epoch 876/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.0313e-08 - val_loss: 2.5327e-06\n",
      "Epoch 877/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.2675e-08 - val_loss: 2.7175e-06\n",
      "Epoch 878/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.5648e-08 - val_loss: 3.6370e-06\n",
      "Epoch 879/1000\n",
      "148/148 [==============================] - 0s 144us/step - loss: 3.4188e-08 - val_loss: 3.5593e-06\n",
      "Epoch 880/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 4.6329e-08 - val_loss: 1.0012e-06\n",
      "Epoch 881/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.8876e-08 - val_loss: 9.3463e-07\n",
      "Epoch 882/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.0239e-08 - val_loss: 8.2778e-07\n",
      "Epoch 883/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.4057e-08 - val_loss: 8.0452e-07\n",
      "Epoch 884/1000\n",
      "148/148 [==============================] - 0s 150us/step - loss: 2.6870e-08 - val_loss: 1.4646e-06\n",
      "Epoch 885/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.7046e-08 - val_loss: 1.5242e-06\n",
      "Epoch 886/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0688e-08 - val_loss: 1.7359e-06\n",
      "Epoch 887/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2341e-08 - val_loss: 1.7093e-06\n",
      "Epoch 888/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.7989e-08 - val_loss: 1.4905e-06\n",
      "Epoch 889/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.6865e-08 - val_loss: 1.2168e-06\n",
      "Epoch 890/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 4.7875e-08 - val_loss: 1.4005e-06\n",
      "Epoch 891/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.4957e-08 - val_loss: 1.0753e-06\n",
      "Epoch 892/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.6241e-08 - val_loss: 1.5601e-06\n",
      "Epoch 893/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4417e-08 - val_loss: 1.4569e-06\n",
      "Epoch 894/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 1.7096e-08 - val_loss: 1.0754e-06\n",
      "Epoch 895/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.4972e-08 - val_loss: 1.4633e-06\n",
      "Epoch 896/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 1.1841e-08 - val_loss: 1.5501e-06\n",
      "Epoch 897/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0122e-08 - val_loss: 1.4714e-06\n",
      "Epoch 898/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.1559e-08 - val_loss: 1.5625e-06\n",
      "Epoch 899/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.2724e-08 - val_loss: 1.5619e-06\n",
      "Epoch 900/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.6799e-08 - val_loss: 1.2386e-06\n",
      "Epoch 901/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.0583e-08 - val_loss: 7.8468e-07\n",
      "Epoch 902/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.3621e-08 - val_loss: 8.9432e-07\n",
      "Epoch 903/1000\n",
      "148/148 [==============================] - 0s 167us/step - loss: 3.5624e-08 - val_loss: 1.5690e-06\n",
      "Epoch 904/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 6.2491e-08 - val_loss: 1.5423e-06\n",
      "Epoch 905/1000\n",
      "148/148 [==============================] - 0s 178us/step - loss: 2.7346e-08 - val_loss: 1.7229e-06\n",
      "Epoch 906/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.0828e-08 - val_loss: 1.8147e-06\n",
      "Epoch 907/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5065e-08 - val_loss: 2.3772e-06\n",
      "Epoch 908/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7853e-08 - val_loss: 1.9561e-06\n",
      "Epoch 909/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.3363e-08 - val_loss: 1.6790e-06\n",
      "Epoch 910/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.3737e-08 - val_loss: 8.5045e-07\n",
      "Epoch 911/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.7091e-08 - val_loss: 9.2282e-07\n",
      "Epoch 912/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.1307e-08 - val_loss: 5.7349e-07\n",
      "Epoch 913/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.1265e-08 - val_loss: 1.0637e-06\n",
      "Epoch 914/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.0165e-08 - val_loss: 1.1745e-06\n",
      "Epoch 915/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.1414e-08 - val_loss: 1.3025e-06\n",
      "Epoch 916/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 8.8918e-08 - val_loss: 1.3709e-06\n",
      "Epoch 917/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.6974e-08 - val_loss: 1.4686e-06\n",
      "Epoch 918/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.9739e-07 - val_loss: 1.8311e-06\n",
      "Epoch 919/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.2366e-08 - val_loss: 1.5748e-06\n",
      "Epoch 920/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 8.6103e-08 - val_loss: 1.3086e-06\n",
      "Epoch 921/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.4737e-07 - val_loss: 1.6616e-06\n",
      "Epoch 922/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.6413e-07 - val_loss: 1.2454e-06\n",
      "Epoch 923/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 5.3425e-07 - val_loss: 1.1474e-06\n",
      "Epoch 924/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.2869e-07 - val_loss: 8.7771e-07\n",
      "Epoch 925/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.0094e-07 - val_loss: 1.5057e-06\n",
      "Epoch 926/1000\n",
      "148/148 [==============================] - 0s 139us/step - loss: 2.1153e-07 - val_loss: 1.6320e-06\n",
      "Epoch 927/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 8.0454e-07 - val_loss: 1.2369e-06\n",
      "Epoch 928/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.7514e-06 - val_loss: 6.9563e-06\n",
      "Epoch 929/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.0738e-05 - val_loss: 2.3532e-06\n",
      "Epoch 930/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 9.7159e-06 - val_loss: 1.7918e-06\n",
      "Epoch 931/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.5804e-06 - val_loss: 1.7685e-07\n",
      "Epoch 932/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.8902e-06 - val_loss: 1.6331e-06\n",
      "Epoch 933/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 1.3662e-06 - val_loss: 4.0471e-06\n",
      "Epoch 934/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.1654e-07 - val_loss: 1.7817e-06\n",
      "Epoch 935/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 6.0838e-07 - val_loss: 2.2229e-06\n",
      "Epoch 936/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.4868e-06 - val_loss: 3.0196e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "148/148 [==============================] - 0s 216us/step - loss: 2.1582e-06 - val_loss: 9.1767e-07\n",
      "Epoch 938/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 1.9809e-06 - val_loss: 1.9854e-06\n",
      "Epoch 939/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 3.6990e-06 - val_loss: 1.5727e-06\n",
      "Epoch 940/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 1.6824e-06 - val_loss: 1.3931e-06\n",
      "Epoch 941/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 4.1434e-07 - val_loss: 9.2375e-07\n",
      "Epoch 942/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 9.4574e-08 - val_loss: 1.5660e-06\n",
      "Epoch 943/1000\n",
      "148/148 [==============================] - 0s 134us/step - loss: 1.0825e-07 - val_loss: 1.8648e-06\n",
      "Epoch 944/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 5.9526e-08 - val_loss: 1.4129e-06\n",
      "Epoch 945/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.7528e-08 - val_loss: 1.2379e-06\n",
      "Epoch 946/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 8.3245e-08 - val_loss: 1.3867e-06\n",
      "Epoch 947/1000\n",
      "148/148 [==============================] - 0s 165us/step - loss: 3.7114e-08 - val_loss: 1.0891e-06\n",
      "Epoch 948/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.4003e-08 - val_loss: 7.9494e-07\n",
      "Epoch 949/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0467e-07 - val_loss: 4.7500e-07\n",
      "Epoch 950/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.0803e-07 - val_loss: 6.6355e-07\n",
      "Epoch 951/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.8934e-07 - val_loss: 9.0655e-07\n",
      "Epoch 952/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 3.1646e-07 - val_loss: 8.4037e-07\n",
      "Epoch 953/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.8710e-07 - val_loss: 2.6070e-06\n",
      "Epoch 954/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.0161e-07 - val_loss: 3.8294e-06\n",
      "Epoch 955/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 2.9889e-07 - val_loss: 1.7772e-06\n",
      "Epoch 956/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 1.5405e-07 - val_loss: 2.3316e-06\n",
      "Epoch 957/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.5432e-07 - val_loss: 2.3540e-06\n",
      "Epoch 958/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.4291e-08 - val_loss: 1.2608e-06\n",
      "Epoch 959/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.4363e-07 - val_loss: 2.6364e-06\n",
      "Epoch 960/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 7.6181e-07 - val_loss: 3.2150e-06\n",
      "Epoch 961/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 1.3221e-06 - val_loss: 1.6709e-06\n",
      "Epoch 962/1000\n",
      "148/148 [==============================] - 0s 141us/step - loss: 8.9710e-07 - val_loss: 3.8490e-06\n",
      "Epoch 963/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 5.8339e-07 - val_loss: 2.1551e-06\n",
      "Epoch 964/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 1.3562e-05 - val_loss: 1.1237e-05\n",
      "Epoch 965/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 4.7020e-05 - val_loss: 2.4406e-06\n",
      "Epoch 966/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.5167e-05 - val_loss: 7.1721e-07\n",
      "Epoch 967/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 8.1779e-05 - val_loss: 6.1780e-06\n",
      "Epoch 968/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 8.8921e-05 - val_loss: 4.7016e-05\n",
      "Epoch 969/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.1635e-05 - val_loss: 1.1135e-04\n",
      "Epoch 970/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 1.0684e-04 - val_loss: 4.9823e-05\n",
      "Epoch 971/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0097e-04 - val_loss: 5.3978e-05\n",
      "Epoch 972/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 5.7612e-05 - val_loss: 2.9606e-04\n",
      "Epoch 973/1000\n",
      "148/148 [==============================] - 0s 162us/step - loss: 5.2662e-05 - val_loss: 2.2593e-04\n",
      "Epoch 974/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.2304e-04 - val_loss: 1.1895e-04\n",
      "Epoch 975/1000\n",
      "148/148 [==============================] - 0s 195us/step - loss: 1.8916e-04 - val_loss: 2.4655e-05\n",
      "Epoch 976/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 9.8496e-05 - val_loss: 9.0422e-06\n",
      "Epoch 977/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 5.2117e-05 - val_loss: 1.2268e-05\n",
      "Epoch 978/1000\n",
      "148/148 [==============================] - 0s 128us/step - loss: 5.9809e-05 - val_loss: 9.3850e-06\n",
      "Epoch 979/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.0202e-05 - val_loss: 4.3509e-05\n",
      "Epoch 980/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 5.5088e-05 - val_loss: 7.3505e-07\n",
      "Epoch 981/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 3.1331e-05 - val_loss: 2.1813e-06\n",
      "Epoch 982/1000\n",
      "148/148 [==============================] - 0s 175us/step - loss: 2.7253e-05 - val_loss: 2.8277e-06\n",
      "Epoch 983/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 7.2109e-06 - val_loss: 1.0604e-04\n",
      "Epoch 984/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 8.2963e-06 - val_loss: 2.4064e-04\n",
      "Epoch 985/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 8.3352e-06 - val_loss: 1.3792e-04\n",
      "Epoch 986/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 6.6553e-06 - val_loss: 1.6252e-05\n",
      "Epoch 987/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 5.2727e-06 - val_loss: 6.6903e-06\n",
      "Epoch 988/1000\n",
      "148/148 [==============================] - 0s 142us/step - loss: 2.6366e-06 - val_loss: 1.2949e-05\n",
      "Epoch 989/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 2.8986e-06 - val_loss: 1.9120e-06\n",
      "Epoch 990/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.1423e-06 - val_loss: 8.2497e-06\n",
      "Epoch 991/1000\n",
      "148/148 [==============================] - 0s 182us/step - loss: 8.0823e-07 - val_loss: 2.0631e-05\n",
      "Epoch 992/1000\n",
      "148/148 [==============================] - 0s 155us/step - loss: 3.8806e-07 - val_loss: 2.7734e-05\n",
      "Epoch 993/1000\n",
      "148/148 [==============================] - 0s 154us/step - loss: 3.6134e-07 - val_loss: 1.5094e-05\n",
      "Epoch 994/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 2.6047e-07 - val_loss: 1.4429e-05\n",
      "Epoch 995/1000\n",
      "148/148 [==============================] - 0s 135us/step - loss: 4.9638e-07 - val_loss: 9.8876e-06\n",
      "Epoch 996/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 3.7035e-07 - val_loss: 5.3078e-06\n",
      "Epoch 997/1000\n",
      "148/148 [==============================] - 0s 169us/step - loss: 2.1897e-07 - val_loss: 5.8329e-06\n",
      "Epoch 998/1000\n",
      "148/148 [==============================] - 0s 189us/step - loss: 1.1872e-07 - val_loss: 6.0517e-06\n",
      "Epoch 999/1000\n",
      "148/148 [==============================] - 0s 168us/step - loss: 1.0182e-07 - val_loss: 4.0923e-06\n",
      "Epoch 1000/1000\n",
      "148/148 [==============================] - 0s 148us/step - loss: 1.0219e-07 - val_loss: 1.9491e-06\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(x_train.reshape(148, 5, 1), y_train, epochs=1000, validation_data=(x_test.reshape(37, 5, 1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(r.history['loss'], label=\"Loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting y_test when x_test is feeded into the model\n",
    "\n",
    "result = model.predict(x_test.reshape(37,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153.00946, 154.01285, 155.01624, 156.0196 , 157.023  , 158.02637,\n",
       "       159.02975, 160.03314, 161.03653, 162.0399 , 163.04329, 164.04666,\n",
       "       165.05005, 166.05342, 167.05682, 168.06018, 169.06357, 170.06647,\n",
       "       171.06932, 172.0729 , 173.07655, 174.08017, 175.08383, 176.08746,\n",
       "       177.0911 , 178.09473, 179.09837, 180.10202, 181.10565, 182.10928,\n",
       "       183.11345, 184.11801, 185.12213, 186.12592, 187.12973, 188.13351,\n",
       "       189.13733], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reversing predicted y_test values \n",
    "\n",
    "scaler.inverse_transform(result).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153., 154., 155., 156., 157., 158., 159., 160., 161., 162., 163.,\n",
       "       164., 165., 166., 167., 168., 169., 170., 171., 172., 173., 174.,\n",
       "       175., 176., 177., 178., 179., 180., 181., 182., 183., 184., 185.,\n",
       "       186., 187., 188., 189.], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjusting predicited y_test values by rounding \n",
    "\n",
    "np.round(scaler.inverse_transform(result).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153., 154., 155., 156., 157., 158., 159., 160., 161., 162., 163.,\n",
       "       164., 165., 166., 167., 168., 169., 170., 171., 172., 173., 174.,\n",
       "       175., 176., 177., 178., 179., 180., 181., 182., 183., 184., 185.,\n",
       "       186., 187., 188., 189.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into original y_test values\n",
    "\n",
    "scaler.inverse_transform(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.scatter(range(37), result, c='r', label=\"Predicted\")\n",
    "plt.scatter(range(37),y_test, c='b', label=\"Original\")\n",
    "plt.legend(loc =\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(result, c='r', label=\"Predicted\")\n",
    "plt.plot(y_test, c='b', label=\"Original\")\n",
    "plt.legend(loc =\"lower right\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.Shape: (10, 5, 1) Y_test.Shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the test dataset for series of numbers prediction with LSTM trained model \n",
    "\n",
    "T = 5\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for t in range(len(test_dataset)-T):\n",
    "  x = test_dataset[t:t+T]\n",
    "  X_test.append(x)\n",
    "  y = test_dataset[t+T]\n",
    "  Y_test.append(y)\n",
    "X_test = np.array(X_test).reshape(-1, T, 1)\n",
    "Y_test = np.array(Y_test)\n",
    "NN = len(X_test)\n",
    "\n",
    "print(\"X_test.Shape:\",X_test.shape, \"Y_test.Shape:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with untrain dataset X_test \n",
    "\n",
    "result_01 = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190., 191., 192., 193., 194., 195., 196., 197., 198., 199.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjusting predicited Y_test values by rounding  \n",
    "\n",
    "np.round(scaler.inverse_transform(result_01).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190., 191., 192., 193., 194., 195., 196., 197., 198., 199.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into original y_test values\n",
    "\n",
    "scaler.inverse_transform(Y_test).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
